"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"A Survey and Taxonomy on Energy-Aware Data Management Strategies in Cloud Environment","X. You; X. Lv; Z. Zhao; J. Han; X. Ren","Beijing Key Laboratory of Internet Culture and Digital Dissemination Research, Beijing Information Science & Technology University, Beijing, China; Beijing Key Laboratory of Internet Culture and Digital Dissemination Research, Beijing Information Science & Technology University, Beijing, China; National Joint Engineering Laboratory of Internet Applied Technology of Mines, Internet of Things (IoT) Research Center, China University of Mining and Technology, Xuzhou, China; Laboratory of Complex Systems, Institute of Systems Engineering, AMS, PLA, Beijing, China; Key Laboratory of Complex Systems Modeling and Simulation, Ministry of Education, Hangzhou Dianzi University, Hangzhou, China",IEEE Access,"28 May 2020","2020","8","","94279","94293","During the past ten years, the energy consumption problem in cloud-related environments has attracted substantial attention in research and industrial communities. Researchers have conducted many surveys on energy efficiency issues from different perspectives. All of the surveys can be classified into five categories: surveys on the energy efficiency of the whole cloud related system, surveys on the energy efficiency of a certain level or component of the cloud, surveys on all of the energy efficient strategies, surveys on a certain energy efficiency techniques, and other energy efficiency related surveys. However, to the best of our knowledge, surveys on energy-aware data management strategies in cloud-related environment are absent. In this paper, we conduct a comprehensive survey on energy saving-aware data management strategies in cloud-related environments, such as data classification, data placement and data replication strategies. Compared to current existing reviews on energy efficiency in cloud-related environments, we firstly conduct the survey on the energy consumption problem from the data management perspective. Furthermore, we classify the energy-aware data management strategies from different perspectives. This survey and the taxonomy of the energy-aware data management strategies demonstrate the potential for reducing the energy consumption at the data management level of a cloud storage system, which will compress more space for energy reduction and finally achieve energy proportionality. Moreover, this survey and taxonomy on the energy efficiency issue from the data management perspective is an important supplement to current existing surveys on energy efficiency in cloud-related environments.","2169-3536","","10.1109/ACCESS.2020.2992748","National Natural Science Foundation of China(grant numbers:61671070); National Science Key Lab Fund(grant numbers:6142006190301); National Language Committee of China(grant numbers:ZDI135-53); Project of and Project of Developing University Intension for Improving the Level of Scientific Research, Qin Xin Talents Cultivation Program(grant numbers:2019KYNH226); Beijing Information Science & Technology University(grant numbers:QXTCP B201908); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LQY18F020001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087894","Energy consumption;cloud storage system;data classification;data placement;data replication;energy proportionality","Cloud computing;Energy consumption;Taxonomy;Data centers;Green products;Layout;Ocean temperature","","10","","134","CCBY","6 May 2020","","","IEEE","IEEE Journals"
"A Comprehensive Review of Green Computing: Past, Present, and Future Research","S. G. Paul; A. Saha; M. S. Arefin; T. Bhuiyan; A. A. Biswas; A. W. Reza; N. M. Alotaibi; S. A. Alyami; M. A. Moni","Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Bangabandhu Sheikh Mujibur Rahman University, Kishoreganj, Bangladesh; Department of Computer Science and Engineering, East West University, Dhaka, Bangladesh; Department of Mathematics and Statistics, Faculty of Science, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia; Department of Mathematics and Statistics, Faculty of Science, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia; Artificial Intelligence and Cyber Futures Institute, Charles Stuart University, Bathurst, NSW, Australia",IEEE Access,"21 Aug 2023","2023","11","","87445","87494","Green computing, also called sustainable computing, is the process of developing and optimizing computer chips, systems, networks, and software in such a manner that can maximize efficiency by utilizing energy more efficiently and minimizing the negative environmental influence on the surrounding. The term “green computing” refers to practices that lessen the negative effects of technology on the environment. Due to the improvements in modern technology, various devices, mechanisms, and software have been developed, and lots of studies have been conducted to optimize and increase those technologies’ green computing abilities. Thus, review and summarization of green computing-based studies are required to identify the current advancements, challenges, and future research opportunities. This study reviewed and summarized green computing in each area studies, by exploring green computing’s twelve areas. Current research trends, datasets or testing mechanisms, and the construction or implementation of various technologies to accomplish green computing and sustainable development have been discussed. This study, after conducting a thorough comparison and analysis, provides responses to the proposed state-of-the-art research questions. Furthermore, this study presents the current challenges and future research opportunities with respect to each green computing area. This study will provide organizations, researchers, and institutions conducting research on green computing with insights and ideas. Furthermore, environmental organizations, companies, and government agencies concerned with reducing carbon emissions and energy consumption will also benefit from this review study.","2169-3536","","10.1109/ACCESS.2023.3304332","Deanship of Scientific Research, Imam Mohammad Ibn Saud Islamic University (IMSIU), through the Research Partnership Program(grant numbers:RP-21-09-09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214579","Carbon emissions;eco-friendly computing;energy efficiency;green computing;green computing area;sustainable development","Green computing;Green products;Sustainable development;Energy efficiency;Cloud computing;Software;Hardware;Carbon emissions;Green computing;Sustainable development","","14","","258","CCBYNCND","11 Aug 2023","","","IEEE","IEEE Journals"
"Smart Energy Conservation in Data Centers Using Machine Learning Based Software-Defined Networking","H. Aslam; S. Munawar","Department of Computer Science and Information Technology, Virtual University of Pakistan, Dera Ghazi Khan; Department of Computer Science and Information Technology, Virtual University of Pakistan, Lahore",2023 6th International Conference on Energy Conservation and Efficiency (ICECE),"12 Apr 2023","2023","","","1","10","The rapid growth of Data Centers (DC) poses the problem of heavy energy consumption. The servers consume most of the energy in the DC, but the network infrastructure also uses a great deal of energy. It is therefore necessary to minimize the energy consumption of DC. DC Energy Conservation Strategy has various directorates, including energy-efficient methods for servers and networks, blended for servers and networks, cooling and renewable energy. As the literature revealed, many existing ways are available, but there are many problems with the current strategies, such as the issues include loss of packets, systems with rigid approaches with low modifications, obsolete methodologies for newer hardware devices, methods tested on small networks, and the amount of energy saved compared to the risk and financial cost involved is not worth it. This research eliminates the risk of packet loss up to some extent by securing as well improving the network efficiency. The study aims to construct a way to save energy in DC by employing the software-defined networking technique and modifying the existing Elastic Tree to maximize power savings, minimize the performance effect, and guarantee fault tolerance. It can consider improving the existing optimizer in elastic tree methodology and introducing new factors like power control based on traffic pattern analysis. A Mininet emulator is utilized to develop a virtual DC network. An optimizer is designed using different models and includes a floodlight controller that monitors traffic flow and creates a custom network topology by tracking the traffic pattern in DC. This custom network topology keeps the network's essential components active and power down the unneeded parts, including many links and switches, to meet the best performance. The custom topology suggested demonstrating in J-Graph. This exploration further leads to optimizer analysis, a step toward improving smart energy conservation.","2767-9829","979-8-3503-3219-3","10.1109/ICECE58062.2023.10092487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10092487","Power Efficiency;Data Centers;Deep Learning;Cloud DC;Energy Conservation;Energy Efficiency;Artificial Intelligence (AI);software-defined networking","Energy consumption;Data centers;Renewable energy sources;Network topology;Power control;Traffic control;Topology","","","","102","IEEE","12 Apr 2023","","","IEEE","IEEE Conferences"
"Riding Pattern Identification by Machine Learning for Electric Motorcycles","M. Faraji-Niri; T. Q. Dinh; J. Marco","WMG, University of Warwick, Coventry, United Kingdom; WMG, University of Warwick, Coventry, United Kingdom; WMG, University of Warwick, Coventry, United Kingdom",2021 24th International Conference on Mechatronics Technology (ICMT),"1 Feb 2022","2021","","","1","6","Identification of riding patterns is one of the key enablers to update energy consumption strategy, optimise the energy management system and increase the range of electric motorcycles despite their weight and space limits. Considering the varying driving conditions in real applications, improving accuracy of the riding pattern recognition without significant complexity is the main challenge. In this paper a simple and efficient online classification method is introduced based on features extracted only from the motorcycle speed. The recognition mechanism is firstly developed using support vector machine technique. The effect of validation method for removing the optimism in classification and the contribution of features to the accuracy of model is then investigated. Evaluation of the method on the real riding conditions in simulation environment shows the effectiveness of the approach.","","978-1-6654-2459-2","10.1109/ICMT53429.2021.9687179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687179","Ride Cycle Classification;Electric Motorcycles;Machine Learning","Support vector machines;Energy consumption;Mechatronics;Motorcycles;Machine learning;Feature extraction;Windows","","1","","21","IEEE","1 Feb 2022","","","IEEE","IEEE Conferences"
"Leveraging Deep Learning to Strengthen the Cyber-Resilience of Renewable Energy Supply Chains: A Survey","M. N. Halgamuge","Department of Information Systems and Business Analytics, RMIT University, Melbourne, VIC, Australia",IEEE Communications Surveys & Tutorials,"22 Aug 2024","2024","26","3","2146","2175","Deep learning shows immense potential for strengthening the cyber-resilience of renewable energy supply chains. However, research gaps in comprehensive benchmarks, real-world model evaluations, and data generation tailored to the renewable domain persist. This study explores applying state-of-the-art deep learning techniques to secure renewable supply chains, drawing insights from over 300 publications. We aim to provide an updated, rigorous analysis of deep learning applications in this field to guide future research. We systematically review literature spanning 2020–2023, retrieving relevant articles from major databases. We examine deep learning’s role in intrusion/anomaly detection, supply chain cyberattack detection frameworks, security standards, historical attack analysis, data management strategies, model architectures, and supply chain cyber datasets. Our analysis demonstrates deep learning enables renewable supply chain anomaly detection by processing massively distributed data. We highlight crucial model design factors, including accuracy, adaptation capability, communication security, and resilience to adversarial threats. Comparing 18 major historical attacks informs risk analysis. We also showcase potential deep learning architectures, evaluating their relative strengths and limitations in security applications. Moreover, our review emphasizes best practices for renewable data curation, considering quality, labeling, access efficiency, and governance. Effective deep learning integration necessitates tailored benchmarks, model tuning guidance, and renewable energy data generation. Our multi-dimensional analysis motivates focused efforts on enhancing detection explanations, securing communications, continually retraining models, and establishing standardized assessment protocols. Overall, we provide a comprehensive roadmap to progress renewable supply chain cyber-resilience leveraging deep learning’s immense potential.","1553-877X","","10.1109/COMST.2024.3365076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433003","Renewable energy system;supply chain;cyber security;deep learning;wind energy;solar energy;hydropower","Renewable energy sources;Supply chains;Deep learning;Security;Surveys;Computer security;Internet of Things","","","","326","IEEE","12 Feb 2024","","","IEEE","IEEE Journals"
"A Survey on Green IoT and Its Opportunities for Future Directions","S. Upadhye; N. Shelke; U. P. Thakur","Department of Computer Application, Shri Ramdeobaba College of Engineering and Management, Nagpur, India; Symbiosis Institute of Technology, Nagpur Campus Symbiosis International (Deemed University), Pune, India; Department of Computer Science and Engineering, Jhulelal Institute of Technology, Nagpur, India",2023 International Conference on Advanced Computing & Communication Technologies (ICACCTech),"27 Feb 2024","2023","","","329","334","The Internet of Things (IoT) has changed the way technology has evolved, integrating it with other aspects such as home appliances for home automation, smart city projects, e-waste management, and many more. But with the increase in the usage of IoT, there are several challenges that come along, like an increase in energy consumption. Due to this, the Green IoT comes into play. It looks for alternative solutions to the present style of implementing IoT technology, which leads to eco-friendly, sustainable, and cost-effective solutions. This survey points towards effective ways of implementing the IoT for eco-friendly, sustainable, and cost-effective management. The Internet of Things (IoT) has transformed the way technology is integrated into various aspects of life, including home automation, smart city projects, and e-waste management. However, the increasing usage of IoT technology has led to challenges, such as higher energy consumption. This has given rise to Green IoT, which seeks alternative solutions for implementing eco-friendly, sustainable, and cost-effective IoT technology. This survey focuses on effective ways to implement IoT technology for sustainable and eco-friendly cost management. It also explores the potential of IoT technology in new areas, its future sustainability, and its challenges. The adoption of green IoT practices can reduce pollution hazards, traffic waste, and energy consumption while enhancing public safety and quality of life. To create sustainable and eco-friendly cities, researchers, policymakers, and industry leaders must collaborate to address IoT implementation challenges. The survey concludes by highlighting opportunities for future research and innovation in this field.","","979-8-3503-8088-0","10.1109/ICACCTech61146.2023.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10441655","Green IoT;Sustainability;Eco-friendly;Energy efficient;IoT oppotunities","Surveys;Energy consumption;Home automation;Smart cities;Green products;Electronic waste;Internet of Things","","","","27","IEEE","27 Feb 2024","","","IEEE","IEEE Conferences"
"Energy Efficient Data Management in Health Care","H. V; L. J; S. R. A; N. Divya Bharathi; S. Upadhyay; V. R","Computer Science and Engineering, R.M.K Engineering College; R.M.K. Engineering College; Electronics And Communication Engineering, R.M.K. College of Engineering and Technology; Electronics and Communication Engineering, SIMATS School of Engineering; Department of Electronics & Communication Engineering, Cambridge Institute of Technology, Ranchi; CSE, Ramco Institute of Technology, Rajapalayam",2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS),"27 Mar 2023","2023","","","682","688","In healthcare WSN applications, data loss due to congestion may trigger a ""death alert"" for a crucial patient. Because of this, a system must be designed to either prevent or reduce congestion. This study presents an energy-efficient and reliable multi-path data transmission protocol for healthcare Wireless Sensor Networks (WSN). Spare data and sensitive data packets are sent through a route with little transmission interference when the system is jammed. The recommended technique assesses the danger of congestion at intermediate nodes and adjusts their transmission rate to prevent congestion. Each node's buffer is partitioned to make data transport fair and efficient. The protocol's high reliability is maintained through hop-by-hop loss recovery and acknowledgement. Simulations are used to test the recommended method's functionality. In terms of energy economy, reliability, and end-to-end delivery ratio, it exceeds existing healthcare congestion management algorithms. This study evaluates and compares the routing techniques. They present a concept for developing an energy-efficient routing protocol. This approach designs quick, compact, more energy-efficient routes than existing ones. NS2 is used to run and test the proposed system. The proposed method beats the current protocol in terms of average delay, energy savings, and packet delivery ratio.","","978-1-6654-6216-7","10.1109/ICAIS56108.2023.10073796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10073796","Network simulator;energy consumption;hop to hop loss;energy efficient routing;WSN","Wireless sensor networks;Packet loss;Medical services;Telecommunication traffic;Routing;Energy efficiency;Routing protocols","","","","18","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"Carbon Credits Storage: A Comparative Multifactor Analysis of On-chain vs Off-chain Approaches","N. A. Alghanmi; N. Alghanmi; H. Alhosaini; F. K. Hussain","University of Jeddah, Jeddah, Saudi Arabia; King Abdulaziz University, Rabigh, Saudi Arabia; University of Jeddah, Jeddah, Saudi Arabia; University of Technology Sydney, Sydney, Australia",2023 IEEE International Conference on e-Business Engineering (ICEBE),"18 Dec 2023","2023","","","134","142","Data management with blockchain technology has significant implications for supply chain management, healthcare systems, finance, and government. Carbon credit systems, often referred to as the emissions reduction mechanism, are one of the areas impacted by blockchain which is a sector that seeks to reduce the levels of greenhouse gas emissions. The transparency, verifiability, and reliability characteristics of blockchain technology make it easier to track and audit information efficiently and reliably. On-chain and off-chain are two terms commonly used in the context of blockchain data management. The term ”onchain” refers to transactions that are explicitly documented on the ledger. Off-chain, on the other hand, refers to transactions that occur outside of the blockchain network. In this paper, we investigate blockchain-based solutions that are related to carbon credit systems and focus on both on-chain and offchain approaches. Moreover, we evaluate their performance and applicability based on the following main metrics: security, scalability, latency, and cost. In addition, we run a comparative analysis to assess these systems, identify their strengths and limitations, and suggest future directions for researchers to follow.","2472-8527","979-8-3503-2555-3","10.1109/ICEBE59045.2023.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356172","Blockchain;Blockchain Management;Data Management;On-Chain;Off-Chain;Carbon Credits","Measurement;Supply chain management;Scalability;Government;Finance;Medical services;Blockchains","","","","60","IEEE","18 Dec 2023","","","IEEE","IEEE Conferences"
"Artificial Intelligence Applications and Prospects for The Smart Grid","X. Zhao; Y. Guo; X. Guo; H. Li","School of Electrical and Information Engineering, University of Panzhihua, Panzhihua, China; School of Electrical and Information Engineering, University of Panzhihua, Panzhihua, China; School of Electrical and Information Engineering, University of Panzhihua, Panzhihua, China; School of Electrical and Information Engineering, University of Panzhihua, Panzhihua, China",2023 Panda Forum on Power and Energy (PandaFPE),"9 Jun 2023","2023","","","1844","1848","The power system has steadily expanded the integration and development process with artificial intelligence (AI) under the new wave of global AI. The application of AI technology can not only improve the efficiency and safety of the power system, but also provide a better service experience for consumers. In order to do this, this research explores how AI technology is used in power systems. AI's application and current situation in the smart grid (SG) are clarified, such as power load forecasting, energy management, fault diagnosis and monitoring, etc. The issues faced in the SG, such as security, data processing capability and consumer participation, are discussed. In SG, data security and privacy protection are very important issues. In addition, SG needs to process a large amount of data, so it needs powerful data processing capability and efficient algorithms to handle these data. The possible future trends of the SG are foreseen, including the deep integration of AI technologies into the SG, the establishment of a safe and reliable innovative grid system, and the change of consumer participation role.","","979-8-3503-2117-3","10.1109/PandaFPE57779.2023.10141110","National Natural Science Foundation of China(grant numbers:52202368); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10141110","Artificial intelligence;Smart grid;Application status;Development trend","Renewable energy sources;Power supplies;Market research;Data processing;Regulation;Power system reliability;Smart grids","","3","","22","IEEE","9 Jun 2023","","","IEEE","IEEE Conferences"
"Green Computing for Energy Transition: A Survey","T. Nazaré; J. Gadelha; E. Nepomuceno; R. Lozi","Maynooth University, IE; Maynooth University, IE; Maynooth University, IE; Universite Cote d'Azur, FR",IEEE Latin America Transactions,"14 Sep 2023","2023","21","9","937","948","The global information technology (IT) industry accounts for approximately 2% of the world's greenhouse gas emissions, equivalent to the aviation industry's emissions. Moreover, IT energy consumption is projected to increase by 5% annually, and the industry is expected to consume 21% of the world's electricity by 2030. Therefore, there is a growing urgency to develop and implement sustainable computing practices that reduce energy consumption and mitigate the environmental impact of the computing industry. Green computing has emerged as a vital area of research due to the increasing demand for environmentally sustainable practices in the computing industry. To contribute to this dialogue, this paper presents a comprehensive survey of 74 articles related to green computing and its various subtopics, including sustainable practices, energy-efficient hardware design, software optimization, and the use of renewable energy sources. Additionally, the survey analyses the role of green algorithms in reducing energy consumption and carbon footprint in computing systems. The findings highlight the significance of adopting green computing practices to mitigate the adverse impact of computing on the environment, including greenhouse gas emissions, energy consumption, and waste generation. Our survey underscores the growing interest in green computing, as evidenced by the increasing number of articles and research studies dedicated to this topic. Furthermore, our analysis of the existing literature highlights the need for further research in this area to develop more effective and sustainable solutions. In conclusion, the survey serves as a valuable resource for researchers, practitioners, and policymakers to understand the current state of research in green computing and to identify areas for future research. By promoting sustainable practices in the computing industry, we can contribute to a more environmentally sustainable future for our planet.","1548-0992","","10.1109/TLA.2023.10251799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251799","Green Algorithms;Sustainable;Green Computing;Carbon Footprint;Energy Transition","Green computing;Energy consumption;Green products;Industries;Carbon footprint;Software algorithms;Surveys","","4","","","IEEE","14 Sep 2023","","","IEEE","IEEE Journals"
"Green Efficiency for Quality Models in the Field of Cryptocurrency; IOTA Green Efficiency","A. A. Sori; M. Golsorkhtabaramiri; A. A. Sori","Department of Computer Engineering, Babol Branch, Islamic Azad University, Babol, Iran; Department of Computer Engineering, Babol Branch, Islamic Azad University, Babol, Iran; Department of Computer Engineering, Qaemshahr Branch, Islamic Azad University, Qaemshahr, Iran",2021 IEEE Green Technologies Conference (GreenTech),"28 Jun 2021","2021","","","357","363","In the last few years, cryptocurrencies have found a special place in the free economy. In addition to the importance and economic features of cryptocurrencies, the technical perspective on this area is also significant. If we want to use cryptocurrencies in the future as a global technology with everyday use, then this field needs to be optimized. In addition to issues such as security, scalability, speed, etc., energy efficiency and sustainability should also be considered. In this paper, the proposed “green efficiency” characteristic is added to the quality model for the field of cryptocurrency. This characteristic consists of four units that have independent tasks, the overall process of which seeks to design an optimal quality model in terms of energy consumption in cryptocurrency. The central unit of this proposal is the G-ECC, which controls other units. The unit makes the final decision to reduce energy consumption and trade-offs between features by reviewing and evaluating reports received from other units. At the end of this article, the green efficiency of IOTA cryptocurrency is reviewed in the proposed model.","2166-5478","978-1-7281-9139-3","10.1109/GreenTech48523.2021.00101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458457","cryptocurrency;quality model;green efficiency;sustainability;energy consumption;IOTA","Economics;Energy consumption;Scalability;Conferences;Energy efficiency;Cryptography;Proposals","","2","","49","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Optimizing Multimedia IoT Gateway for Enhanced Performance, Energy Efficiency, and Multimedia Quality","S. Vijaykumar; S. P. Thyagaraj","Department of Computer Science Engineering, Vijaya Vittala Institute of Technology, Bengaluru, Karnataka, India; Department of Computer Science Engineering, Vijaya Vittala Institute of Technology, Bengaluru, Karnataka, India","2023 International Conference on Network, Multimedia and Information Technology (NMITCON)","17 Oct 2023","2023","","","01","06","Multimedia Internet-of-Thing (IoT) applications generate a significant amount of traffic due to the nature of multimedia data, which includes audio, video, images, and other high-bandwidth content. These applications require the transmission of large data packets in real-time or near real-time, resulting in increased network traffic and bandwidth requirements. Hence in this work, an IoT gateway optimization that optimizes the RTP, RTCP, and RTSP protocols has been presented. The performance of a proposed model is compared to the BBP model in terms of throughput, energy consumption, and multimedia loss in IoT devices for multimedia applications. The results indicate that the proposed model achieves better throughput and demonstrates higher average performance across different device numbers, enabling faster and more reliable transmission of multimedia data. Additionally, the proposed model outperforms the BBP model in terms of energy consumption, resulting in reduced energy usage even with an increasing number of devices. Moreover, the proposed model significantly reduces multimedia loss, ensuring a seamless and high-performance multimedia experience. These findings highlight the importance of optimizing RTP, RTCP, and RTSP in IoT devices for improved performance, energy efficiency, and enhanced multimedia quality.","","979-8-3503-0082-6","10.1109/NMITCON58196.2023.10276269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10276269","Multimedia;IoT;network traffic;RTP;RTCP;RTSP","Performance evaluation;Energy consumption;Adaptation models;Streaming media;Throughput;Energy efficiency;Real-time systems","","","","26","IEEE","17 Oct 2023","","","IEEE","IEEE Conferences"
"Blockchain Applications in Smart Grid Systems","M. Abaas; P. Singh; R. Lee","College of Engineering, Villanova University, Villanova, PA, USA; College of Engineering, Villanova University, Villanova, PA, USA; College of Engineering, Villanova University, Villanova, PA, USA",2020 52nd North American Power Symposium (NAPS),"21 Jun 2021","2021","","","1","6","Blockchain has been implemented in several application in smart grid systems, such as data management and cybersecurity in utility grid systems. In addition, blockchain has been deployed in peer-to-peer electricity trading in microgrid systems. Due to the promising Blockchain features, it is considered as a good fit for energy trading. However, Blockchain applications in power grids are in their infancy so there are many research opportunities in this field. This paper reviews the existing applications of Blockchain in power grids and suggests some new opportunities for applying this technology, especially in enhancing the resiliency of power grids.","","978-1-7281-8192-9","10.1109/NAPS50074.2021.9449754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449754","Blockchain;Cybersecurity;Data Management;Energy Trading;Smart Grid;Power Grid Resilience","Power system dynamics;Memory;Blockchain;Microgrids;Power markets;Smart grids;Peer-to-peer computing","","3","","34","IEEE","21 Jun 2021","","","IEEE","IEEE Conferences"
"Knowledge and Data Management: The Cornerstone of Effective Organizational Strategy","M. Rajić; P. Milosavljević; Z. Kostić","Department of Management in Mechanical Engineering, Faculty of Mechanical Engineering, University of Niš Niš, Serbia; Department of Management in Mechanical Engineering, Faculty of Mechanical Engineering, University of Niš Niš, Serbia; Department of Management in Mechanical Engineering, Faculty of Mechanical Engineering, University of Niš Niš, Serbia","2023 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)","11 Dec 2023","2023","","","1","7","In the modern business landscape, organizations operate in highly complex and dynamic environments, facing constant challenges in maximizing efficiency, sustainability, and profitability. To achieve success, businesses must harness and leverage knowledge and data effectively. Knowledge and Data Management are important in shaping an organization's strategy. By maintaining a knowledge repository and implementing collaborative platforms, businesses can avoid duplicating efforts, reduce errors, and develop strategies with a long-term vision. The seamless transfer of knowledge from experienced employees to new hires also ensures the preservation of critical expertise, further improving an organization's competitive advantage. The effective utilization of data is crucial to optimize energy consumption, reduce costs, make processes more sustainable, and consequently minimize environmental impact. Energy-intensive industries must carefully monitor and analyse data related to energy consumption, production processes, and equipment efficiency to identify opportunities for improvement, energy management, and industrial management, serving as the base for informed decision-making and sustainable growth. This paper explores the interconnectedness of these key areas and how they can be improved through effective knowledge and data management practices.","","979-8-3503-1324-6","10.1109/BdKCSE59280.2023.10339774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10339774","knowledge;data management;organization strategy;industrial management;energy management","Industries;Energy consumption;Uncertainty;ISO Standards;Standards organizations;Decision making;Organizations","","","","41","IEEE","11 Dec 2023","","","IEEE","IEEE Conferences"
"Data Analytics Functions and Practices in Electric Distribution Utilities Management-A New Perspective","R. Veerlapati; R. Thota","Electrical & Electronics Engineering Department, Kits Warangal, Telangana, India; E.E.E,Department Warangal, Vaagdevi College of Engineering, Telangana, India",2021 International Conference on Intelligent Technologies (CONIT),"4 Aug 2021","2021","","","1","6","Across the whole execution of the Smart-grids, data processing plays a significant part. Intelligent grids are strengthened by activities such as data analytics, highperformance assessment, appropriate management of data networks, and the internet of things.In this modern world, intelligent meters achieve an enormous amount of data through practical mechanisms and strategies. Intelligent energy meter deployments have generated a vast quantity of data at various periods, which indicates that clustering, demand projections, optimum energy efficiency, energy management, tracking, and diagnostics need data analyzing. In dealing with problems in the execution of emerging technology, data analysis slowly becomes an essential part of several industrial sectors. This article emphasizes the issues of data analytics and the obstacles posed by the smart-grid integrated energy sources. A comprehensive overview of mostly applied data processing approaches and a concise summary of widely used data management strategies, as well as a suggestion for potential recommendations on the issue. The article explains how electric utilities will benefit from combining current and emerging forms of data and data analytics and explore how data collection approaches may be utilized for power big-data distribution planning.","","978-1-7281-8583-5","10.1109/CONIT51480.2021.9498302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498302","Smart-Grid;Data Analytics;Big Data;Power Grid;Distribution Management","Meters;Support vector machines;Data analysis;Systems architecture;Big Data;Regulation;Smart grids","","","","11","IEEE","4 Aug 2021","","","IEEE","IEEE Conferences"
"EXPRESS: An Energy-Efficient and Secure Framework for Mobile Edge Computing and Blockchain based Smart Systems","J. Xu; X. Liu; X. Li; L. Zhang; Y. Yang","School of Computer Science and Technology, Anhui University, Hefei, China; School of Information Technology, Deakin University, Geelong, Australia; School of Computer Science and Technology, Anhui University, Hefei, China; Antwork Robotics Co., Ltm., Hangzhou, China; School of Software and Electrical Engineering, University of Technology, Melbourne, Australia",2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE),"24 Dec 2020","2020","","","1283","1286","As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.","2643-1572","978-1-4503-6768-4","","National Natural Science Foundation of China(grant numbers:61972001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286009","Smart System Framework;Mobile Edge Computing;Blockchain;Computation Management;Data Management","Systems architecture;Blockchain;Unmanned aerial vehicles;Energy efficiency;Edge computing;Software engineering;Smart manufacturing","","9","","9","","24 Dec 2020","","","IEEE","IEEE Conferences"
"From silos to open, federated and enriched Data Lakes for smart building data management","J. L. Hernández; S. Martín; V. Marinakis; I. de Miguel","Energy division, CARTIF Technology Centre, Boecillo, Spain; Energy division, CARTIF Technology Centre, Boecillo, Spain; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Universidad de Valladolid, Valladolid, Spain",2023 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv),"4 Jul 2023","2023","","","29","33","Current building data is treated as silos from the different building domains. However, this provokes the lack of cross-domain data mixture to provide added-value services, mainly due to lack of interoperability. Data quality is also an issue when collecting data from buildings. The proposed data lake aims to solve these challenges by considering the whole data life-cycle to ensure minimum data quality requirements, providing high-quality services to make better-informed decisions. Heterogeneous building-related data is thus combined to enrich the information, being able to address multiple stakeholders in the smart building context. The data lake is being deployed in the DigiBUILD project, where data from 10 pilots with different purposes are collected to demonstrate the capability and benefits of its application.","","978-1-6654-5693-7","10.1109/MetroLivEnv56897.2023.10164046","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164046","data lake;data quality;standards;ontologies;smart buildings","Smart buildings;Data integrity;Conferences;Ontologies;Metrology;Big Data applications;Stakeholders","","3","","18","IEEE","4 Jul 2023","","","IEEE","IEEE Conferences"
"SSDe: FPGA-Based SSD Express Emulation Framework","Y. Lu; L. Yu; D. Chen","Coordinated Science Laboratory, University of Urbana-Champaign, Illinois; Coordinated Science Laboratory, University of Urbana-Champaign, Illinois; Coordinated Science Laboratory, University of Urbana-Champaign, Illinois",2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD),"30 Nov 2023","2023","","","1","9","Solid State Drives (SSDs) are crucial for modern high-performance computing (HPC) and cloud services, providing superior speed and reliability. Two prominent approaches for mirroring SSD behavior are SSD emulation and simulation. Using specialized hardware, emulation outperforms simulation in speed and efficiency, especially in Hardware-in-the-Loop (HIL) testing and design space exploration (DSE) for cloud service systems. FPGA-based SSD emulation further enhances the accurate emulation of smartSSDs, devices consisting of SSD and FPGA components. Despite their merits, current SSD emulators encounter difficulties meeting these applications' demands. Many are limited by their underlying hardware platforms, impeding their capacity to emulate the full array of SSD behaviors. Some emulators are primarily devised for testing and validating new SSD designs rather than emulating existing, commercially-available SSDs. To address this, we introduce SSDe, an FPGA-based SSD Express emulator that accurately emulates the Non-Volatile Memory Express (NVMe) SSDs. SSDe, a next-generation SSD emulator built on top of FSSD [1] (a previous FPGA-based SSD emulator we developed), brings in additional capabilities such as energy modeling, garbage collection, and runtime reconfiguration. These features enhance its efficiency in managing diverse emulation tasks, making SSDe a more flexible and efficient emulator than both FSSD and traditional software simulators. SSDe achieves an average error of 14.1% in bandwidth and 18% in energy modeling, while its runtime parameter reconfiguration for DSE study takes less than 0.1 seconds (2.36 $\times 10^{5}$ times faster than FSSD). SSDe stands as a new and robust SSD emulator, offering new opportunities for optimizing HPC and cloud infrastructures.","1558-2434","979-8-3503-2225-5","10.1109/ICCAD57390.2023.10323737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323737","SSD Emulator;FPGA;Design Space Exploration;Energy Modeling;Garbage Collection;Runtime Reconfiguration","Runtime;Nonvolatile memory;Solid state drives;Computational modeling;Emulation;Hardware;Space exploration","","","","49","IEEE","30 Nov 2023","","","IEEE","IEEE Conferences"
"Physiological Signal Monitoring for Identification of Emotional Dysregulation in Children","C. B. Redd; D. Silvera-Tawil; D. Hopp; D. Zandberg; A. Martiniuk; C. Dietrich; M. K. Karunanithi","The Australian e-Health Research Centre, CSIRO, Brisbane, Australia; The Australian e-Health Research Centre, CSIRO, Brisbane, Australia; Royal Far West, Sydney, Australia; Cerebral Palsy Alliance, Sydney, Australia; Royal Far West, Sydney, Australia; SADA Systems, Seattle, USA; The Australian e-Health Research Centre, CSIRO, Brisbane, Australia",2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"27 Aug 2020","2020","","","4273","4277","Children, particularly those with atypical or delayed development, have a reduced ability to self-regulate their emotions and behaviour. After a number of anxiety or stress provoking events, this reduced regulatory ability can result in a meltdown. Extrinsic signals of an impending meltdown are often recognised and acted on by clinicians or parents. These external indications are also accompanied by internal physiological changes, such as increase in heart rate, skin electrodermal activity, and skin temperature. These physiological signals may be used to predict impending meltdown events and facilitate earlier and effective carer intervention, especially in complex management cases. We present a preliminary study using a wearable sensor system for continuous monitoring of physiological signals to measure and predict emotional changes in school-aged children. Our models are able to correctly classify the behavioural state of a child with 68% mean global model accuracy and up to 85% for person-dependent models. Prediction of emotion and identification of impending meltdowns will potentially assist parents, carers, teachers and clinicians to manage stress and problem behaviours before they escalate, and support self-management strategies throughout the variety of normal daily life.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9176506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176506","","Biomedical monitoring;Pediatrics;Monitoring;Temperature measurement;Stress;Skin;Australia","Anxiety Disorders;Caregivers;Child;Emotions;Humans;Monitoring, Physiologic;Problem Behavior","10","","24","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"A dataflow architecture with distributed control for DNN acceleration","H. Krichene; R. Prasad","CEA, List, Université Paris-Saclay, Palaiseau, France; CEA, List, Université Paris-Saclay, Palaiseau, France",2024 13th Mediterranean Conference on Embedded Computing (MECO),"3 Jul 2024","2024","","","1","4","The increasing demand for edge computing requires effective Deep Neural Network (DNN) accelerators that are suitable for resource-limited environments. This paper presents a new method that uses distributed control methodology for DNN acceleration on edge devices. Our architecture offers significant improvements over a similar architecture without such feature, including a remarkable reduction in memory requirements by up to 7×, along with notable speedups of up to 7.42× in DNN processing. Additionally, our design reaches energy efficiency of a maximum of 4300 MOPS/W, demonstrating its potential to address resource constraints while improving DNN performance on edge platforms.","2637-9511","979-8-3503-8756-8","10.1109/MECO62516.2024.10577802","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577802","Distributed control;DNN;dataflow architecture","Performance evaluation;Embedded computing;Memory management;Decentralized control;Distributed databases;Artificial neural networks;Energy efficiency","","","","9","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"Empowering Intermittent IoT Networks","S. R. Karthic V; Y. M; S. E; H. P. P; M. S. P","Department of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Department of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Department of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Department of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Department of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India",2024 International Conference on Science Technology Engineering and Management (ICSTEM),"25 Jun 2024","2024","","","1","6","Internet of Things (IoT) forms a network of interconnected devices that generate data and process them on cloud. From about 8.6 billion active IoT devices in 2019, a recent survey shows that, at present there are over 15.1 billion IoT devices connected worldwide. The number of active IoT devices is expected to double by 2030. The primary aim of such devices is to automate various processes and to reduce human labor. For generating legitimate data, any IoT device requires sufficient power and uninterrupted communication. Some of these devices may also be placed at remote unserviceable locations. Hence, these devices are gradually adopting battery-less, energy harvesting solutions leading to Transiently Powered embedded systems. These represent a novel category of embedded systems relying exclusively on energy harvested from external sources to perform long-running computations. Performing complex computations require sufficient memory and a stable power source. Enabling long-running computations on these systems is a major challenge due to highly intermittent nature of the power supply, resulting in frequent system reboots. While distributed task concurrency holds promise for intermittent networks, data unavailability due to frequent failures poses a challenge. The maj or challenge faced by energy harvesting devices is that due to the fluctuating nature of the power supply, the communication between interconnected IoT devices are interrupted, leading to loss of data and degrades the computation progress. The proposed work introduces a novel approach to improve the forward computation progress and ensures that no data loss occurs while performing large computations in an intermittent network. The future scope is to distribute a long running process among various devices in an intermittent network by also ensuring that there is no loss or duplication of data.","","979-8-3503-7691-3","10.1109/ICSTEM61137.2024.10560786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10560786","Intermittent networks;Energy harvesting;Data unavailability;Frequent system failures;Computation progress;Distributed task concurrency;Internet of Things;Checkpointing;Data recovery","Performance evaluation;Concurrent computing;Checkpointing;Cloud computing;Embedded systems;Power supplies;Distributed databases","","","","10","IEEE","25 Jun 2024","","","IEEE","IEEE Conferences"
"f-HybridMem: A Fuzzy-based Approach for Decision Support in Hybrid Memory Management","R. C. de Moura; G. B. Schneider; L. de Souza Oliveira; M. L. Pilla; A. C. Yamin; R. H. S. Reiser","Laboratory of Ubiquitous and Parallel Systems (LUPS), Federal University of Pelotas, Pelotas, Brazil; Laboratory of Ubiquitous and Parallel Systems (LUPS), Federal University of Pelotas, Pelotas, Brazil; Laboratory of Ubiquitous and Parallel Systems (LUPS), Federal University of Pelotas, Pelotas, Brazil; Laboratory of Ubiquitous and Parallel Systems (LUPS), Federal University of Pelotas, Pelotas, Brazil; Laboratory of Ubiquitous and Parallel Systems (LUPS), Federal University of Pelotas, Pelotas, Brazil; Laboratory of Ubiquitous and Parallel Systems (LUPS), Federal University of Pelotas, Pelotas, Brazil",2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),"26 Aug 2020","2020","","","1","8","In the Hybrid Memory research approach, the development of new storing data strategies combines the traditional volatile memories (DRAM) with the emerging non-volatile memory (NVM) to take advantage of their potential and best features. One question in the hybrid memory research is the decision of which memory technology to use in order to store data of distinct applications. These decision processes have to examine the behavior of memory operations, such as read/write frequency, and also their memory characteristics. Also, considering the large volume of parameters and the uncertainties inherent in the data migration, the decision to store data in hybrid memories is not a trivial task. This paper presents the f-HybridMem component, a fuzzy-based system to support the uncertainty in data management for hybrid memory architectures. Thus, this proposal contributes to determine a correct selection between memory modules by improving the data management, in a page level organization. The memory management takes into account the behavior of memory operations and the memory characteristics. Such architecture is conceived based on the following modules: (i) Access Updater, a hardware module to identify the pages access patterns, and (ii) f-HybridMem component, a fuzzy-based software module supporting the migration decision processes. In addition, tests are conducted attempt evaluating the accuracy of the fuzzy-based system. Moreover, the proposed evaluations aim to estimate the influence of the following parameters: Buffer Size, Counters Size, Frequency of Migration, Promote Value, Demote Value, providing a correct recommend for data migrations.","1558-4739","978-1-7281-6932-3","10.1109/FUZZ48607.2020.9177585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177585","Decision analysis;Decision Support;Hybrid memory;Memory Management;Fuzzy Logic Application","Random access memory;Nonvolatile memory;Memory management;Phase change materials;Energy consumption;Memory architecture","","3","","45","IEEE","26 Aug 2020","","","IEEE","IEEE Conferences"
"Towards an Autonomous, Power-Efficient Base Station for Sensor Data Collection","P. -L. Sixdenier","Friedrich-Alexander- Universität Erlangen-Nürnberg (FAU), Erlangen, Germany",2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C),"18 Nov 2021","2021","","","313","315","For a bio-monitoring project called AMMOD, we have to design an autonomous station powered by solar panels that gathers samples from sensors in remote places and transmit them to the cloud. In this paper, we give a brief overview of our research on designing an autonomous, self-managing base station to operate heterogeneous sensors and manage their data in a power-efficient and self-sustained way.","","978-1-6654-4393-7","10.1109/ACSOS-C52956.2021.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599272","autonomous-system;iot;data-compression;power-management;data-transmission","Base stations;Cloud computing;Conferences;Data collection;Sensor systems;Sensors;Solar panels","","","","7","IEEE","18 Nov 2021","","","IEEE","IEEE Conferences"
"Trustworthy Artificial Intelligence in the Energy Sector: Landscape Analysis and Evaluation Framework","S. Pelekis; E. Karakolis; G. Lampropoulos; S. Mouzakitis; O. Markaki; C. Ntanos; D. Askounis","School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece","2024 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)","18 Dec 2024","2024","","","1","10","The present study aims to evaluate the current fuzzy landscape of Trustworthy AI (TAl) within the European Union (EU), with a specific focus on the energy sector. The analysis encompasses legal frameworks, directives, initiatives, and standards like the AI Ethics Guidelines for Trustworthy AI (EGTAI), the Assessment List for Trustworthy AI (ALTAI), the AI act, and relevant CEN-CENELEC standardization efforts, as well as EU-funded projects such as AI4EU and SHERPA. Subsequently, we introduce a new TAl application framework, called E-TAl, tailored for energy applications, including smart grid and smart building systems. This framework draws inspi-ration from EGTAI but is customized for AI systems in the energy domain. It is designed for stakeholders in electrical power and energy systems (EPES), including researchers, developers, and energy experts linked to transmission system operators, distribution system operators, utilities, and aggregators. These stakeholders can utilize E-TAl to develop and evaluate AI services for the energy sector with a focus on ensuring trustworthiness throughout their development and iterative assessment processes.","2693-8855","979-8-3503-6243-5","10.1109/ICE/ITMC61926.2024.10794222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794222","AI;trustworthy AI;AI act;ethics guidelines for trustworthy AI;ALTAI;assessment;evaluation;practice;regulation;energy sector","Technological innovation;Smart buildings;Law;Europe;Smart grids;Stakeholders;Iterative methods;Artificial intelligence;Standards;Guidelines","","","","76","IEEE","18 Dec 2024","","","IEEE","IEEE Conferences"
"Opportunities, Challenges, and Benefits of 5G-IoT toward Sustainable Development of Green Smart Cities (SD-GSC)","N. A B; D. Pradhan; S. S. Jambli","Dept. Of Electronics & Communication, Engineering Acharya Institute of Technology, Bangalore, India; Dept. Of Electronics & Communication, Engineering Acharya Institute of Technology, Bangalore, India; Dept. Of Electronics & Communication, Engineering Acharya Institute of Technology, Bangalore, India",2023 3rd International Conference on Intelligent Technologies (CONIT),"7 Aug 2023","2023","","","1","8","This article provides an overview of the opportunities, challenges, and benefits of the 5G-IoT (Internet of Things) ecosystem toward the sustainable development of Green Smart Cities (GSC). The authors first describe the key characteristics and requirements of GSCs, which aim to promote environmental sustainability, economic growth, and social well-being through the integration of advanced technologies and innovative approaches. They then discuss the potential of 5G-IoT to enable the deployment of GSCs at scale, by providing high-speed, low-latency, and reliable connectivity to a wide range of devices and applications. There are several key opportunities and benefits of 5G-IoT for GSCs, including improved energy efficiency, enhanced transportation, smarter buildings, and better public safety and healthcare. They also discuss some of the key challenges associated with the deployment of 5G-IoT in GSCs, such as security and privacy concerns, interoperability issues, and the need for effective governance and collaboration among stakeholders. This paper highlight the importance of a holistic and inclusive approach to the development of GSCs, which involves engaging all stakeholders, including citizens, businesses, governments, and non-governmental organizations (NGOs), in the design and implementation of smart city solutions.","","979-8-3503-3860-7","10.1109/CONIT59222.2023.10205780","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10205780","IOT;5G;GSC;ICT","Smart cities;Green buildings;Government;Buildings;Collaboration;Transportation;Safety","","1","","20","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"LoRa Tunnel Worker Wellness Management System","G. Banu; S. Dhas Bensam; D. Priyadharshini; D. Velmurugan","Department of EEE, VSB College of Engineering Technical Campus Coimbatore, Tamilnadu, India; Department of EEE, VSB College of Engineering Technical Campus Coimbatore, Tamilnadu, India; Department of EEE, VSB College of Engineering Technical Campus Coimbatore, Tamilnadu, India; Department of EEE, VSB College of Engineering Technical Campus Coimbatore, Tamilnadu, India",2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI),"4 Oct 2024","2024","","","126","131","The coal mining industry is characterized by challenging working conditions, which pose risks to the health and safety of employees. This project presents a comprehensive health monitoring and emergency alert system designed to address these concerns among coal mine employees. The proposed system comprises of two sections one to monitor the mineworker status and another one is the total monitoring section. In the mine labourer area, air contamination is primarily due to the outflows because of emissions of particulate matter and gases incorporate such as Sulphur dioxide (SO2), Nitrogen dioxide (NO2), Carbon monoxide (CO). To monitor the concentration level of unsafe gases, semiconductor gas sensors are utilized. The system integrates various sensors, including temperature sensors and MQ135 gas sensors, to monitor environmental conditions within the coal mine continuously. Additionally, it incorporates an emergency button that, when pressed, triggers an immediate alert message. All collected data and emergency alerts are transmitted wirelessly through a LoRa (Long-Range) communication system from LoRa transmitters (Tx) to LoRa receivers (Rx).","","979-8-3315-4066-1","10.1109/ICoICI62503.2024.10696473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696473","Lora Tunnel;Management system;Health Monitoring;wireless System;Sensors;GSM","Temperature sensors;Temperature measurement;Industries;Transmitters;LoRa;Coal mining;Sulfur;Sustainable development;Monitoring;Gas detectors","","","","14","IEEE","4 Oct 2024","","","IEEE","IEEE Conferences"
"Blockchain-Based Security Architecture for Unmanned Aerial Vehicles in B5G/6G Services and Beyond: A Comprehensive Approach","S. K. Jagatheesaperumal; M. Rahouti; A. Chehri; K. Xiong; J. Bieniek","Department of Electronics and Communication Engineering, Mepco Schlenk Engineering College, Sivakasi, Tamil Nadu, India; Department of Computer and Information Sciences, Fordham University, New York, NY, USA; Royal Military College of Canada (RMC), Kingston, Ontario, Canada; Cyber Florida and ICNS Lab, University of South Florida, Tampa, FL, USA; Department of Computer and Information Sciences, Fordham University, New York, NY, USA",IEEE Open Journal of the Communications Society,"","2025","PP","99","1","1","Unmanned Aerial Vehicles (UAVs) were popularly used by hobbyists in the past, but they have now become critical enablers for managing disasters, handling emergencies, and so on. For example, one of their most critical applications is to provide seamless wireless communication services in remote rural areas. Thus, it is substantial to identify and consider the different security challenges in the research and development associated with advanced UAV-based B5G/6G architectures. Catering to this requirement, this article conducts a comprehensive review of the security aspects of UAVs with respect to the 5G/6G system architecture, its enabling technologies, and privacy issues. It exhibits security integration at all the protocol stack layers and analyzes the existing mechanisms to secure UAV-based B5G/6G communications and its energy and power optimization factors. Last, this article also summarizes modern technological trends for establishing security and protecting UAV-based systems, along with the open challenges and strategies for future research work.","2644-125X","","10.1109/OJCOMS.2025.3528220","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2022-3256); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10855475","Unmanned Aerial Vehicle;B5G/6G Communication;Security;Energy;Artificial Intelligence;IoT","Security;Autonomous aerial vehicles;Blockchains;Surveys;Wireless communication;5G mobile communication;Internet of Things;Communication system security;Navigation;Energy efficiency","","","","","CCBY","27 Jan 2025","","","IEEE","IEEE Early Access Articles"
"Precision-Aware Data Management in Federated Cloud Environments: A Context-Aware Approach","V. K. Kolekar; S. R. Sakhare","Department of Computer Engineering, SMT. Kashibai Navale College of Engineering, Pune; Department of Computer Engineering, Vishwakarma Institute of Information Technology, Pune, INDIA",2023 3rd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"18 Apr 2024","2023","","","1211","1214","In the ever-evolving world of cloud computing, the management of data in federated cloud environments presents a complex challenge. Presented study investigates precision-aware data management techniques with the goal of improving the efficiency of federated cloud systems. Our work acknowledges the crucial significance of context-awareness in enhancing data operations and introduces an adaptive data management middleware. The precision-aware system caters to the requirement for accuracy and reliability in data processing by integrating sophisticated algorithms and techniques. Simultaneously, the integration of context-awareness ensures that data management strategies dynamically adapt to the changing contextual conditions within federated cloud environments. This strategy has two aspects, first to increase the accuracy of data operations and second to improve the overall responsiveness and adaptability of the system. Our study focuses on creating innovative middleware that can effortlessly integrate precision-aware and context-aware features. We assess the effectiveness of the proposed system by conducting empirical evaluations and analyzing real-world use cases. Our findings demonstrate that the system is capable of optimizing data management in diverse and dynamic federated cloud contexts. The results of this study enhance the progress of adaptive data management approaches by providing a detailed comprehension of the interaction between precision and context in federated cloud environments. Proposed work is important for research scholars, practitioners, and industry experts who are looking for creative ways to improve the performance and adaptability of data management systems in complex cloud environments.","","979-8-3503-4363-2","10.1109/ICIMIA60377.2023.10426563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426563","Data management;Federated cloud environments;Context-awareness;Precision-awareness;Adaptive middleware","Industries;Cloud computing;Systematics;System performance;Data processing;Reliability;Middleware","","","","13","IEEE","18 Apr 2024","","","IEEE","IEEE Conferences"
"Using Context-Awareness for Storage Services in Edge Computing","R. Pérez-Torres; C. Torres-Huitzil; T. Truong; D. Buckley; C. J. Sreenan","School of Computer Science & IT, University College Cork, Cork, Ireland; School of Engineering and Sciences, Instituto Tecnológico y de Estudios Superiores de Monterrey—Campus Puebla, Puebla, Mexico; OCTO Research and Strategy Office, Dell EMC Research Europe, Cork, Ireland; OCTO Research and Strategy Office, Dell EMC Research Europe, Cork, Ireland; School of Computer Science & IT, University College Cork, Cork, Ireland",IT Professional,"31 Mar 2021","2021","23","2","50","57","Modern mobile networks face a dynamic environment with massive devices and heterogeneous service expectations that will need to significantly scale for 5G. Edge computing approaches aim at enhancing scalability through strategies like computation offloading and local storage services, which will be fundamental to deploying large-scale distributed applications. Unlike the cloud, edge resources are limited, which call for novel techniques to handle large volumes of up- and downstream data under a changing environment. Being closer to data consumers and producers, a compelling view is to adopt context-aware techniques for enabling the edge to work with patterns from mobile traffic at different spatiotemporal scales. In this article, we overview the challenges and opportunities of edge storage from the perspective of context-awareness. We introduce a conceptual architecture to learn and exploit context information for enhancing uplink and downlink scenarios. Finally, we outline future directions for edge applications.","1941-045X","","10.1109/MITP.2020.3043164","Science Foundation Ireland (SFI); European Regional Development Fund(grant numbers:13/RC/2077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391745","","Scalability;Computer architecture;Downlink;Spatiotemporal phenomena;Planning;Uplink;Edge computing","","1","","17","IEEE","31 Mar 2021","","","IEEE","IEEE Magazines"
"Efficient Newton-Raphson Power Flow with Parallel Jacobian Construction","M. A. Kuyumcu; C. Gavriluta; A. Benigni","Power and Renewable Gas Systems, Austrian Institute of Technology, Vienna, Austria; Power and Renewable Gas Systems, Austrian Institute of Technology, Vienna, Austria; Institute of Energy and Climate Research, Forschungszentrum Jülich, Jülich, Germany",2024 Open Source Modelling and Simulation of Energy Systems (OSMSES),"16 Sep 2024","2024","","","1","7","This paper presents a novel node-level data localization approach to reduce the time spent on the Jacobian building step of the Newton-Raphson Power Flow problem on CPUs. By leveraging the sparsely connected graph structure of the electrical network, we package the data of a network bus and its immediate neighbors and structure the computations to reuse data. This reduces the overhead associated with random memory accesses on GPU and CPU architectures. We demonstrate the effectiveness of our method on large-scale power networks, achieving a 16.8x speedup for Jacobian matrix building compared to Matpower on a 25,000-bus network.","","979-8-3503-8468-0","10.1109/OSMSES62085.2024.10668985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10668985","Newton-Raphson;Power Flow;CPU;OpenMP;Parallel","Jacobian matrices;Location awareness;Architecture;Buildings;Graphics processing units;Computer architecture;Newton method","","","","28","IEEE","16 Sep 2024","","","IEEE","IEEE Conferences"
"A Case Study of Data Management Challenges Presented in Large-Scale Machine Learning Workflows","C. S. Lee; V. Hewes; G. Cerati; J. Kowalkowski; A. Aurisano; A. Agrawal; A. Choudhary; W. -K. Liao",Northwestern University; University of Cincinnati; Fermi National Accelerator Laboratory; Fermi National Accelerator Laboratory; University of Cincinnati; Northwestern University; Northwestern University; Northwestern University,"2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)","10 Jul 2023","2023","","","71","81","Running scientific workflow applications on high-performance computing systems provides promising results in terms of accuracy and scalability. An example is the particle track reconstruction research in high-energy physics that consists of multiple machine-learning tasks. However, as the modern HPC system scales up, researchers spend more effort on coordinating the individual workflow tasks due to their increasing demands on computational power, large memory footprint, and data movement among various storage devices. These issues are further exacerbated when intermediate result data must be shared among different tasks and each is optimized to fulfill its own design goals, such as the shortest time or minimal memory footprint. In this paper, we investigate the data management challenges presented in scientific workflows. We observe that individual tasks, such as data generation, data curation, model training, and inference, often use data layouts only best for one's I/O performance but orthogonal to its successive tasks. We propose various solutions by employing alternative data structures and layouts in consideration of two tasks running consecutively in the workflow. Our experimental results show up to a 16.46x and 3.42x speedup for initialization time and I/O time respectively, compared to previous approaches.","","979-8-3503-0119-9","10.1109/CCGrid57682.2023.00017","U.S. Department of Energy(grant numbers:DE-SC0021399,DE-SC0019358); National Institute of Standards and Technology(grant numbers:70NANB19H005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10171505","Data Management;Parallel I/O;HDF5;High Performance Computing;Machine Learning;Scientific Workflows","Training;Costs;Tracking;Scalability;Layout;Memory;Machine learning","","1","","38","IEEE","10 Jul 2023","","","IEEE","IEEE Conferences"
"TizenRT OS Based Data Compression Algorithms for IoT Devices","T. R. Chamak; S. Kaushik; S. Singhal; A. Dadheech; P. A. Anitha; P. S. Jenicka; V. Thapa","School of Computer Science Engineering and Information, Systems Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science Engineering and Information, Systems Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science Engineering and Information, Systems Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science Engineering and Information, Systems Vellore Institute of Technology, Vellore, Tamil Nadu, India; Samsung Research Institute, Bangalore, Karnataka, India","2023 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)","15 Feb 2024","2023","","","992","997","The paper investigates the integration and adaptation of the LZ4 compression algorithm within the context of TizenRT, in addition to existing algorithms Miniz and LZMA. TizenRT, a real-time operating system tailored for Internet of Things (IoT) devices, presents unique challenges in balancing compression efficiency and resource constraints. The study evaluates the performance of LZ4 alongside Miniz and LZMA in terms of compression ratios, processing overhead, and memory utilization. Experimental results demonstrate the feasibility of LZ4's adoption in TizenRT, highlighting its potential to enhance data compression and decompression operations while adhering to the stringent requirements of IoT devices. The findings contribute to the optimization of data management strategies within the TizenRT ecosystem.","","979-8-3503-0611-8","10.1109/ICCCIS60361.2023.10425386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425386","TizenRT;RTOS;IoT;Miniz;LZMA;LZ4;Lossless Compression","Performance evaluation;Operating systems;Data compression;Real-time systems;Internet of Things;Intelligent systems;Optimization","","","","18","IEEE","15 Feb 2024","","","IEEE","IEEE Conferences"
"Design and Testing of Low Power Cache Memory","S. K. Shetty; E. Mohapatra","Dept. of Electronics & Communication, RV college of engineering, Bengaluru, India; Dept. of Electronics & Communication, RV college of engineering, Bengaluru, India",2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS),"1 Jan 2025","2024","","","1","5","In Integrated Circuit (IC) design, low-power cache memory with dft and scan chain techniques is essential for ensuring efficient and reliable operation. These techniques integrate testing capabilities directly into the cache memory, eliminating the need for external test equipment and enabling automatic testing. This approach is cost-effective and crucial for maintaining the quality and reliability of ICs throughout production and their operational lifespan. The benefits of using DFT and scan chains include faster testing, reduced production costs, improved product reliability, and enhanced manufacturing efficiency. The implementation of low-power techniques, including clock gating, resulted in a significant power reduction. The total power of the proposed Low Power Cache Memory design is 20% less than the standard Cache Memory Design. Simulations and synthesis were conducted using Cadence Genus, with physical design and verification completed using Cadence Innovus. Further efficiency gains could be achieved by adopting advanced low-power design methods and integrating machine learning for dynamic power management and adaptive testing in the cache memory.","2767-1097","979-8-3315-0546-2","10.1109/CSITSS64042.2024.10817017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817017","DFT;IC;DRC;RTL;SRAM","Energy consumption;System performance;Cache memory;Discrete Fourier transforms;Production;Very large scale integration;Test equipment;Standards;Testing;Clocks","","","","12","IEEE","1 Jan 2025","","","IEEE","IEEE Conferences"
"The Role of IoT in Sustainable Digital Transformation: Applications and Challenges","A. Alrefai; R. ElBanna; C. Al Ghaddaf; I. A. Abu-AlSondos; E. M. Chehaimi; I. A. Alnajjar","College of Business Administration, American University in the Emirates, Dubai, UAE; College of Business Administration, American University in the Emirates, Dubai, UAE; College of Business Administration, American University in the Emirates, Dubai, UAE; Department of IT Management, American University in the Emirates, Dubai, UAE; Founder & CEO Bright Path United Arab Emirates, Abu Dhabi, UAE; Department of Computer Science, American University in the Emirates, Dubai, UAE",2024 2nd International Conference on Cyber Resilience (ICCR),"22 May 2024","2024","","","1","4","This research paper discusses into exploring how IoT plays a role in driving sustainable digital transformation. IoT is about technologies and devices that come equipped with sensors, software and connectivity enabling the collection, analysis, and exchange of data. This data driven approach implications for enhancing social and environmental sustainability while increasing productivity and efficiency. The paper investigates applications of IoT that have the potential to promote sustainability across sectors. It also examines the challenges and complexities that need to be addressed to fully leverage the potential of IoT for transformation. Through our research efforts in this field the aim is to provide an understanding of where IoT stands today concerning sustainability. The goal is to offer insights, into how technology can drive environmental and economic outcomes.","","979-8-3503-9496-2","10.1109/ICCR61006.2024.10532884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10532884","IoT;Sustainable Digital Transformation;Applications;Sustainability;IoT Devices","Economics;Technological innovation;Supply chain management;Smart cities;Digital transformation;Government;Standards organizations","","","","25","IEEE","22 May 2024","","","IEEE","IEEE Conferences"
"Digital Twin Data Management: A Comprehensive Review","E. B. Ouedraogo; A. Hawbani; X. Wang; Z. Liu; L. Zhao; M. A. A. Al-qaness; S. H. Alsamhi","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science, Shenyang Aerospace University, Shenyang; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; The University of Electro-Communications, Tokyo, Japan; School of Computer Science, Shenyang Aerospace University, Shenyang; College of Physics and Electronic Information Engineering, Zhejiang Normal University, Jinhua, China; insight centre for data analytics, university of Galway, Ireland",IEEE Transactions on Big Data,"","2025","PP","99","1","20","Digital Twins are virtual representations of physical assets and systems that rely on effective Data Management to integrate, process, and analyze diverse data sources. This article comprehensively examines Data Management challenges, architectures, techniques, and applications in the context of Digital Twins. It explores key issues such as data heterogeneity, quality assurance, scalability, security, and interoperability. The paper outlines architectural approaches like centralized, distributed, cloud-based, and blockchain solutions and Data Management techniques for modeling, integration, fusion, quality management, and visualization. Domain-specific considerations across manufacturing, smart cities, healthcare, and other sectors are discussed. Finally, open research challenges related to standards, real-time data processing, intelligent Data Management, and ethical aspects are highlighted. By synthesizing the state-of-the-art, this review serves as a valuable reference for developing robust Data Management strategies that enable Digital Twin deployments.","2332-7790","","10.1109/TBDATA.2025.3533891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10854807","Data integration;data management;data quality;data security;data visualization;digital twin","Digital twins;Data models;Data visualization;Biological system modeling;Reviews;Scalability;Interoperability;Smart cities;Real-time systems;Medical services","","","","","IEEE","27 Jan 2025","","","IEEE","IEEE Early Access Articles"
"Resilience of Cyber-Physical Systems: Role of AI, Digital Twins, and Edge Computing","A. S. Jin; L. Hogewood; S. Fries; J. H. Lambert; L. Fiondella; A. Strelzoff; J. Boone; K. Fleckner; I. Linkov","Sonny Astani Department of Civil and Environmental Engineering, University of Southern California, Los Angeles, CA, USA; United States Army Corps of Engineers, Concord, MA, USA; United States Army Corps of Engineers, Concord, MA, USA; University of Virginia, Charlottesville, VA, USA; University of Massachusetts Dartmouth College of Arts and Sciences, Dartmouth, MA, USA; United States Army Corps of Engineers, Concord, MA, USA; ERDC, United States Army Corps of Engineers, Vicksburg, MS, USA; Artesion Corp., Seattle, WA, USA; United States Army Corps of Engineers, Concord, MA, USA",IEEE Engineering Management Review,"26 Jul 2022","2022","50","2","195","203","Cyber-physical systems encompass multiple system domains (i.e., water, energy, networking) with heterogeneous goals and complexity of interactions. Existing technologies do not address the disparate time and spatial scales across the many system domains, especially with the latest threats and challenge spaces. New methods to manage resilience of systems, including integrating new computing and sensing strategies, machine learning and artificial intelligence, as well as advanced resilience analytics and prediction, are required to ensure that cyber-physical systems can withstand adverse events. This article summarizes the results of the December 2021 Society for Risk Analysis “Workshop on Resilience Analytics: Methodology and Applications to Cyber-Energy Systems” in which a multidisciplinary team of researchers, policymakers, military, and industry professionals met to identify priorities for research.","1937-4178","","10.1109/EMR.2022.3172649","U.S. Department of Defense; National Science Foundation(grant numbers:#1848669); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772938","Cyber-physical systems;resilience;risk analysis","Resilience;Sensors;Sensor systems;Digital twin;Data models;Intelligent sensors;Machine learning","","8","","23","IEEE","11 May 2022","","","IEEE","IEEE Journals"
"Distributed-to-Centralized Data Management: A New Sense of Large-Scale ICT Management of Smart City IoT Networks","A. Sinaeepourfard; J. Krogstie; S. Sengupta","Norwegian University of Science and Technology (NTNU); IDI Department; Fundació i2CAT, Spain",IEEE Internet of Things Magazine,"27 Oct 2020","2020","3","3","76","82","Modern cities are equipped with various information and communications technology (ICT) resources including Internet of Things (IoT) devices, computing platforms, and data storage media. Data are one of the most valuable ICT resources in smart cities. Data management strategies play a vital role in managing the requirements of user and business models in a city. Using the benefits of data makes an agile, creative, and smart city via the widespread use of appropriate city services. Centralized and distributed-to-centralized data management (D2CDM) architectures are recommended to organize the large-scale produced city data in smart city networks, including physical data resources (e.g., sensor data) and nonphysical data sources (e.g., city consumer personal databases). In this article, we explain two different ICT technology management solutions for smart city networks in which the ICT resources in a city can be managed and delivered: centralized and distributed-to-centralized. We also describe two main strategies for data management in smart cities, and the advantages of D2C-DM are discussed based on two ongoing case studies. We also mention there is much room for future works and development of this study, such as developing software services in smart cities based on edge-to-cloud orchestration and enhancing the effectiveness of machine learning (ML) and artificial intelligence (AI) techniques through multilevel ICT architecture.","2576-3199","","10.1109/IOTM.0001.1900038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241477","","Smart cities;Computer architecture;Distributed databases;Cloud computing;Internet of Things;Information and communications technology","","10","","20","IEEE","27 Oct 2020","","","IEEE","IEEE Magazines"
"Smart City Middleware: A Survey and a Conceptual Framework","C. Goumopoulos","Department of Information and Communications Systems Engineering, University of the Aegean, Samos, Greece",IEEE Access,"9 Jan 2024","2024","12","","4015","4047","Smart city middleware serves as a foundational tool in the evolution of urban digitalization, acting as an intermediary software layer that simplifies the development, deployment, and management of applications tailored for smart urban environments. However, the development of effective middleware for smart cities is challenging. The present research embarks on a comprehensive exploration of the smart city middleware landscape, unraveling the intricacies of its development and the challenges faced therein. Rooted in the assessment of 20 distinct middleware solutions, our study highlights the pivotal technologies, features and functionalities that are imperative for a middleware to effectively support a city’s digital transformation. The functional and non-functional requirements form the nucleus of our evaluation. We also explore the architectural styles pivotal to middleware development and the programming paradigms shaping smart city application development. Our study highlights challenges in using middleware for smart city applications, such as interoperability, scalability, security amidst big data, context management, reliability, quality of service, energy efficiency, and compliance with technological standards and regulations. Based on the detailed analysis, we propose a conceptual framework for smart city middleware, shaped by the challenges and requirements identified in existing literature and middleware solutions. This framework is designed to reflect the diverse demands and complexities of urban digital transformation, and guide smart city middleware development accordingly. As a result, this research stands as a reference study for software developers, urban planners, and researchers, outlining the current state and future directions in the domain of smart city middleware.","2169-3536","","10.1109/ACCESS.2023.3349376","University of the Aegean Research Unit through the “Internet of Things-Intelligent Environments in Next-Generation Networks” Project(grant numbers:70477); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10379798","Smart cities;middleware;conceptual framework;surveys;functional and non-functional requirements;enabling technologies;architectural styles;programming paradigms;challenges","Smart cities;Middleware;Software;Surveys;Interoperability;Security;Computer architecture","","9","","123","CCBY","3 Jan 2024","","","IEEE","IEEE Journals"
"Digital Twins: A Comprehensive Study on Models, Platforms, Applications and Challenges","Sneha; P. D. Singh; V. Tripathi","Department of CSE, Graphic Era (Deemed to be University), Dehradun, India; Department of CSE, Graphic Era (Deemed to be University), Dehradun, India; Department of CSE, Graphic Era (Deemed to be University), Dehradun, India",2024 11th International Conference on Computing for Sustainable Global Development (INDIACom),"18 Apr 2024","2024","","","1072","1077","Technological innovation has created “digital twins,” which can replicate and synchronize digital and physical things in (almost) real-time, assess situations from multiple perspectives, and optimize physical objects by predicting how they will behave in the future based on these analyses. This study delves deeply into Digital Twin technology, covering its origins as a game-changing link between the real and the virtual. It explores diverse models, dissecting their functionalities and predictive capacities. Through a comparative lens, it evaluates prominent platforms Oracle Digital Twin, ANSYS Twin Builder, and Siemens Digital Twin - examining their features and adaptability across industries. Extensive applications across Manufacturing, Energy, Automotive, and Logistics underscore the technology’s optimization potential and operational enhancements. Lastly, the study discusses challenges and future perspectives for digital twin technology, offering insight into potential breakthroughs and areas of exploration in this rapidly evolving sector.","","978-93-80544-51-9","10.23919/INDIACom61295.2024.10498975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10498975","digital twins;predictive analysis;comparative evaluation;industries;transformation","Industries;Technological innovation;Transforms;Digital twins;Manufacturing;Finite element analysis;Synchronization","","","","33","","18 Apr 2024","","","IEEE","IEEE Conferences"
"In-depth Exploration of the Present Research Status on Smart Cities","D. Bakir; Z. Chiba; N. Abghour; K. Moussaid; M. Miyara; A. Ouaguid","Mathematics and Computing Department, LIS Labs Faculty of Sciences Ain Chock, Hassan II University, Casablanca, Morocco; Mathematics and Computing Department, LIS Labs Faculty of Sciences Ain Chock, Hassan II University, Casablanca, Morocco; Mathematics and Computing Department, LIS Labs Faculty of Sciences Ain Chock, Hassan II University, Casablanca, Morocco; Mathematics and Computing Department, LIS Labs Faculty of Sciences Ain Chock, Hassan II University, Casablanca, Morocco; Mathematics and Computing Department, LIS Labs Faculty of Sciences Ain Chock, Hassan II University, Casablanca, Morocco; 2IACS Laboratory ENSET of Mohammedia, University Hassan II, Casablanca, Morocco",2024 International Conference on Ubiquitous Networking (UNet),"17 Dec 2024","2024","10","","01","07","Smart cities harness pervasive technology and big data to cultivate more efficient, sustainable, and innovative urban environments. They leverage ubiquitous computing and analytics to monitor and optimize services, resource management, and economic growth. Additionally, smart cities tackle urban challenges like climate change, overcrowding, and resource scarcity through intelligent systems and solutions. In domains such as health, energy, mobility, and agriculture, smart cities utilize sensors, micro-grids, smart vehicles, and other advanced technologies to evaluate conditions, impacts, programs, and strategies. However, these advancements introduce challenges, including data security, privacy concerns, interoperability issues, and infrastructure limitations. By examining research and case studies across these domains, this paper evaluates potential limitations and future directions for smart city development. It aims to contribute to a deeper understanding of smart cities' complexities and provide valuable insights for new research avenues for future scholars.","","979-8-3503-5614-4","10.1109/UNet62310.2024.10794723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794723","smart cities;challenges;health;energy;mobility;agriculture","Economics;Technological innovation;Smart cities;Data security;Ubiquitous computing;Resource management;Intelligent systems;Monitoring;Interoperability;Intelligent sensors","","","","18","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"Database Management Difficulties in the Internet of Things","M. Lourens; A. Tamizhselvi; B. Goswami; J. Alanya-Beltran; M. Aarif; D. Gangodkar","Department of Human Resources Management, Durban University of Technology, Berea, Durban, South Africa; Information Technology; Institute of Business Management, GLA University, Mathura, Uttar Pradesh, India; Department of Electronic, Universidad Tecnológica del Perú, Perú; Shri JJT University, Jhunjhunu, Rajasthan, India; Department of Computer Science & Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India.",2022 5th International Conference on Contemporary Computing and Informatics (IC3I),"22 Mar 2023","2022","","","322","326","The “Internet of Things (IoT)” is an internet protocol for which real-world, virtual as well as digital objects are given recognition, detecting, connectivity, and process technology so they can interact with one another and other Internet-connected devices and services to carry out users’ tasks. There are many IoT solutions available to improve and comfort civilian lives. Additionally, the use of IoT technology in the automotive sector gave rise to the concept of the “Industrial Internet of Things (IIoT),” which has simplified the usage of Cyber Physic Systems, which enable machine and human communication. In general, the variety, heterogeneity, and vast volume of data produced by these businesses make the use of traditional database management systems inappropriate. While constructing IoT data management systems, a number of special issues should be taken into account. These varied guiding notions have led to the proposal of range Of iot data management strategies. The Internet of Things will undoubtedly become a realization as more gadgets are linked to the Internet. Massive amounts of information will be instantiated by items in environment. A high rate and numerous increments will be made to its quantity. This research paper has highlighted database management and its challenges in IoT technology through secondary qualitative analysis.","","979-8-3503-9826-7","10.1109/IC3I56241.2022.10072614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10072614","Internet of Things (IoT);database management;Technology;Big data","Protocols;Database systems;Proposals;Task analysis;Informatics;Physics;Industrial Internet of Things","","4","","17","IEEE","22 Mar 2023","","","IEEE","IEEE Conferences"
"Comparison of Choreography vs Orchestration Based Saga Patterns in Microservices","S. Aydin; C. B. Çebi","Department of Information Technologies, Işık University, Istanbul, Türkiye; Department of Computer Engineering, Işık University, Istanbul, Türkiye","2022 International Conference on Electrical, Computer and Energy Technologies (ICECET)","9 Sep 2022","2022","","","1","6","Microservice Architecture (MSA) is a design and architecture pattern created to deal with the challenges of conventional software programs in terms of stream processing, highly available flexibility, and infrastructural agility. Despite the many advantages of MSA, designing isolated services using the autonomous Databases per Services paradigm is difficult. We realized that because each microservice will have its repository, ensuring data coherence between databases becomes difficult, especially in reversals, where operations transcend different sites. Distributed networked transactions and rollbacks can be efficiently handled using two-phase commitment methods in hardware virtualization using RDBMS databases. However, these approaches can’t be used in micro-services with segregated NoSQL servers. Three issues have been addressed in this study: (i) investigate the implementation of event choreography and orchestration methods for the Saga pattern execution in MSA, (ii) existing reality suggestions on the saga pattern adoption and implementation besides the use cases, and (iii) introduce the disbursed transaction records and rollbacks challenges in isolated No-SQL databases with reliant collections in MSA.","","978-1-6654-7087-2","10.1109/ICECET55527.2022.9872665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9872665","saga pattern;orchestration;microservice architecture;choreography;styling;SQL database","Memory management;Microservice architectures;Distributed databases;Coherence;Software;Hardware;Teamwork","","2","","20","IEEE","9 Sep 2022","","","IEEE","IEEE Conferences"
"Enhancing Retrieval Augmented Generation Systems with Knowledge Graphs","T. Prudhvith; C. Swattik; S. Prakash","Data Science and Insights, Genpact India Private Limited, Bengaluru, India; Data Science and Insights, Genpact India Private Limited, Bengaluru, India; Data Science and Insights, Genpact India Private Limited, Bengaluru, India","2024 International Conference on Electrical, Computer and Energy Technologies (ICECET","8 Oct 2024","2024","","","1","8","Knowledge graphs play a pivotal role in information retrieval, yet their effectiveness can be further optimized. This paper introduces a comprehensive approach to enriching knowledge graphs, addressing contemporary challenges in answering user queries. Our methodology integrates key phrase extraction indulged with a custom prompt to create a Knowledge Graph (KG) with every node connected with each other, node embedding generation w.r.t properties, and an autonomous updating agent during the creation of KG and inference. Furthermore, we explore the incorporation of traditional vector search to enhance contextual understanding. Our experiments demonstrate a substantial improvement in accuracy, reaching approximately 96% compared to traditional KG approaches and our creation of KG process. Notably, the hybrid model sometimes outperforms the Retrieval-Augmented Generation (RAG) system, showcasing the efficacy of the integrated approach. This enhancement is attributed to the methodology proposed coupled with the additional context provided by traditional vector search. The results underscore the significance of our approach in delivering more accurate and contextually relevant information, showcasing the potential of this integrated method in advancing knowledge graph systems.","","979-8-3503-9591-4","10.1109/ICECET61485.2024.10698122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698122","Knowledge Graphs;Key Phrase Extraction;Embeddings;Vector Search;Information Retrieval;GPT4","Electric potential;Accuracy;Knowledge graphs;Information retrieval;Vectors;Hybrid power systems","","","","22","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Characteristics of Simulation: A Meta-Review of Modern Simulation Applications","H. van der Valk; S. Winkelmann; F. Ramge; J. Hunker; K. Langenbach; M. Rabe","Chair for Industrial Information Management, TU Dortmund University, Dortmund, GERMANY; Chair for Industrial Information Management, TU Dortmund University, Dortmund, GERMANY; Chair for Industrial Information Management, TU Dortmund University, Dortmund, GERMANY; Department of IT in Production and Logistics, TU Dortmund University, Dortmund, GERMANY; Department of IT in Production and Logistics, TU Dortmund University, Dortmund, GERMANY; Department of IT in Production and Logistics, TU Dortmund University, Dortmund, GERMANY",2022 Winter Simulation Conference (WSC),"23 Jan 2023","2022","","","2558","2569","Simulation studies enable practitioners and researchers to prove assumptions and hypotheses. Through experiments, they can analyze real-world and conceptual systems. Hence, simulation is an integral part of industrial and scientific work. Nevertheless, simulation applications have to adapt to modern, digitized working changes. As simulation evolves analogously to the industrial world, the scientific world must adjust accordingly, and new research streams for the next steps of simulation's evolution must be defined. This work aims at gathering and exhibiting the properties of recent simulation studies. It provides the groundwork for the definition of research streams for the future of simulation. The paper lays the foundation for prescriptive design knowledge on simulation studies through a structured literature review. Thus, researchers and practitioners are enabled to take on the current challenges of simulation based on a descriptive up-to-date data basis.","1558-4305","978-1-6654-7661-4","10.1109/WSC57314.2022.10015478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10015478","","Adaptation models;Bibliographies;Data models","","2","","35","IEEE","23 Jan 2023","","","IEEE","IEEE Conferences"
"Cloud Computing Infrastructure in Smart Home Devices","R. Roy; N. Sharma","Dept of Computer Science and Engineering, Lovely Professional University, Punjab, India; Dept of Computer Science and Engineering, Lovely Professional University, Punjab, India",2023 Seventh International Conference on Image Information Processing (ICIIP),"28 May 2024","2023","","","677","682","Cloud computing has transformed how we engage with technology. Computer users now have easy access to computing resources via the internet. This inclination is not limited to smart home devices. Smart home devices have become more dominant by means and the use of technology. Internet of Things (IoT) takes grown the popularity, makes our daily lives easier and more efficient. Cloud computing technology provides a chance to increase the performance, usefulness of smart home devices with integration in smart home gadgets. The author has worked and emphasizes the assistances of cloud computing, like as scalability, cost-efficiency, greater storage capacity, along with covering the drawbacks, such as security threats, data privacy concerns, and latency issues. Recent research studies imply that cloud computing can considerably progress the performance of smart home devices by providing greater storage, processing power, and data analytics capabilities. The possible risks associated with cloud computing must be carefully handled to maintain the security and privacy of users’ data has discussed in the paper.","2640-074X","979-8-3503-7140-6","10.1109/ICIIP61524.2023.10537782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537782","Cloud Computing;Smart Home Devices;Internet of Things (IoT);Security risks;Data privacy;Data analytics","Performance evaluation;Cloud computing;Data privacy;Data analysis;Costs;Scalability;Smart homes","","1","","28","IEEE","28 May 2024","","","IEEE","IEEE Conferences"
"AI in Medical Imaging Informatics: Current Challenges and Future Directions","A. S. Panayides; A. Amini; N. D. Filipovic; A. Sharma; S. A. Tsaftaris; A. Young; D. Foran; N. Do; S. Golemati; T. Kurc; K. Huang; K. S. Nikita; B. P. Veasey; M. Zervakis; J. H. Saltz; C. S. Pattichis","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Electrical and Computer Engineering Department, University of Louisville, Louisville, USA; University of Kragujevac, Kragujevac, Serbia; Emory University Atlanta, USA; School of Engineering, The University of Edinburgh, U.K.; Department of Anatomy and Medical Imaging, University of Auckland, Auckland, New Zealand; Department of Pathology and Laboratory Medicine, Robert Wood Johnson Medical School, Rutgers, The State University of New Jersey, Piscataway, USA; U.S. Department of Veterans Affairs Boston Healthcare System, Boston, USA; Medical School, National and Kapodistrian University of Athens, Athens, Greece; Stony Brook University, Stony Brook, USA; School of Medicine, Regenstrief Institute, Indiana University, USA; Biomedical Simulations and Imaging Lab, School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering Department, University of Louisville, Louisville, USA; Technical University of Crete, Chania, Greece; Stony Brook University, Stony Brook, USA; Department of Computer Science of the University of Cyprus, Nicosia, Cyprus",IEEE Journal of Biomedical and Health Informatics,"1 Jul 2020","2020","24","7","1837","1857","This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine.","2168-2208","","10.1109/JBHI.2020.2991043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103969","Medical Imaging;Image Analysis;Image Classification;Image Processing;Image Segmentation;Image Visualization;Integrative Analytics;Machine Learning;Deep Learning;Big Data","Biomedical imaging;X-ray imaging;Magnetic resonance imaging;Computed tomography;Informatics;Three-dimensional displays","Artificial Intelligence;Big Data;Diagnostic Imaging;Humans;Image Interpretation, Computer-Assisted;Image Processing, Computer-Assisted;Medical Informatics;Precision Medicine","284","","91","CCBY","29 May 2020","","","IEEE","IEEE Journals"
"A Systematic Literature Review of I/O Optimization in HPC and Cloud Computing Environments","M. A. G. Napa; A. F. Lorenzon","Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil",2024 International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW),"26 Nov 2024","2024","","","66","72","Efficient data management strategies are increasingly critical in high-performance computing (HPC) and cloud computing environments, where large volumes of data must be processed without introducing performance bottlenecks that can affect scalability. In this scenario, this paper presents a systematic literature review (SLR) investigating the relationship between I/O operations and HPC and cloud environments. Following the PRISMA framework, we selected and analyzed 88 studies that provide information on the current state of I/O research in HPC and the cloud. A well-defined research protocol guided the selection of relevant studies, limiting the review to works published in the last decade to ensure a contemporary understanding of advances and challenges in I/O operations. The analysis of these studies involved a structured categorization, which identified the benchmarks, file systems, and emerging technologies employed. Our discussion also highlights current trends in optimizing I/O performance, offering an overview of the developments in this area of HPC and cloud computing research.","","979-8-3315-0673-5","10.1109/SBAC-PADW64858.2024.00020","Petrobras(grant numbers:2020/00182-5); CNPq/MCTI/FNDCT - Universal 18/2021(grant numbers:406182/2021-3); Capes(grant numbers:001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764543","I/O;systematic literature review;cloud computing;high-performance computing","Cloud computing;Protocols;Limiting;File systems;High performance computing;Scalability;Conferences;Computer architecture;Market research;Optimization","","","","17","IEEE","26 Nov 2024","","","IEEE","IEEE Conferences"
"Ensemble Simulations on Leadership Computing Systems","A. Georgiadou; H. Monge-Camacho; T. Sohail; S. Ghosh; A. V. Parambathu; D. N. Asthagiri; D. Bykov; T. Athawale; T. L. Beck","National Center for Computational Sciences, Oak Ridge, TN, USA; National Center for Computational Sciences, Oak Ridge, TN, USA; National Center for Computational Sciences, Oak Ridge, TN, USA; National Center for Computational Sciences, Oak Ridge, TN, USA; University of Delaware, Delaware, DE, USA; National Center for Computational Sciences, Oak Ridge, TN, USA; National Center for Computational Sciences, Oak Ridge, TN, USA; Oak Ridge National Laboratory, Oak Ridge, TN, USA; National Center for Computational Sciences, Oak Ridge, TN, USA","SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis","8 Jan 2025","2024","","","394","401","Scientific productivity can be enhanced through workflow management tools, relieving large High Performance Computing (HPC) system users from the tedious tasks of scheduling and designing the complex computational execution of scientific applications. This paper presents a study on the usage of ensemble workflow tools to accelerate science using the Summit and Frontier supercomputing systems. The research aims to connect science domain simulations using Oak Ridge Leadership Computing Facility (OLCF) supercomputing platforms with ensemble workflow methods in order to accelerate HPC-enabled discovery and boost scientific impact. We present the coupling, porting and optimization of Radical-Cybertools on three applications: Chroma, NAMD and LAMMPS. The tools augment traditional HPC monolithic runs with a pilot scheduler. Lessons-learned are discussed for physics, biology and materials science applications. We discuss intrinsic limitations of coupling and porting ensemble workflow tools to applications that run on large HPC systems. The origins of technical challenges and their solutions developed during the implementation process are discussed. Data management strategies, OLCF’s policies for ensembles, and natively supported workflow tools are also summarized.1","","979-8-3503-5554-3","10.1109/SCW63240.2024.00059","Office of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10820570","","Couplings;Productivity;Leadership;Processor scheduling;High performance computing;Computational modeling;Lattices;Rendering (computer graphics);Reproducibility of results;Resource management","","","","45","IEEE","8 Jan 2025","","","IEEE","IEEE Conferences"
"DFMan: A Graph-based Optimization of Dataflow Scheduling on High-Performance Computing Systems","F. Chowdhury; F. Di Natale; A. Moody; K. Mohror; W. Yu",Florida State University; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Florida State University,2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS),"15 Jul 2022","2022","","","368","378","Scientific research and development campaigns are materialized by workflows of applications executing on high-performance computing (HPC) systems. These applications con-sist of tasks that can have inter- or intra-application flows of data to achieve the research goals successfully. These dataflows create dependencies among the tasks and cause resource con-tention on shared storage systems, thus limiting the aggregated I/O bandwidth achieved by the workflow. However, these I/O performance issues are often solved by tedious and manual efforts that demand holistic knowledge about the data dependencies in the workflow and the information about the infrastructure being utilized. Taking this into consideration, we design DFMan, a graph-based dataflow management and optimization framework for maximizing I/O bandwidth by leveraging the powerful storage stack on HPC systems to manage data sharing optimally among the tasks in the workflows. In particular, we devise a graph-based optimization algorithm that can leverage an intuitive graph representation of dataflow- and system-related information, and automatically carry out co-scheduling of task and data placement. According to our experiments, DFMan optimizes a wide variety of scientific workflows such as Hurricane 3D on Cloud Model 1 (CM1), Montage Carina Nebula (NGC3372), and an emulated dataflow kernel of the Multiscale Machine-learned Modeling Infrastructure (MuMMI I/O) on the Lassen supercomputer, and improves their aggregated I/O bandwidth by up to 5.42 x, 2.12 x and 1.29 x, respectively, compared to the baseline bandwidth.","1530-2075","978-1-6654-8106-9","10.1109/IPDPS53621.2022.00043","U.S. Department of Energy; Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344,LLNL-CONF-827797); Office of Science; National Science Foundation(grant numbers:1561041,1564647,1763547); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820699","Graph based optimization;Task data co scheduling;HPC workflow;HPC Dataflow;HPC storage systems;Scientific-application-workflow","Solid modeling;Three-dimensional displays;Processor scheduling;High performance computing;Bandwidth;Manuals;Supercomputers","","6","","50","IEEE","15 Jul 2022","","","IEEE","IEEE Conferences"
"Efficient Data Management in Neutron Scattering Data Reduction Workflows at ORNL","W. F. Godoy; P. F. Peterson; S. E. Hahn; J. J. Billings","Oak Ridge National Laboratory,Computer Science and Mathematics Division,Oak Ridge,TN,USA; Oak Ridge National Laboratory,Computer Science and Mathematics Division,Oak Ridge,TN,USA; Oak Ridge National Laboratory,Computer Science and Mathematics Division,Oak Ridge,TN,USA; Oak Ridge National Laboratory,Computer Science and Mathematics Division",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","2674","2680","Oak Ridge National Laboratory (ORNL) experimental neutron science facilities produce 1.2 TB a day of raw event-based data that is stored using the standard metadata-rich NeXus schema built on top of the HDF5 file format. Performance of several data reduction workflows is largely determined by the amount of time spent on the loading and processing algorithms in Mantid, an open-source data analysis framework used across several neutron sciences facilities around the world. The present work introduces new data management algorithms to address identified input output (I/O) bottlenecks on Mantid. First, we introduce an in-memory binary-tree metadata index that resemble NeXus data access patterns to provide a scalable search and extraction mechanism. Second, data encapsulation in Mantid algorithms is optimally redesigned to reduce the total compute and memory runtime footprint associated with metadata I/O reconstruction tasks. Results from this work show speed ups in wall-clock time on ORNL data reduction workflows, ranging from 11% to 30% depending on the complexity of the targeted instrument-specific data. Nevertheless, we highlight the need for more research to address reduction challenges as experimental data volumes increase.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9377836","Basic Energy Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377836","experimental data;reduction workflows;data management;metadata;indexing;Mantid;NeXus;HDF5;neutron scattering","Neutron spin echo;Runtime;Data analysis;Instruments;Neutrons;Metadata;Distance measurement","","3","","26","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Characterizing Scientific Workflows on HPC Systems using Logs","D. Ghoshal; B. Austin; D. Bard; C. Daley; G. Lockwood; N. J. Wright; L. Ramakrishnan","Lawrence Berkeley National Laboratory, Berkeley, CA; Lawrence Berkeley National Laboratory, Berkeley, CA; Lawrence Berkeley National Laboratory, Berkeley, CA; Lawrence Berkeley National Laboratory, Berkeley, CA; Lawrence Berkeley National Laboratory, Berkeley, CA; Lawrence Berkeley National Laboratory, Berkeley, CA; Lawrence Berkeley National Laboratory, Berkeley, CA",2020 IEEE/ACM Workflows in Support of Large-Scale Science (WORKS),"4 Jan 2021","2020","","","57","64","Scientific advances depend on the ability to effectively and efficiently use high performance computing (HPC) systems to manage and run large, complex scientific workflows. Towards understanding the characteristics of these large scientific workflows, we propose two methods to identify workflows with temporal connections and data-dependencies from batch queue and I/O logs available at HPC systems. We use the two methods to characterize and correlate workflow runtime with node requests, I/O patterns, and resource usage on three months of log data available for Cori, a supercomputer at NERSC. A key result from our analyses shows that single-job workflows often do not use all allocated CPUs that provides opportunities to consider allocating resources at a finer-granularity.","","978-1-6654-0452-5","10.1109/WORKS51914.2020.00013","U.S. Department of Energy; Advanced Scientific Computing Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308164","","Runtime;Task analysis;Windows;Tools;Supercomputers;Queueing analysis;Processor scheduling","","2","","13","IEEE","4 Jan 2021","","","IEEE","IEEE Conferences"
"Triangle Counting Accelerations: From Algorithm to In-Memory Computing Architecture","X. Wang; J. Yang; Y. Zhao; X. Jia; R. Yin; X. Chen; G. Qu; W. Zhao","MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, BDBC, State Key Laboratory of Software Development Environment (NLSDE), Beihang University, Beijing, China; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; Department of Electrical and Computer Engineering and Institute for Systems Research, University of Maryland, College Park, MD, USA; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China",IEEE Transactions on Computers,"7 Sep 2022","2022","71","10","2462","2472","Triangles are the basic substructure of networks and triangle counting (TC) has been a fundamental graph computing problem in numerous fields such as social network analysis. Nevertheless, like other graph computing problems, due to the high memory-computation ratio and random memory access pattern, TC involves a large amount of data transfers thus suffers from the bandwidth bottleneck in the traditional Von-Neumann architecture. To overcome this challenge, in this paper, we propose to accelerate TC with the emerging processing-in-memory (PIM) architecture through an algorithm-architecture co-optimization manner. To enable the efficient in-memory implementations, we come up to reformulate TC with bitwise logic operations (such as AND), and develop customized graph compression and mapping techniques for efficient data flow management. With the emerging computational Spin-Transfer Torque Magnetic RAM (STT-MRAM) array, which is one of the most promising PIM enabling techniques, the device-to-architecture co-simulation results demonstrate that the proposed TC in-memory accelerator outperforms the state-of-the-art GPU and FPGA accelerations by $12.2\times$12.2× and $31.8\times$31.8×, respectively, and achieves a $34\times$34× energy efficiency improvement over the FPGA accelerator.","1557-9956","","10.1109/TC.2021.3131049","National Natural Science Foundation of China(grant numbers:62004011); State Key Laboratory of Computer Architecture(grant numbers:CARCH201917); National Natural Science Foundation of China(grant numbers:62072019); National Natural Science Foundation of China(grant numbers:U20A20204); Special Research Assistant Project of CAS(grant numbers:E0YY221-2020000702); National Natural Science Foundation of China(grant numbers:62106259); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627790","Triangle counting acceleration;processing-in-memory;algorithm-architecture co-design;graph computing","Sensors;Random access memory;Magnetic tunneling;Field programmable gate arrays;Task analysis;Process control;Graphics processing units","","13","","28","IEEE","26 Nov 2021","","","IEEE","IEEE Journals"
"Green Open Innovation and Circular Economy: Investigating the Role of Big Data Management and Sustainable Supply Chain","R. K. Singh; K. Mathiyazhagan; V. Scuotto; M. Pironti","International Management Institute, Kolkata, India; Thiagarajar School of Management, Madurai, India; Leonard de Vinci, Pole universitaire, Research Center, Paris La Défense, France; ICxT Innovation Interdepartmental Center, University of Turin, Turin, Italy",IEEE Transactions on Engineering Management,"21 May 2024","2024","71","","8417","8429","The study delves into the concept of circular economy target (CET) performance in the context of green open innovation (GOI) to understand the role of Big Data management (BDM) and sustainable supply chain performances (SSCPs), including knowledge management (KM). The authors developed a self-administered survey for 294 participants from the cement, electronics, tyres, rubber, and energy sectors. These industries are relevant for their environmental impacts and sustainability challenges. The study's empirical findings emphasize the positive association between BDM with Big Data capability (BDC) and KM. Further, it positively associates with SSCP and CET, especially in the context of GOI. GOI was also observed as a moderating variable in the relationships between BDC-SSCP and KM-SSCP. The conceptual framework elucidates the interaction between BDC, knowledge capabilities, and SSCP. It underscores the collective synergy of these components in achieving CET. This is in the frame of GOI, which intertwines the value chain between territorial actors such as companies, universities, and research institutes that exploit and convert big data into knowledge to get new forms of sustainable innovations.","1558-0040","","10.1109/TEM.2024.3387107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496234","Big Data capability (BDC);Big Data management (BDM);circular economy target (CET) performance;green open innovation (GOI);knowledge management (KM);sustainable supply chain performance","Supply chains;Technological innovation;Sustainable development;Green products;Companies;Big Data;Dynamic scheduling","","7","","79","IEEE","10 Apr 2024","","","IEEE","IEEE Journals"
"Transforming Urban Landscapes: Exploring the Potential of IoT-Enabled Smart Cities for Enhanced Productivity, Sustainability, and Quality of Life","J. Khurana","Centre for Interdisciplinary Research for Business and Technology, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India",2023 3rd International Conference on Advancement in Electronics & Communication Engineering (AECE),"15 Feb 2024","2023","","","744","749","The IoT has an opportunity to turn cities into “smart cities” that are more productive, environmentally friendly, and habitable. IoT-enabled smart cities may give real-time data on numerous elements of urban life by linking a large number of sensors and devices. These aspects include things like traffic, energy usage, and air quality. This information may then be put to use to increase the quality of life for inhabitants, as well as improve public safety and urban infrastructure and services. In this article, we present an overview of the current state of the art in devices-enabled smart cities. This includes both the technology and the applications that are already being employed, as well as the difficulties that must be solved in order to allow their wider adoption. We also explore potential advances in the industry, including the possible applications of upcoming technologies like 5G, which is computing on the edge, and robotics.","","979-8-3503-3072-4","10.1109/AECE59614.2023.10428408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10428408","Urban Infrastructure;Sustainability;Edge Computing;Artificial Intelligence;5G;Public Safety;Quality of Life","Technological innovation;Smart cities;5G mobile communication;Service robots;Security;Stakeholders;Sustainable development","","","","20","IEEE","15 Feb 2024","","","IEEE","IEEE Conferences"
"Big Data Management in Smart Grids: Technologies and Challenges","A. Zainab; A. Ghrayeb; D. Syed; H. Abu-Rub; S. S. Refaat; O. Bouhali","Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA; Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar; Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA; Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar; Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar; Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar",IEEE Access,"21 May 2021","2021","9","","73046","73059","Smart grids are re-engineering the electricity transmission and distribution system throughout the world. It is an amalgam of increased digital information with the electrical power grids. Managing the data generated from the grid efficiently is the key to successful knowledge extraction from the smart grid big data. Most of the scientific advancements are becoming data-driven and becoming an interesting area of research for data scientists. It is challenging the world computationally enough to develop new storage methods and data processing technologies. Managing big data involves data cleaning, integration of varied data sources, and decision-making applications. This paper focuses on the study of big data management and proposes a management process to help manage the data in the grid. Data management tools and techniques have been leveraged in understanding the sources and data types in the grid. The paper emphasizes the limitations of the existing solutions inclined towards applications of the smart grid big data.","2169-3536","","10.1109/ACCESS.2021.3080433","NPRP from the Qatar National Research Fund (A member of Qatar Foundation), an Internal Seed Grant from Texas A&M University, Qatar(grant numbers:NPRP10-0101-170082); IBERDROLA QSTPLLC; Open Access Funding by Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431185","Apache spark;big data;data mining;Hadoop;indexing;management process;smart grid;stream mining","Smart grids;Big Data;Companies;Cloud computing;Data mining;Predictive models;Data models","","24","","86","CCBY","14 May 2021","","","IEEE","IEEE Journals"
"Impact of Big Data and Machine Learning on Digital Transformation in Marketing: A Literature Review","A. Miklosik; N. Evans","Marketing Department, Faculty of Management, Comenius University in Bratislava, Bratislava, Slovakia; UniSA STEM, University of South Australia, Adelaide, Australia",IEEE Access,"8 Jun 2020","2020","8","","101284","101292","This paper describes the impact of big data and machine learning (ML) on digital transformation of the marketing industry and the challenges it faces from a data and information management perspective. To do this, the study identified areas of digital transformation in marketing that have not yet been sufficiently covered by existing peer-reviewed academic research. Research papers were retrieved from five databases, namely Web of Science, Scopus, ScienceDirect, Emerald, and ProQuest. Screening of 214 articles resulted in 69 articles being selected for this literature review. A gap in the existing research was identified, with five areas directly related to digital transformation in marketing. Another five potential opportunities for future research in the area of big data utilisation and application of ML-driven technologies in the marketing field were also identified. An investigation of the prospects of digital transformation in marketing can benefit both academic researchers and business practitioners working in the domain of information technologies (IT), information systems (IS), business, and marketing, by identifying areas needing primary research, systemisation, follow-up research, validation or gathering of empirical data.","2169-3536","","10.1109/ACCESS.2020.2998754","KEGA (The innovative learning texts from marketing for secondary schools)(grant numbers:016EU-4/2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103568","Big data;digital transformation;marketing;information management;disruptive technologies;machine learning (ML)","Big Data;Business;Industries;Data mining;Machine learning;Media;Transforms","","52","","69","CCBY","29 May 2020","","","IEEE","IEEE Journals"
"Livestock Management With Unmanned Aerial Vehicles: A Review","M. A. Alanezi; M. S. Shahriar; M. B. Hasan; S. Ahmed; Y. A. Sha’aban; H. R. E. H. Bouchekara","Department of Computer Science and Engineering, University of Hafr Al Batin, Hafr Al Batin, Saudi Arabia; Department of Electrical Engineering, University of Hafr Al Batin, Hafr Al Batin, Saudi Arabia; Department of Computer Science and Engineering, Islamic University of Technology, Gazipur, Bangladesh; Department of Computer Science and Engineering, Islamic University of Technology, Gazipur, Bangladesh; Department of Electrical Engineering, University of Hafr Al Batin, Hafr Al Batin, Saudi Arabia; Department of Electrical Engineering, University of Hafr Al Batin, Hafr Al Batin, Saudi Arabia",IEEE Access,"2 May 2022","2022","10","","45001","45028","The ease of use and advancements in drone technology is resulting in the widespread application of Unmanned Aerial Vehicles (UAVs) to diverse fields, making it a booming technology. Among UAVs’ several applications, livestock agriculture is one of the most promising, where UAVs facilitate various operations for efficient animal management. But the field is characterized by multiple environmental, technical, economic, and strategic challenges. However, the use of advanced technological techniques like Artificial Intelligence (AI), Internet of Things (IoT), Machine Learning (ML), Deep Learning (DL), advanced sensors, etc., along with the assurance of animal welfare while operating the UAVs, can lead to widespread adoption of drone technology amongst livestock farmers. This paper discusses livestock management research where UAVs monitor farm animals via detection, counting, tracking animals, etc. In this article, an attempt has been made to elucidate different aspects and broader issues around livestock management while highlighting the associated challenges, opportunities, and prospects. This work is the first review paper on the subject matter with all the necessary information and analysis, to the best of our knowledge. Therefore, the article promises to provide interested researchers with detailed information about the field, guiding future research.","2169-3536","","10.1109/ACCESS.2022.3168295","Deputyship for Research and Innovation, Ministry of Education, Saudi Arabia(grant numbers:IFP-A-201-2-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759302","Unmanned aerial vehicle;cattle;livestock management;livestock agriculture","Agriculture;Cows;Monitoring;Drones;Autonomous aerial vehicles;Animals;Sensors","","39","","217","CCBY","18 Apr 2022","","","IEEE","IEEE Journals"
"Optimizing Quality Inspection and Control in Powder Bed Metal Additive Manufacturing: Challenges and Research Directions","S. Di Cataldo; S. Vinco; G. Urgese; F. Calignano; E. Ficarra; A. Macii; E. Macii","Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Interuniversity Department of Regional and Urban Studies and Planning, Politecnico di Torino, Turin, Italy; Department of Management and Production Engineering, Politecnico di Torino, Turin, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Interuniversity Department of Regional and Urban Studies and Planning, Politecnico di Torino, Turin, Italy",Proceedings of the IEEE,"23 Mar 2021","2021","109","4","326","346","One of the key targets of Industry 4.0 and digital production, in general, is the support of faster, cleaner, and increasingly customizable manufacturing processes. Additive manufacturing (AM) is a natural fit in this context, as it offers the possibility to produce complex parts without the design constraints of traditional manufacturing routes, typically reducing both material waste and time to market. Nonetheless, the lack of repeatability of the manufacturing process, which typically translates into a lack of reproducibility and reliability of the quality of the final products compared to traditional subtractive technologies, is currently one of the major barriers to the widespread adoption of AM in mass production. To overcome this limitation, there are growing efforts in recent years toward better integration of advanced information technologies into AM, exploiting the layer-by-layer nature of the build. The consequence of these efforts is twofold: 1) the integration of advanced sensing technologies into the AM systems, making possible the in situ monitoring of huge amounts of data at multiple time scales and resolutions and 2) the ever-increasing role of data-driven approaches [especially machine learning (ML)] in the analysis of such data to provide real-time quality monitoring and process optimization. This article introduces and reviews the key technological developments of this phenomenon, with a special focus on metal powder bed fusion (PBF) technologies that are attracting the highest attention by the industrial AM community. After introducing the main manufacturing quality issues and needs that have to be developed and optimized, we provide a wide overview of the latest progress of in situ monitoring and control in metal PBF, with special regards to sensing technologies and ML approaches. Finally, we identify the open challenges and future research directions in this field.","1558-2256","","10.1109/JPROC.2021.3054628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347446","Additive manufacturing (AM);in situ monitoring;Industry 4.0;metal 3-D printing;powder bed fusion (PBF);process optimization;smart manufacturing","Optimization;Powders;Laser fusion;Laser sintering;Three-dimensional printing;Laser beams;Fourth Industrial Revolution;Smart manufacturing;Process monitoring","","26","","164","IEEE","4 Feb 2021","","","IEEE","IEEE Journals"
"Subscription-Based Data-Sharing Model Using Blockchain and Data as a Service","F. A. Al-Zahrani","Computer Engineering Department, Umm AlQura University, Mecca, Saudi Arabia",IEEE Access,"30 Jun 2020","2020","8","","115966","115981","In modern times, many individuals, businesses and the Internet of Things (IoT) integrated industries collect huge amounts of meaningful data daily, which may be beneficial for other individuals and businesses as well. By utilizing this data, future trends to make the right decisions on the bases of facts and figures are analyzed efficiently. In addition to that, many new ways are paved for researchers to utilize this data in their upcoming research. However, due to some major issues like security, privacy and access control of data, data owners avoid sharing data among themselves. Another main problem is the selfish behavior of data owners. Businesses also act selfishly and invest huge amounts of money to collect and maintain the data for their benefits. Therefore, data owners are hesitant to share their data with others without the availability of a fair profit and secure data-sharing platform. Moreover, consumers are not much motivated to buy data from Data Providers (DPs) due to its bad quality and inconsistency. The data provided by data owners is mostly incomplete, outdated, heterogeneous and costly. In this paper, a subscription-based data-sharing model is proposed by leveraging the blockchain technology and Data as a Service (DaaS) concept. In this model, users subscribe to a DP for a specific period to get access to the data and pay according to the subscription plan. The DP keeps receiving revenue recurrently for a long-time, which has a huge profit margin in comparison with selling data at once. Furthermore, two major pricing models, Flat Rate Pricing (FRP) and Usage-Based Pricing (UBP), are discussed to set standards for data owners to monetize their data, and a new hybrid pricing model is also proposed. Blockchain technology is utilized in the proposed model to make it secure, transparent and immutable. To investigate the performance of the proposed model, a private blockchain network is deployed using a web interface provided by MultiChain blockchain. The simulation results demonstrate that the proposed model is feasible and efficient. The theoretical discussion proves that the proposed model is beneficial for both data owners and data consumers and has a good scope in the future for data management and trading processes.","2169-3536","","10.1109/ACCESS.2020.3002823","National Science, Technology and Innovation Plan (MAARIFAH)(grant numbers:12-INF2970-10); King Abdul-Aziz City for Science and Technology (KACST), Kingdom of Saudi Arabia; Science and Technology Unit at Umm Al-Qura University for their continued logistics support; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129880","Access control;blockchain;data-sharing;data as a service;pricing strategies;incentive mechanism;data subscription","Blockchain;Data models;Data privacy;Access control;Pricing","","25","","37","CCBY","30 Jun 2020","","","IEEE","IEEE Journals"
"Slicing-Based Artificial Intelligence Service Provisioning on the Network Edge: Balancing AI Service Performance and Resource Consumption of Data Management","M. Li; J. Gao; C. Zhou; X. S. Shen; W. Zhuang","Department of Electrical and Computer Engineering, University of Waterloo, Ontario, Canada; Department of Electrical and Computer Engineering, Marquette University, Milwaukee, Wisconsin, USA; Department of Electrical and Computer Engineering, University of Waterloo, Ontario, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Ontario, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Ontario, Canada",IEEE Vehicular Technology Magazine,"6 Dec 2021","2021","16","4","16","26","Edge intelligence leverages computing resources on the network edge to provide artificial intelligence (AI) services close to network users. As it enables fast inference and distributed learning, edge intelligence is envisioned to be an important component of 6G networks. In this article, we investigate AI service provisioning for supporting edge intelligence. First, we present the features and requirements of AI services. Then we introduce AI service data management and customize network slicing for AI services. Specifically, we propose a novel resource-pooling method to regularize service data exchange within the network edge while allocating network resources for AI services. Using this method, network resources can be properly allocated to network slices to fulfill AI service requirements. A trace-driven case study demonstrates that the proposed method can allow network slicing to satisfy diverse AI service performance requirements via the flexible selection of resource-pooling policies. In this study, we illustrate the necessity, challenge, and potential of AI service provisioning on the network edge and provide insights into resource management for AI services.","1556-6080","","10.1109/MVT.2021.3114655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9586568","","Artificial intelligence;Training data;Data models;Image edge detection;Servers;Network slicing;Computational modeling;Network slicing;Resource management;Computer aided instruction;6G mobile communication","","21","","15","IEEE","26 Oct 2021","","","IEEE","IEEE Magazines"
"Internet of Behaviors: A Survey","J. Sun; W. Gan; H. -C. Chao; P. S. Yu; W. Ding","College of Cyber Security, Jinan University, Guangzhou, China; College of Cyber Security, Jinan University, Guangzhou, China; Department of Electrical Engineering, National Dong Hwa University, Hualien, Taiwan; Department of Computer Science, University of Illinois at Chicago, Chicago, IL, USA; School of Information Science and Technology, Nantong University, Nantong, China",IEEE Internet of Things Journal,"22 Jun 2023","2023","10","13","11117","11134","The Internet of Behavior (IoB) is a research theme that aims to analyze human behavior data on the Internet from the perspective of behavioral psychology, obtain insights about human behavior, and better understand the intention behind the behavior. In this way, the IoB can predict human behavioral trends in the future and even change human behavior, which can provide more convenience for human life. With the increasing prosperity of the Internet of Things (IoT), more and more behavior-related data is collected on the Internet by connected devices such as sensors. People and behavior are connected through the extension of the IoT—the IoB. Presently, the IoB has gradually been applied to our lives, but it is still in its early stages, and many opportunities and challenges are emerging. This article provides an in-depth overview of the fundamental aspects of the IoB: 1) we introduce the development process and research status of the IoB from the perspective of the IoT; 2) we propose the characteristics of the IoB and define its development direction in terms of three aspects: a) real time; b) autonomy; and c) reliability; 3) we provide a comprehensive summary of the current applications of the IoB, including specific discussions in five scenarios that give an overview of the application status of the IoB; and 4) we discuss the challenges of the IoB’s development and its future directions, which hopefully will bring some progress to the IoB. To the best of our knowledge, this is the first survey paper on the IoB. We hope that this in-depth review can provide some useful directions for more productive research in related fields.","2327-4662","","10.1109/JIOT.2023.3247594","National Natural Science Foundation of China(grant numbers:62002136,62272196); Natural Science Foundation of Guangdong Province(grant numbers:2022A1515011861); Guangzhou Basic and Applied Basic Research Foundation(grant numbers:202102020277); Young Scholar Program of Pazhou Lab(grant numbers:PZL2021KF0023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049600","Applications;behavior;data science;Internet;Internet of Behavior (IoB)","Behavioral sciences;Internet of Things;Psychology;Sensors;Real-time systems;Market research;Data mining","","16","","118","IEEE","22 Feb 2023","","","IEEE","IEEE Journals"
"Hybrid Neural Network Based Models for Evapotranspiration Prediction Over Limited Weather Parameters","P. J. Vaz; G. Schütz; C. Guerrero; P. J. S. Cardoso","Instituto Superior de Engenharia, Universidade do Algarve, Campus da Penha, Faro, Portugal; Instituto Superior de Engenharia, Universidade do Algarve, Campus da Penha, Faro, Portugal; Faculdade de Ciências e Tecnologia, Universidade do Algarve, Campus de Gambelas, Faro, Portugal; Instituto Superior de Engenharia, Universidade do Algarve, Campus da Penha, Faro, Portugal",IEEE Access,"6 Jan 2023","2023","11","","963","976","Evapotranspiration can be used to estimate the amount of water required by agriculture projects and green spaces, playing a key role in water management policies that combat the hydrological drought, which assumes a structural character in many countries. In this context, this work presents a study on reference evapotranspiration ( $ET_{o}$ ) estimation models, having as input a limited set of meteorological parameters, namely: temperature, humidity, and wind. Since solar radiation (SR) is an important parameter in the determination of  $ET_{o}$ , SR estimation models are also developed. These  $ET_{o}$  and SR estimation models compare the use of Artificial Neural Networks (ANN), Long Short Term Memory (LSTM), Gated Recurrent Unit (GRU), Recurrent Neural Network (RNN), and hybrid neural network models such as LSTM-ANN, RNN-ANN, and GRU-ANN. Two main approaches were taken for  $ET_{o}$  estimation: (i) directly use those algorithms to estimate  $ET_{o}$ , and (ii) estimate solar radiation first and then use that estimation together with other meteorological parameters in a method that predicts  $ET_{o}$ . For the latter case, two variants were implemented: the use of the estimated solar radiation as (ii.1) a feature of the neural network regressors, and (ii.2) the use of the Penman-Monteith method (a.k.a. FAO-56PM method, adopted by the United Nations Food and Agriculture Organization) to compute  $ET_{o}$ , which has solar radiation as one of the input parameters. Using experimental data collected from a weather station (WS) located in Vale do Lobo (Portugal), the later approach achieved the best result with a coefficient of determination  $(R^{2})$  of 0.977. The developed model was then applied to data from eleven stations located in Colorado (USA), with very distinct climatic conditions, showing similar results to the ones for which the models were initially designed ( $R^{2}>0.95$ ), proving a good generalization. As a final notice, the reduced-set features were carefully selected so that they are compatible with free online weather forecast services.","2169-3536","","10.1109/ACCESS.2022.3233301","Project GSSIC—Green Spaces SMART Irrigation Control(grant numbers:ALG-01-0247-FEDER-047030); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10003192","Artificial neural networks;evapotranspiration;public garden;smart irrigation;solar radiation","Solar radiation;Meteorology;Crops;Computational modeling;Artificial neural networks;Predictive models;Irrigation","","10","","53","CCBY","29 Dec 2022","","","IEEE","IEEE Journals"
"A Resilient Fire Protection System for Software-Defined Factories","G. Tricomi; C. Scaffidi; G. Merlino; F. Longo; A. Puliafito; S. Distefano","Department of Ingegneria, Università degli Studi di Messina, Messina, Italy; Department of Ingegneria, Università degli Studi di Messina, Messina, Italy; Department of Ingegneria, Università degli Studi di Messina, Messina, Italy; Department of Ingegneria, Università degli Studi di Messina, Messina, Italy; National Laboratory on Smart Cities Communities, National Interuniversity Consortium for Informatics (CINI), Rome, Italy; National Laboratory on Smart Cities Communities, National Interuniversity Consortium for Informatics (CINI), Rome, Italy",IEEE Internet of Things Journal,"6 Feb 2023","2023","10","4","3151","3164","A Smart Factory exploits information and communication technologies (ICT) to improve the production process and the working environment, usually addressing safety concerns. To this concern, factory-grade fire protection systems are governed by several procedures and standards whose application often becomes definitely challenging when the factory premises are dispersed across multiple administrative domains. In such contexts, the Smart Factory approach can prove very effective in the management and coordination of the factory-level fire protection system. However, a catastrophic event may compromise the ICT infrastructure, affecting communication among factory domains and therefore its smart services. A strategy to cope with the latter may be the introduction of mechanisms to handle data analysis on-site for a prompt response while enabling seamless data distribution and processing among neighboring (federated) ICT infrastructures and emergency operators. In this work, a novel software-defined approach for the adaptive management of a Smart Factory infrastructure is proposed, centered around business logic rewiring and reconfiguration at runtime across different factory domains. Thereby, even in the case of catastrophic (e.g., potentially disruptive) events, working devices of the emergency system can go on with their operations, including transferring data to rescuers and others emergency control systems. To demonstrate the effectiveness of the proposed software-defined factory approach, a federated fire protection system operating in an industrial setting is implemented as a case study, able to promptly react and adapt to infrastructure-critical fires and their consequences by leveraging all information and computing facilities pooled over cloud/fog/edge devices spanning the premises.","2327-4662","","10.1109/JIOT.2021.3127387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9611521","Complex event processing (CEP);federation;fog/edge/cloud computing;Industry 4.0;Internet of Things (IoT);smart environment;smart factory;software-defined systems","Production facilities;Buildings;Safety;Software;Smart manufacturing;Real-time systems;Internet of Things","","10","","32","IEEE","11 Nov 2021","","","IEEE","IEEE Journals"
"Securing the Internet of Things in Artificial Intelligence Era: A Comprehensive Survey","M. Humayun; N. Tariq; M. Alfayad; M. Zakwan; G. Alwakid; M. Assiri","Department of Information Systems, College of Computer and Information Sciences, Jouf University, Sakaka, Al Jouf, Saudi Arabia; Department of Avionics Engineering, Air University, Islamabad, Pakistan; Department of Information Systems, College of Computer and Information Sciences, Jouf University, Sakaka, Al Jouf, Saudi Arabia; Department of Avionics Engineering, Air University, Islamabad, Pakistan; Department of Computer Sciences, College of Computer and Information Sciences, Jouf University, Sakaka, Al Jouf, Saudi Arabia; Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, P.O. BOX 16273, Al-Kharj, Saudi Arabia",IEEE Access,"21 Feb 2024","2024","12","","25469","25490","The Internet of Things (IoT) has revolutionized various domains, enabling interconnected devices to communicate and exchange data. The integration of Artificial Intelligence (AI) in IoT systems further enhances their capabilities and potential benefits. Unfortunately, in the era of AI, ensuring the privacy and security of the IoT faces novel and specific challenges. IoT security is imperative, necessitating comprehensive strategies, including comprehension of IoT security challenges, implementation of AI methodologies, adoption of resilient security frameworks, and handling of privacy and ethical concerns to construct dependable and secure IoT systems. It is vital to note that the term ‘security’ encompasses a more comprehensive view than cyberattacks alone. Therefore, with an emphasis on securing against cyberattacks, this comprehensive survey also includes physical security threats on the IoT. It investigates the complexities and solutions for IoT systems, placing particular emphasis on AI-based security techniques. The paper undertakes a categorization of the challenges associated with ensuring IoT security, investigates the utilization of AI in IoT security, presents security frameworks and strategies, underscores privacy and ethical considerations, and provides insights derived from practical case studies. Furthermore, the survey sheds light on emerging trends concerning IoT security in the AI era. This survey provides significant contributions to the understanding of establishing dependable and secure IoT systems through an exhaustive examination of the present condition of IoT security and the ramifications of AI on it.","2169-3536","","10.1109/ACCESS.2024.3365634","Deanship of Scientific Research at Jouf University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433502","Artificial intelligence;cyberattack;Internet of Things;privacy;security","Security;Artificial intelligence;Internet of Things;Surveys;Privacy;Ethics;Computer crime;Cyberattack","","9","","126","CCBYNCND","13 Feb 2024","","","IEEE","IEEE Journals"
"Finding Nano-Ötzi: Cryo-Electron Tomography Visualization Guided by Learned Segmentation","N. Nguyen; C. Bohak; D. Engel; P. Mindek; O. Strnad; P. Wonka; S. Li; T. Ropinski; I. Viola","King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Ulm University, Ulm, Germany; Nanographics GmbH, TU Wien, Wien, Austria; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; School of Life Sciences, Tsinghua University, Bejing, China; Ulm University, Ulm, Germany; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",IEEE Transactions on Visualization and Computer Graphics,"1 Sep 2023","2023","29","10","4198","4214","Cryo-electron tomography (cryo-ET) is a new 3D imaging technique with unprecedented potential for resolving submicron structural details. Existing volume visualization methods, however, are not able to reveal details of interest due to low signal-to-noise ratio. In order to design more powerful transfer functions, we propose leveraging soft segmentation as an explicit component of visualization for noisy volumes. Our technical realization is based on semi-supervised learning, where we combine the advantages of two segmentation algorithms. First, the weak segmentation algorithm provides good results for propagating sparse user-provided labels to other voxels in the same volume and is used to generate dense pseudo-labels. Second, the powerful deep-learning-based segmentation algorithm learns from these pseudo-labels to generalize the segmentation to other unseen volumes, a task that the weak segmentation algorithm fails at completely. The proposed volume visualization uses deep-learning-based segmentation as a component for segmentation-aware transfer function design. Appropriate ramp parameters can be suggested automatically through frequency distribution analysis. Furthermore, our visualization uses gradient-free ambient occlusion shading to further suppress the visual presence of noise, and to give structural detail the desired prominence. The cryo-ET data studied in our technical experiments are based on the highest-quality tilted series of intact SARS-CoV-2 virions. Our technique shows the high impact in target sciences for visual data analysis of very noisy volumes that cannot be visualized with existing techniques.","1941-0506","","10.1109/TVCG.2022.3186146","Tsinghua University Spring Breeze Fund(grant numbers:2021Z99CFZ004); National Natural Science Foundation of China(grant numbers:32171195); King Abdullah University of Science and Technology(grant numbers:BAS/1/1680-01-01); KAUST Visualization Core Lab; Baden-Würt-temberg Stiftung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806341","Volume rendering;computer graphics techniques;machine learning techniques;scalar field data;life sciences","Data visualization;Image segmentation;Visualization;Task analysis;Three-dimensional displays;Signal to noise ratio;Noise measurement","","7","","82","CCBY","24 Jun 2022","","","IEEE","IEEE Journals"
"Towards HPC and Big Data Analytics Convergence: Design and Experimental Evaluation of a HPDA Framework for eScience at Scale","D. Elia; S. Fiore; G. Aloisio","Euro-Mediterranean Centre on Climate Change (CMCC) Foundation, Lecce, Italy; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Euro-Mediterranean Centre on Climate Change (CMCC) Foundation, Lecce, Italy",IEEE Access,"21 May 2021","2021","9","","73307","73326","Over the last two decades, scientific discovery has increasingly been driven by the large availability of data from a multitude of sources, including high-resolution simulations, observations and instruments, as well as an enormous network of sensors and edge components. In such a dynamic and growing landscape where data continue to expand, advances in Science have become intertwined with the capacity of analysis tools to effectively handle and extract valuable information from this ocean of data. In view of the exascale era of supercomputers that is rapidly approaching, it is of the utmost importance to design novel solutions that can take full advantage of the upcoming computing infrastructures. The convergence of High Performance Computing (HPC) and data-intensive analytics is key to delivering scalable High Performance Data Analytics (HPDA) solutions for scientific and engineering applications. The aim of this paper is threefold: reviewing some of the most relevant challenges towards HPDA at scale, presenting a HPDA-enabled version of the Ophidia framework and validating the scalability of the proposed framework through an experimental performance evaluation carried out in the context of the Centre of Excellence in Simulation of Weather and Climate in Europe (ESiWACE). The experimental results show that the proposed solution is capable of scaling over several thousand cores and hundreds of cluster nodes. The proposed work is a contribution in support of scientific large-scale applications along the wider convergence path of HPC and Big Data followed by the scientific research community.","2169-3536","","10.1109/ACCESS.2021.3079139","European Union’s Horizon 2020 Research and Innovation Programme through the Project ESiWACE2(grant numbers:823988); European Union’s Horizon 2020 Research and Innovation Programme through the Project EXDCI-2(grant numbers:800957); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428012","Extreme-scale data challenges;HPC and big data convergence;high performance data analytics (HPDA);performance evaluation;scientific data analysis","Big Data;Data analysis;Convergence;Data models;Europe;Ecosystems;Software","","7","","105","CCBY","11 May 2021","","","IEEE","IEEE Journals"
"Resilient Edge Data Management Framework","I. Lujic; V. De Maio; I. Brandic","Institute of Information Systems Engineering, Vienna University of Technology, Vienna, Austria; Institute of Information Systems Engineering, Vienna University of Technology, Vienna, Austria; Institute of Information Systems Engineering, Vienna University of Technology, Vienna, Austria",IEEE Transactions on Services Computing,"5 Aug 2020","2020","13","4","663","674","Transferring and processing huge amounts of data in the cloud can violate the low latency requirements of modern IoT applications, considering underlying network infrastructure limitations. Edge data analytics is a promising solution. However, edge resources have usually less computational capabilities than cloud nodes, resulting in a higher failure rate of IoT systems. Consequently, near-real-time decisions are often based on limited and incomplete data. State-of-the-art solutions, such as operational/workload flows, data reduction, reconstruction, focus mostly on resource and network optimization, while approaches for incomplete data recovery employ a single specific method, despite diverse data characteristics. Data quality impact on accuracy of the decision-making processes is often neglected. We propose EDMFrame, a framework featuring a generic mechanism for recovery of multiple gaps in incomplete datasets, using single-technique recovery (STR) and multiple-technique recovery (MTR) involving projection recovery maps (PRMs). We further devise an adaptive storage management mechanism for reducing data stored at the edge, keeping only the data necessary for predictive analytics. We conduct experiments using time series from smart buildings, (i) automatically recovering various multiple gaps and reducing errors up to 65.48 percent with MTR compared to STR; (ii) reducing amounts of data stored to 39.9 percent on average, keeping prediction accuracy around 98.83 percent.","1939-1374","","10.1109/TSC.2019.2962016","Rucon Project; Internet Foundation Austria; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941259","Edge computing;Internet of Things;data;storage;forecasting;solution reference architectures;data flow architecture","Internet of Things;Cloud computing;Monitoring;Storage management;Intelligent sensors","","6","","47","IEEE","24 Dec 2019","","","IEEE","IEEE Journals"
"Hybrid On/Off Blockchain Approach for Vehicle Data Management, Processing and Visualization Exemplified by the ADAPT Platform","A. Validi; V. Kashansky; J. Khiari; H. Hadian; R. Prodan; J. Li; F. -Y. Wang; C. Olaverri-Monreal","Chair Sustainable Transport Logistics 4.0, Johannes Kepler University, Linz, Austria; University of Klagenfurt; Institute of Information Technology; Chair Sustainable Transport Logistics 4.0, Johannes Kepler University, Linz, Austria; University of Klagenfurt; Institute of Information Technology; University of Klagenfurt; Institute of Information Technology; Institute of Automation Chinese Academy of Sciences China; Institute of Automation Chinese Academy of Sciences China; Chair Sustainable Transport Logistics 4.0, Johannes Kepler University, Linz, Austria",2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC),"1 Nov 2022","2022","","","3152","3158","Hybrid on/off-blockchain vehicle data management approaches have received a lot of attention in recent years. However, there are various technical challenges remained to deal with. In this paper we relied on real-world data from Austria to investigate the effects of connectivity on the transport of personal protective equipment. We proposed a three-step mechanism to process, simulate, and store/visualize aggregated vehicle datasets together with a formal pipeline process workflow model. To this end, we implemented a hybrid blockchain platform based on the hyperledger fabric and gluster file systems. The obtained results demonstrated efficiency and stability for both hyperledger fabric and gluster file systems and ability of the both on/off-blockchain mechanisms to meet the platform quality of service requirements.","","978-1-6654-6880-0","10.1109/ITSC55140.2022.9922501","Austrian research promotion agency; Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922501","","Personal protective equipment;File systems;Distributed ledger;Pipelines;Data visualization;Quality of service;Fabrics","","5","","44","IEEE","1 Nov 2022","","","IEEE","IEEE Conferences"
"Microservices Architecture for IoT Applications in the Ocean : Microservices Architecture based Framework for Reducing the Complexity and Increasing the Scalability of IoT Applications in the Ocean","A. Razzaq","Marine Information Science & Technology, Zhejiang University, Zhoushan, China",2020 20th International Conference on Computational Science and Its Applications (ICCSA),"18 Nov 2020","2020","","","87","90","This is a doctoral research symposium that is prepared to encounter the challenges of IoT systems and data in the Ocean. Managing and analyzing the big data of oceanography is difficult because of increasing the growth of massive data. The use of IoT devices/sensors is becoming more complex day by day. This research discusses the critical challenges of IoT applications and data in the Ocean, also will keep eyes on how microservice architecture plays essential roles in IoT applications. We intent to mitigate or decrease the complexity of IoT data and increase the scalability for the IoT systems in the Ocean. Also, we intend to increase a profound comprehension of the challenges and solutions, migration process, architecture design and description in MSA with IoT systems in the Ocean. We are expecting the outcome will be: (i) MSA systematic study for IoT applications, (ii) process to enhance the scalability of legacy systems (iii) adoption process of monolithic systems to MSA (iv) MSA process or software architecture selection process for IoT applications in the Ocean (v) Recommendations and Guidelines for the developer and scientific use (vi) recommendations for future work.","","978-1-7281-9260-4","10.1109/ICCSA50381.2020.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257516","Software Architecture;Microservices;MSA;IoT;Ocean;Big Data;systematic mapping study","Internet of Things;Computer architecture;Oceans;Scalability;Interoperability;Software architecture;Software","","5","","29","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"Digital Thread for Smart Products: A Survey on Technologies, Challenges, and Opportunities in Service-Oriented Supply Chains","D. Bianchini; T. Fapanni; M. Garda; F. Leotta; M. Mecella; A. Rula; E. Sardini","Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Computer, Control and Management Engineering, University of Rome “La Sapienza,”, Rome, Italy; Department of Computer, Control and Management Engineering, University of Rome “La Sapienza,”, Rome, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy",IEEE Access,"17 Sep 2024","2024","12","","125284","125305","In Smart Manufacturing, the recent opportunities provided by the Information and Communication Technologies have paved the way to a seamless connection of the manufactured product throughout its entire lifecycle, leading to the diffusion of the concepts of Smart Product and Digital Thread, which leverage digital technologies to assure a continuous flow of data encompassing the design phase of a product, manufacturing, operation, maintenance and also its eventual disposal or recycling. This compelling need to obtain a unified view of information associated with Smart Products has stimulated the so-called Internet of Services (IoS) paradigm, allowing for the sharing of products data and the execution of functions among various participants in intertwined supply chains. In these contexts, service-oriented architectures are being more and more employed to meet the complex and ever-evolving data analysis requirements, particularly when implementing Digital Thread solutions for Smart Products, where several issues must be considered, ranging from the heterogeneity of (Big) data to data sovereignty and data access policies, as information may cross the borders of multiple actors participating in intertwined supply chains. This survey discusses about the technological solutions and challenges to implement Digital Threads for Smart Products in Smart Manufacturing contexts, providing insights on opportunities for future research directions. In addition, the survey proposes a comprehensive multi-tier service-oriented architectural model to jointly tackle (Big) data heterogeneity, data sovereignty and data access policies issues, as they are only partially addressed by the research efforts examined in the literature review.","2169-3536","","10.1109/ACCESS.2024.3454375","Next-GenerationEU (Italian Piano Nazionale di Ripresa e Resilienza (PNRR)—M4 C2, Invest 1.3—D.D. 1551.11-10-2022)(grant numbers:PE00000004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664538","Service-oriented architectures;smart products;digital thread;Internet of Services;cyber-physical production network;smart factory","Surveys;Smart manufacturing;Computer architecture;Supply chains;Instruction sets;Distributed databases;Data models;Service-oriented architecture;Product delivery;Cyber-physical systems","","2","","141","CCBYNCND","4 Sep 2024","","","IEEE","IEEE Journals"
"Advanced Intrusion Detection in MANETs: A Survey of Machine Learning and Optimization Techniques for Mitigating Black/Gray Hole Attacks","S. M. Hassan; M. M. Mohamad; F. B. Muchtar","Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Johor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Johor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Johor, Malaysia",IEEE Access,"17 Oct 2024","2024","12","","150046","150090","Mobile Ad Hoc Networks (MANETs) are dynamic networks without fixed infrastructure, making them particularly vulnerable to security threats such as black and gray hole attacks. As these attacks grow more sophisticated, advancing detection methods become critical. This survey critically evaluates existing detection techniques and identifies major gaps in current research. It focuses on a comprehensive classification and in-depth analysis of attack detection methods, particularly those employing advanced Machine Learning techniques. We adopt a structured approach, analyzing MANET characteristics and detailing black and gray hole attacks. The evaluation covers various detection and mitigation techniques, with a strong emphasis on the innovative use of ML and optimization methods like Federated Learning (FL), reinforcement learning, and metaheuristic algorithms. Our findings indicate that advanced ML techniques, especially Long Short-Term Memory (LSTM) networks and FL, significantly enhance detection accuracy and robustness against these attacks. We also discussed the potential of game theory and reinforcement learning for optimizing routing protocols and improving network resilience. The survey underscores the necessity for ongoing research into more sophisticated and adaptable detection mechanisms, urging both academic and practical communities to explore novel approaches for developing more secure, efficient MANET systems.","2169-3536","","10.1109/ACCESS.2024.3457682","Universiti Teknologi Malaysia(grant numbers:Q.J130000.5028.10G12); PEMBANGUNAN SISTEM PEMANTAUAN DAN PERAMALAN PENYELENGGARAAN SENI BINA WARISAN BERASASKAN IoT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670401","Mobile ad hoc networks (MANETs);blackhole attacks;gray hole attacks machine learning in network security;federated learning (FL);optimization techniques in security","Mobile computing;Routing;Surveys;Routing protocols;Optimization;Long short term memory;Mobile ad hoc networks;Machine learning;Network security;Federated learning;Optimization methods","","2","","202","CCBYNCND","10 Sep 2024","","","IEEE","IEEE Journals"
"Age of Twin (AoT): A New Digital Twin Qualifier for 6G Ecosystem","K. Duran; M. Özdem; T. Hoang; T. Q. Duong; B. Canberk","Edinburgh Napier University, UK; Turk Telekom, Turkey; Ho Chi Minh City University of Technology (HCMUT)-Vietnam National University, Vietnam; Memorial University of Newfoundland, Canada; Edinburgh Napier University, UK",IEEE Internet of Things Magazine,"18 Dec 2023","2023","6","4","138","143","With the enhanced zero-touch operation and service management capabilities of digital twin technology, network management authorities have started implementing digital twin modeling. They achieve descriptive, predictive, and prescriptive twinning with rule-based replication and pre-defined synchronization mechanisms. However, it is not possible to reach out to the extreme needs of the sixth generation (6G) services, such as ultra-high data density (uHDD) and event-defined ultra-reliable low latency communication (EDuRLLC) services, with these traditional twin modeling methods. This is because these 6G services require cognitive abilities to manage twin-to-twin interactions by enabling extreme connectivity. For this reason, we propose a new digital twin modeling qualifier, age of twin (AoT), to measure the digital twin data freshness, especially to use in 6G deployments. In AoT formation, we consider device density, packet deadlines, link capacity, and buffer size metrics by relating to the three V of big data characteristics; velocity, volume, and variety. Besides, we form an AoT umbrella to cover topology-wise, service-type-wise, and traffic-type-wise digital twin modeling needs. We perform the AoT-based twin modeling for each AoT class and converge to an AoT value. According to the results, the high twinning rate contributes to increased data freshness and, thus, near-zero AoT value.","2576-3199","","10.1109/IOTM.001.2300113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10364356","","6G mobile communication;Performance evaluation;Data integrity;Ecosystems;Ultra reliable low latency communication;Big Data;Data models","","2","","15","IEEE","18 Dec 2023","","","IEEE","IEEE Magazines"
"Cybersecurity Solutions and Techniques for Internet of Things Integration in Combat Systems","A. Pasdar; N. Koroniotis; M. Keshk; N. Moustafa; Z. Tari","School of Systems & Computing, University of New South Wales, ACT, Australia; School of Systems & Computing, University of New South Wales, ACT, Australia; School of Systems & Computing, University of New South Wales, ACT, Australia; School of Systems & Computing, University of New South Wales, ACT, Australia; School of Computing Technologies, Centre of Cyber Security Research & Innovation (CCSRI), RMIT University, VIC, Australia",IEEE Transactions on Sustainable Computing,"","2024","PP","99","1","20","The Internet of Things (IoT) has enabled pervasive networking and multi-modal sensing, offering various services such as remote operations and augmenting existing processes. The military setting has increasingly and notably adopted IoT technologies, such as sensor-rich drones or autonomous vehicles, which provide military personnel with enhanced situational awareness, faster decision-making capabilities, and improved operational precision. However, integrating IoT into military systems introduces new security challenges due to increased connectivity and susceptibility to vulnerabilities. Cyberattacks on military IoT systems can have severe consequences, including operational disruptions and compromises of sensitive information. This article proposes a new perspective on examining threat models in IoT-enhanced combat systems, emphasising approaches for identifying threats, conducting vulnerability assessments, and suggesting countermeasures. It delves into the characteristics and structures of IoT-enhanced combat systems, exploring technical implementations and technologies. Additionally, it outlines five significant areas of focus, including blockchain, machine learning, game theory, protocols, and algorithms, to enhance understanding of IoT-enhanced combat systems. The insights gained from this analysis can inform the development of secure and resilient military IoT systems, ultimately enhancing the safety and effectiveness of military operations.","2377-3782","","10.1109/TSUSC.2024.3443256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10636816","Combat systems;cyber threat models;internet of battle things;internet of military things;Internet of Things","Security;Internet of Things;Threat modeling;Unified modeling language;Resilience;Prevention and mitigation;Green computing","","2","","","IEEE","14 Aug 2024","","","IEEE","IEEE Early Access Articles"
"Mitigating Challenges of the Space Environment for Onboard Artificial Intelligence: Design Overview of the Imaging Payload on SpIRIT","M. O. Del Castillo; J. Morgan; J. McRobbie; C. Therakam; Z. Joukhadar; R. Mearns; S. Barraclough; R. Sinnott; A. Woods; C. Bayliss; K. Ehinger; B. Rubinstein; J. Bailey; A. Chapman; M. Trenti",The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne; The University of Melbourne,2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","6789","6798","Artificial intelligence (AI) and autonomous edge computing in space are emerging areas of interest to augment capabilities of nanosatellites, where modern sensors generate orders of magnitude more data than can typically be transmitted to mission control. Here, we present the hardware and software design of an onboard AI subsystem hosted on SpIRIT. The system is optimised for on-board computer vision experiments based on visible light and long wave infrared cameras. This paper highlights the key design choices made to maximise the robustness of the system in harsh space conditions, and their motivation relative to key mission requirements, such as limited compute resources, resilience to cosmic radiation, extreme temperature variations, distribution shifts, and very low transmission bandwidths. The payload, called Loris, consists of six visible light cameras, three infrared cameras, a camera control board and a Graphics Processing Unit (GPU) system-on-module. Loris enables the execution of AI models with on-orbit fine-tuning as well as a next-generation image compression algorithm, including progressive coding. This innovative approach not only enhances the data processing capabilities of nanosatellites but also lays the groundwork for broader applications to remote sensing from space.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678148","edge AI;AI in Space;radiation resilience;Enhancing Nanosatellite Capabilities;Low Bandwidth AI;JPEGXL in space","Computer vision;Temperature distribution;Image coding;Space missions;Small satellites;Graphics processing units;Aerospace electronics","","2","","30","IEEE","27 Sep 2024","","","IEEE","IEEE Conferences"
"A Performance Characterization of Scientific Machine Learning Workflows","P. Krawczuk; G. Papadimitriou; R. Tanaka; T. M. Anh Do; S. Subramanya; S. Nagarkar; A. Jain; K. Lam; A. Mandal; L. Pottier; E. Deelman","Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA; Computer Science Department, University of Southern California, Los Angeles, CA, USA; Computer Science Department, University of Southern California, Los Angeles, CA, USA; Computer Science Department, University of Southern California, Los Angeles, CA, USA; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA; Renaissance Computing Institute, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, USA",2021 IEEE Workshop on Workflows in Support of Large-Scale Science (WORKS),"28 Dec 2021","2021","","","58","65","Scientific workflows are one of the well-established pillars of modern large-scale computational science. More recently, scientists have started to leverage machine learning (ML) capabilities in their workflows, leading to a new category of scientific workflows, denoted as scientific ML workflows. ML is not only about training and inference, modern ML workflows also involve complex data processing steps before the training can start, which are not often accounted for in most performance studies. In this work, we consider scientific ML workflows, from data pre-processing to training, inference, and model evaluation. We aim to explore (i) how scientific ML workflows differ from more traditional scientific workflows and; (ii) how we can characterize ML workflows both in terms of execution time and data movements when executing on a target cloud platform. We select three representative workflows, ranging from image classification to natural language processing and image segmentation, which have been executed using the academic cloud platform, Chameleon. We build four realistic deployment scenarios for each workflow, which stress data movements during workflow executions. Then, we compare the performance observed when utilizing these different configurations and study how different settings impact overall workflows performance and efficiency when running on cloud infrastructures. Finally, we summarize our findings and discuss performance impacts when augmenting scientific workflows with ML techniques and how traditional workflow management systems can improve their support for such workflows.","","978-1-6654-1136-3","10.1109/WORKS54523.2021.00013","DOE(grant numbers:#DE-SC0012636,#DE-SC0022328); NSF(grant numbers:#1664162); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652609","scientific workflows;machine learning;cloud;data movements;performance characterization","Training;Image segmentation;Scientific computing;Graphics processing units;Machine learning;Natural language processing;Task analysis","","2","","39","IEEE","28 Dec 2021","","","IEEE","IEEE Conferences"
"Drive-by Air Pollution Sensing Systems: Challenges and Future Directions","H. Zarrar; V. Dyo","Institute for Research in Applicable Computing (IRAC), University of Bedfordshire, Luton, U.K; Institute for Research in Applicable Computing (IRAC), University of Bedfordshire, Luton, U.K",IEEE Sensors Journal,"3 Oct 2023","2023","23","19","23692","23703","Air pollution has become a significant health, environmental, and economic problem worldwide. The conventional approach of deploying fixed high-end air quality monitoring stations provides accurate measurements but can be expensive to deploy and maintain. As a result, the stations are typically deployed in a few strategic locations with various spatial interpolation or prediction models to estimate the air quality values from unsampled points. Recently, drive-by air quality sensing has emerged as a popular approach due to its dynamic nature, high spatial coverage, and low operational costs while providing high-resolution data. At the same time, drive-by sensing (DS) has introduced a range of novel research challenges in terms of spatial and temporal coverage, mobile sensor (MS) calibration, and deployment strategies. This article provides a systematic review and analysis of the recent work in this area, focusing on vehicular platforms, deployment strategies, primary challenges, and promising research directions.","1558-1748","","10.1109/JSEN.2023.3305779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225667","Internet of Things (IoT);low-cost sensor (LCS);spatiotemporal coverage;vehicular-based sensing;vehicular networks","Sensors;Air pollution;Gas detectors;Monitoring;Optical sensors;Sensor phenomena and characterization;Temperature sensors","","2","","137","IEEE","21 Aug 2023","","","IEEE","IEEE Journals"
"Embracing Diversity and Inclusion: A Decolonial Approach to Urban Computing","G. Vargas-Solar; C. Ghedira-Guégan; J. A. Espinosa-Oviedo; J. -L. Zechinelli-Martin","INSA Lyon, CPE, UCBL, LIRIS, UMR5205, CNRS, Univ. Lyon, Lyon, France; INSA Lyon, CPE, UCBL, LIRIS, UMR5205, CNRS, Univ. Lyon, Lyon, France; INSA Lyon, CPE, UCBL, LIRIS, UMR5205, CNRS, Univ. Lyon, Lyon, France; Fundación Universidad de las Américas Puebla, San Andrés Cholula, Mexico",2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA),"2 Apr 2024","2023","","","1","6","This vision paper underscores the technical challenges and difficulties of addressing urban computing from a Diversity and Inclusion (DEI) decolonial standpoint. Issues of DEI, which encompass factors such as gender, race, age, socio-economic status, physical abilities, and religion, necessitate a shift in how we conceptualise the design of scientific and engineering methodologies. The decolonial perspective can be employed to scrutinise the influence of dominant viewpoints on our understanding of progress, innovation, and their contribution to societal welfare. The hypothesis is that these perspectives can be integrated into the design processes that deal with solutions, knowledge, and information systems across all layers, from infrastructure to application and user interfaces. This paper exhibits research questions, challenges and possible strategies to design DEI aware urban computing solutions with a decolonial perspective.","2161-5330","979-8-3503-1943-9","10.1109/AICCSA59173.2023.10479352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479352","","Technological innovation;User interfaces;Cultural differences;Information systems","","1","","20","IEEE","2 Apr 2024","","","IEEE","IEEE Conferences"
"Effects of Adopting Industry 4.0 on a Manufacturing Plant","P. Waghanna; A. Reddy; S. Deshpande; S. Chavan; V. R. Jaiswal; V. Naranje","BE IT Department of Pune Institute of Computer Technology, Pune; BE IT Department of Pune Institute of Computer Technology, Pune; BE IT Department of Pune Institute of Computer Technology, Pune; BE IT Department of Pune Institute of Computer Technology, Pune; IT Department of Pune Institute of Computer Technology, Pune; School of Engineering, Architecture and Interior Design, Amity University, Dubai","2024 11th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","14 May 2024","2024","","","1","6","In the era of Industry 4.0, Smart Manufacturing is reshaping how things are made. At the heart of it is the Industrial Internet of Things (IIoT), where smart sensors and connections create a digital system for factories. This paper highlights how IIoT facilitates real-time data exchange, aiding quick decision-making and creating adaptable manufacturing setups. Cyber-Physical Systems (CPS) integration is also discussed, showing how the line between physical and digital elements in manufacturing is getting blurred. Big Data Analytics is another game-changer, supporting data-driven decisions and predictive maintenance. The paper also digs into Artificial Intelligence and Machine Learning, showing how they automate tasks and continuously learn, improving manufacturing processes. Real-world applications are examined, including Digital Twins, advanced robotics like collaborative robots (Cobots), 3D printing, and smart supply chain management. While Smart Manufacturing offers numerous benefits, it's not without challenges. The survey talks about security and privacy concerns, emphasizing the need for strong cybersecurity. Interoperability, ensuring different technologies work seamlessly together, and addressing the workforce skills gap are also explored. The paper ends with examples of successful implementations and looks at future trends, such as the impact of 5G, blockchain in supply chain management, human augmentation, and the push for sustainability in Smart Manufacturing. This survey is a practical guide for anyone interested in understanding the current state and where Smart Manufacturing is headed in the world of Industry 4.0.","2769-2884","979-8-3503-5035-7","10.1109/ICRITO61523.2024.10522189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10522189","Industry 4.0;IIoT;Cyber Physical Systems;CoBots;AI;ML","Industries;Surveys;Technological innovation;Supply chain management;Market research;Fourth Industrial Revolution;Sustainable development","","1","","16","IEEE","14 May 2024","","","IEEE","IEEE Conferences"
"Security Challenges Prospective Measures In The Current Status of Internet of Things (IoT)","R. J.; V. S. M.","Department of Computer Science and Engineering, VIT, Chennai, India; Department of Computer Science and Engineering, VIT, Chennai, India",2022 International Conference on Connected Systems & Intelligence (CSI),"1 Nov 2022","2022","","","1","8","This paper provides a high-level review and evaluation of the present situation regarding IoT Securities. An Internet of Things design seeks to connect everyone with anything they want, whenever they want it. The perception layer, network layer, the application layer is the most important three layers which mainly make the Internet of Things. To achieve a stable IoT reality, a range of safety precautions must be imposed at each tier. The only way to assure the future of the IoT infrastructure is to address and resolve the security issues that it has. Many researchers have attempted to address the security concerns specific to IoT layers and devices by applying suitable measures. This paper provides a top level view of safety ideas, technology and security problems, possible remedies, and the IoT's future directions for securing and also in this paper, a depth evaluation of the safety associated demanding situations and raw sources of danger with inside the IoT programs have been showcased. Latter discussion on the safety issue, diverse rising and present technology centered for attaining an excessive diploma of agree with inside the IoT programs are discussed.","","978-1-6654-5815-3","10.1109/CSI54720.2022.9923984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9923984","IoT Construction;Security layer;Systemic Approach on Strategies;Framework layer","Current measurement;Safety;Security;Internet of Things","","1","","33","IEEE","1 Nov 2022","","","IEEE","IEEE Conferences"
"Real Time Environmental Factors Monitoring System by Sensor Fusion on a NodeMCU ESP8266-Wemos-D1 R1 Board","A. Panicker; D. Gupta; H. Deora; A. Jain; A. Kumar; N. Gupta","Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Electronics and Communication Engineering Department, Jaypee Institute of Information Technology, Noida, India; Department of Applied Science and Humanity, Dronacharya Group of Institutions, Greater Noida, U. P., India",2023 IEEE 11th Region 10 Humanitarian Technology Conference (R10-HTC),"19 Mar 2024","2023","","","1077","1082","It is an effective environment monitoring system that provides the community with a tool to monitor and data acquisition. The data then collected can be used to develop effective and feasible solutions to control green parameters like temperature, pressure, moisture, etc. This project's independence from the availability of a network makes it suitable for tough and remote geographical areas. The multiple sensor frame transmits the data wirelessly through the ESP-NOW protocol to a remote monitoring computer where through the application it is possible to monitor each sensor, detect alarm conditions, locate the sensors in an animated geographical map, and record all acquired data for preventive and statistical purposes.","2572-7621","979-8-3503-2614-7","10.1109/R10-HTC57504.2023.10461798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10461798","Sensors;Environmental factors;PCB;Tem-perature Pressure","Temperature sensors;Temperature measurement;Temperature distribution;Temperature dependence;Soil moisture;Humidity;Sensor fusion","","1","","15","IEEE","19 Mar 2024","","","IEEE","IEEE Conferences"
"A New IoT Storage System Based on Raw NVM","T. Cai; Y. Ma; D. Niu; P. Gao; T. Lei; J. Dai","The School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; The School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; The School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; The School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; The School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; The School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China",2022 IEEE International Conference on Big Data (Big Data),"26 Jan 2023","2022","","","367","372","NVM storage devices have the advantages of high read-write speed, non-volatile and large capacity, which provides support for efficient storage and management of a large number of time series data collected by IoT devices. However, how to study a new IoT storage system for time series data according to the advantages of NVM storage devices is an important issue that needs to be solved. This paper first analyses the characteristics of accessing to IoT time series data and then based on the characteristics of NVM storage devices, a multi-granularity auto-converting structure for time series data is designed. It not only reflects the timeliness of accessing to IoT time series data, but also avoids additional data replication, which improves the storage efficiency of IoT time series data. A timeliness-based heterogeneous query strategy is designed to improve the query efficiency according to the IoT time series data storage structure and accessing characteristics. The prototype of a new IoT storage system based on raw NVM named NBTSMS is implemented based on the Intel open-source NVM storage device driver PMEM. InfluxDB, OpenTSDB, and TimescaleDB are used for evaluation with YCSB-TS. Results show that NSTSMS can improve write throughput by 137%, random query throughput by 153.7%, scan throughput by 189.4%, and mixed-operations throughput by 55%.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020847","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020847","IoT;IoT time series data;time series data storage system;NVM storage device","Time series analysis;Memory;Prototypes;Big Data;Throughput;Internet of Things;Device drivers","","1","","22","IEEE","26 Jan 2023","","","IEEE","IEEE Conferences"
"Symphony of Sensors: The Harmonious Art of Massive Data Generation by Devices","R. Mishra; A. Mihovska; R. Prasad","Department of Computer Engineering and Science, University of Mumbai, Mumbai, India; Research & Development & Innovation Consortium (RDIC), Sofia, Bulgaria; Department of Business Development and Technology, Aarhus University, Herning, Denmark",2023 26th International Symposium on Wireless Personal Multimedia Communications (WPMC),"11 Dec 2023","2023","","","1","5","In today's interconnected world, devices of all shapes and sizes orchestrate a grand symphony of data generation, producing an unparalleled cacophony of information that prevail through every aspect of our lives. This paper takes center stage to explore the intricate choreography of this symphony, shedding light on the diverse cast of devices, the rhythms of data generation, and the significant implications for society. Through a harmonious blend of analysis and imagination, we unravel the melodies of innovation, challenges, and opportunities that arise from the massive data generation by devices.","1882-5621","979-8-3503-0890-7","10.1109/WPMC59531.2023.10338947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10338947","Data Preprocessing;IoT;Wearables;Cloud Computing;Real-time data;Distributed Computing","Wireless communication;Technological innovation;Wireless sensor networks;Shape;Standards organizations;Standardization;Production","","","","35","IEEE","11 Dec 2023","","","IEEE","IEEE Conferences"
"Federated Learning for Intelligent IoT Systems: Background, Frameworks, and Optimization Techniques","P. P. Ray","Department of Computer Applications, Sikkim University, Gangtok, Sikkim, India","Model Optimization Methods for Efficient and Edge AI: Federated Learning Architectures, Frameworks and Applications","","2025","","","241","280","Summary <p>In the rapidly expanding realm of the Intelligent Internet of Things (ITIoT) and federated learning, ensuring optimal performance while maintaining stringent security and privacy standards is paramount. This chapter first delves into the background of federate learning and it's necessary for existing IoT systems to emerge as intelligent. Second, we provide a comparative analysis of the state‐of‐the‐art industrial framework for leveraging ITIoT applications and development. Third, we delve deep into the optimization techniques for federated ITIoT systems, highlighting key strategies for efficient communication, model compression, asynchronous updates, and staleness handling. Moreover, the significance of robust privacy‐preserving mechanisms is underlined, with a comprehensive exploration of potential attack vectors and their respective mitigation strategies in federated IoT setups. Through a multifaceted approach, this chapter provides an in‐depth understanding of the challenges and solutions associated with federated ITIoT systems.</p>","","9781394219209","10.1002/9781394219230.ch13","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10770775.pdf&bkn=10770699&pdfType=chapter","","Internet of Things;Federated learning;Data privacy;Data models;Computational modeling;Bandwidth;Servers;Security;Painting;Intelligent sensors","","","","","","28 Nov 2024","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Automated Validation of Spatial Data","J. V. T. Salgado; D. Z. R. Vinicius; V. D. S. Dias; R. L. Rosa","Dep. of Computer Science, Univ. of Lavras Federal, Minas Gerais, Brazil; Dep. of Computer Science, Univ. of Lavras Federal, Minas Gerais, Brazil; Dep. of Computer Science, Univ. of Lavras Federal, Minas Gerais, Brazil; Dep. of Computer Science, Univ. of Lavras Federal, Minas Gerais, Brazil","2024 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)","23 Oct 2024","2024","","","1","6","Spatial databases, are often based on relational database management systems (RDBMS), to incorporate geographical data essential for data planning and optimization. However, maintaining the integrity of spatial data poses challenges, particularly in enforcing topological rules and preventing performance degradation during query execution. In this context, we propose an automated geometry validation application tailored for database environments, complemented by a user-friendly web-based interface. Our solution addresses the issue of invalid geometries often encountered in datasets, enhancing the reliability and efficiency of spatial database operations. Through performance and accuracy evaluations, we demonstrate the effectiveness of our approach in improving the overall user experience and trust in data planning processes with minimal implementation efforts.","1847-358X","978-953-290-138-2","10.23919/SoftCOM62040.2024.10721916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10721916","Spatial databases;Network Planning;Computational geometry;Geographical information systems","Geometry;Urban planning;Transportation;Spatial databases;User experience;Planning;Telecommunications;Reliability;Optimization;Geographic information systems","","","","18","","23 Oct 2024","","","IEEE","IEEE Conferences"
"IoT Data Management and A Brief Analysis of IoT in the Health Industry","M. Z. Hussain; M. Z. Hasan; M. O. Suffian; M. Ali Sarwar; S. Nosheen; M. A. Yaqub; A. Bilal","Department of Computer Science, Baharia University, Lahore, Pakistan; Department of Computer Science, University of Central Punjab, Lahore, Pakistan; Department of Economics, Information Technology University, Lahore, Pakistan; Department of Economics, Information Technology University, Lahore, Pakistan; Department of Computer Science, Bahria University, Lahore, Pakistan; Department of Computer Science, University of Education, Lahore, Pakistan; Department of Computer Science, National College of Business Administration Economics, Lahore, Pakistan",2023 Computer Applications & Technological Solutions (CATS),"9 Feb 2024","2023","","","1","14","The Internet of Things (IoT) has totally changed how we interact with the world, how we live and work. It is an ecosystem which consists of internet enabled devices which use microchips, sensors or any type of hardware which can be used for communication. IoT devices provide vast amounts of data but managing this data and ensuring its integrity and security is a challenging task that requires expertise. Depending on the unique needs and limitations of the IoT system, data processing and analysis can be carried out using cloud computing techniques. The efficiency, scalability, and efficacy of connected devices are all driven by Machine Learning and Cloud Computing, two key technologies in the IoT landscape. IoT is set to unlock new levels of creativity and value across sectors, revolutionizing how businesses run and how individuals go about their everyday lives. This paper talks about how data is collected from IoT devices, how is it processed, what are the sources of this data, how ML and Cloud Computing helps to maintain this data and overcome the challenges faced by the use of this technology. This paper also specifies how IoT is used in the medical industry. By 2025, IoT in healthcare market is projected to be worth more than534.3 billion dollars. Over the course of time, Internet of Medical Things (IoMT) has provided improved patient monitoring, early diagnosis, individualized treatments and diagnostics for the patients. Medical IoT devices like wearable sensors and remote monitoring devices have transformed patient care as they can enable early illness detection by collecting and analyzing patient data in real time this improving disease management. While the use of IoT promises to improve many parts of our lives, it also has some challenges that must be solved to fully utilize its ability by using latest technological techniques.","","979-8-3503-8388-1","10.1109/CATS58046.2023.10424074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10424074","IoT;sensors;communication;IoT integration;data management;data handling;healthcare;IoMT","Industries;Cloud computing;Scalability;Machine learning;Internet of Things;Security;Medical diagnostic imaging","","","","68","IEEE","9 Feb 2024","","","IEEE","IEEE Conferences"
"14Advances in E‐commerce Through the Integration of Distributed Computing Approaches","V. Podile; K. Suresh Kumar; L. P. L. Cavaliere; S. R. R. Annapureddy; K. V. Siva Praneeth; K. P. S. Sabareesh; D. B. Sambasiva Rao","1 K. L. Business School, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India; Panimalar Engineering College, 2 MBA Department, Chennai, Tamil Nadu, India; University of Foggia, 3 Department of Economics, Foggia, Italy; 4 Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India; 4 Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India; 4 Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India; 4 Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India",Meta-Heuristic Algorithms for Advanced Distributed Systems,"","2024","","","229","244","The integration of distributed computing approaches in e‐commerce has brought significant advances and benefits to businesses operating in the digital landscape. This chapter provides an overview of the definition and types of distributed computing approaches and their benefits, challenges, and considerations when integrating them into e‐commerce. The enhanced scalability and flexibility, enhanced performance and efficiency, enhanced security and privacy, cost savings, reduced operational complexity, and enhanced customer experience that result from this integration. The chapter also examines emerging trends in cloud computing, big data, and artificial intelligence in the integration of distributed computing methods in e‐commerce. The discussion comes to the conclusion that the incorporation of distributed computing methods is a good development for e‐commerce companies, but it is essential to take into account any potential risks and put in place the necessary countermeasures. Overall, this chapter offers a thorough analysis of distributed computing approaches' incorporation into e‐commerce, stressing the advantages, difficulties, and emerging trends. The information presented in this chapter can help businesses understand the importance of this integration and leverage its benefits to stay competitive in the digital age.","","9781394188079","10.1002/9781394188093.ch14","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10473720.pdf&bkn=10473747&pdfType=chapter","","Business;Distributed computing;Security;Scalability;Servers;Task analysis;Costs","","","","","","18 Mar 2024","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"AdaEdge: A Dynamic Compression Selection Framework for Resource Constrained Devices","C. Liu; J. Paparrizos; A. J. Elmore",MIT CSAIL; The Ohio State University; University of Chicago,2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","1506","1519","With the Internet of Things (IoT), a vast number of connected devices generate significant data, necessitating efficient compression techniques to manage storage costs and enhance query performance. However, “one-size-fits-all” approach to data compression is ineffective due to diverse applications, which vary in data characteristics, workloads, and hardware limitations. This paper introduces AdaEdge, a dynamic, hardware-conscious compression selection framework tailored for resource-constrained devices. AdaEdge is a best-effort compression selection frame- work designed to preserve application-critical information as much as possible within system constraints. It enhances the use of limited system resources through a dynamic data compression policy that considers the staleness and the significance of the data. AdaEdge applies a multi-armed bandit algorithm to assist compression selection, optimizing workload targets such as compression ratio, compression throughput, workload accuracy, or their weighted combinations. It supports both lossy and lossless compression selection, adapting to hardware constraints. It operates in both online and offline modes, addressing network constraints for edge nodes and evolving data policies to preserve workload-specific information. AdaEdge improves machine learning task accuracy by up to 30% over baseline within the same storage budget and by up to 20% in scenarios where lossless methods fall short due to low compression ratios. AdaEdge also shows robustness against data shifts and hardware variability.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00124","NSF(grant numbers:IIS-2048088); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597763","Compression;Edge;IoT","Performance evaluation;Accuracy;Data compression;Dynamic scheduling;Throughput;Hardware;Robustness","","","","54","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"Research on Improving Production Efficiency in Smart Manufacturing Using IoT","Y. Jiang","Liaoning Province, School of Materials Science and Engineering, Northeastern University, Shenyang City, China",2024 4th International Conference on Machine Learning and Intelligent Systems Engineering (MLISE),"19 Sep 2024","2024","","","450","454","In the context of the highly competitive and digital transformation of the manufacturing industry, the Internet of Things (IoT) plays a crucial role in enhancing production efficiency in smart manufacturing. This paper delves into how IoT improves production efficiency in smart manufacturing through real-time data collection, monitoring, automated decision-making, remote maintenance and services, and supply chain optimization. At the same time, we explore various challenges encountered in this process, including technical, economic, and regulatory and policy challenges. Despite these challenges, we firmly believe that by deepening the research on the application of IoT in smart manufacturing, we can overcome these difficulties, further improve the production efficiency of smart manufacturing, and promote the continuous development of the manufacturing industry.","","979-8-3503-7507-7","10.1109/MLISE62164.2024.10674615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10674615","Internet of Things;Smart Manufacturing;Production Efficiency;Technical Challenges;Economic Challenges;Regulatory and Policy Challenges","Manufacturing industries;Economics;Technological innovation;Supply chains;Production;Regulation;Real-time systems","","","","10","IEEE","19 Sep 2024","","","IEEE","IEEE Conferences"
"IoT-Enabled Poultry Farming: Innovations in Automation and Monitoring","W. Y. Leong; Y. Z. Leong; W. S. Leong","Persiaran Perdana BBN Putra Nilai, INTI International University, Nilai, Negeri Sembilan; Schneider Electric Singapore Pte. Ltd., 50 Kallang Avenue, Schneider Electric Building, Singapore; Schneider Electric Singapore Pte. Ltd., 50 Kallang Avenue, Schneider Electric Building, Singapore",2024 Asian Conference on Communication and Networks (ASIANComNet),"30 Dec 2024","2024","","","1","5","The integration of Internet of Things (IoT) technology into poultry farming has revolutionized the industry, offering new possibilities for automation, real-time monitoring, and data-driven decision-making. This paper explores the innovative applications of IoT in poultry farming, highlighting how these technologies enhance operational efficiency, improve animal welfare, and increase productivity. By examining IoTenabled devices, systems, and their implementation, we present an overview of the current advancements and future potential in smart poultry farming.","","979-8-3503-6700-3","10.1109/ASIANComNet63184.2024.10811014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10811014","Innovation process;Internet of Things;poultry farming;automation;monitoring","Productivity;Technological innovation;Automation;Costs;Animals;Data security;Standardization;Internet of Things;Monitoring;Farming","","","","26","IEEE","30 Dec 2024","","","IEEE","IEEE Conferences"
"10 Developing a Big Data Infrastructure: Integral Modules and Best Procedures for Alleviating Security and Privacy Challenges","",,Intelligent Cybersecurity and Resilience for Critical Industries: Challenges and Applications,"","2025","","","269","304","Intelligent Cybersecurity and Resilience for Critical Industries: Challenges and Applications thoroughly explores cybersecurity principles, strategies, and technologies crucial for protecting digital assets and combating evolving cyber threats in critical industries. This book provides indispensable guidance in fortifying cyber defenses for critical infrastructures. Each chapter offers invaluable insights into proactive defense measures, from AI-driven threat management in healthcare systems to practical applications of AI for cyber risk management in critical infrastructures. Unraveling the complexities of contemporary cyber threats, this book empowers readers with the knowledge and tools needed to navigate the intricate landscape of cybersecurity effectively. Through a multidisciplinary approach spanning AI, machine learning, and advanced technologies, it addresses the urgent challenges organizations encounter in securing their digital infrastructure and safeguarding sensitive data from malicious cyber-attacks. Technical topics discussed in the book include: - AI-driven strategies for advanced malware detection and prevention - Hybrid deep learning techniques for precise malware classification - Machine learning applications tailored to IoT security challenges - Comprehensive exploration of blockchain techniques enhancing IoT security and privacy - Practical integration of security analysis modules for proactive threat intelligence. Designed as an essential reference, this book caters to students, researchers, cybersecurity professionals, and individuals keen on comprehending and tackling contemporary cyber defense and risk assessment challenges. It serves as a valuable resource for enhancing cybersecurity awareness, knowledge, and practical skills in critical industries.","","9788770042253","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10850586.pdf&bkn=10850510&pdfType=chapter","","","","","","","","22 Jan 2025","","","River Publishers","River eBook Chapters"
"Cloud Computing in Smart Cities: Privacy, Ethical and Social Issues","A. R. M. Alkhazali; A. M. Khasawneh; S. Alzoubi; M. Magableh; R. R. Mohamed; B. Pandey","MIS, BI and Data Analysis Department, Faculty of Business and Financial Science, Irbid National University, Irbid, Jordan; Department of Information Technology, College of Computer Science and Informatics, Amman Arab University (AAU), Jordan; Information Technology department, College of Computer Science and Informatics, Amman Arab University (AAU), Jordan; MIS, BI and Data Analysis Department, Faculty of Business and Financial Science, Irbid National University, Irbid, Jordan; College of Computing dan Informatics, Universiti Tenaga Nasional, Malaysia; Eurasian National University & Astana IT University, Astana, Kazaksthan & Jain Deemed To Be University, Bangalore, India",2023 International Conference on Computer Science and Emerging Technologies (CSET),"19 Dec 2023","2023","","","1","7","The rapid development of cloud computing technologies has revolutionized various sectors, and smart cities are no exception. Smart cities leverage cloud computing to optimize urban services, enhance resource management, and improve the overall quality of life for their inhabitants. However, as these technological advancements proliferate, concerns about privacy, ethical considerations, and social implications have emerged. This research paper critically examines the multifaceted challenges associated with the integration of cloud computing in smart cities, shedding light on the potential risks and highlighting the need for comprehensive solutions. The research employs a mixed-methods approach, combining quantitative data analysis and qualitative case studies to offer a comprehensive perspective on the identified issues. The primary focus lies in identifying privacy risks, ethical dilemmas, and social disparities that arise due to the extensive use of cloud-based systems and data in smart cities. Furthermore, the study investigates the role of key stakeholders, including governments, technology providers, and citizens, in mitigating or exacerbating these challenges. Key findings reveal that while cloud computing empowers smart cities with unparalleled capabilities, it also exposes residents' personal information to potential breaches and misuse. Ethical concerns arise from the handling of sensitive data, data ownership, and algorithmic biases that could perpetuate discrimination. Moreover, social issues like the digital divide and access disparities may further exacerbate existing inequalities in smart city implementation. This research paper concludes by proposing a comprehensive framework of guidelines and best practices to address the identified issues effectively. These recommendations encompass enhanced data privacy measures, transparent and accountable data governance, the promotion of ethical data usage, and inclusive strategies to bridge social disparities. By adopting these measures, smart cities can harness the full potential of cloud computing while safeguarding individual rights and fostering a more equitable and inclusive urban environment. Overall, this study underscores the critical importance of addressing privacy, ethical, and social challenges in the context of cloud computing in smart cities. By adopting a holistic and proactive approach, city planners, policymakers, and technology providers can build sustainable and responsible smart cities that ensure the well-being and dignity of their residents in the digital era.","","979-8-3503-4173-7","10.1109/CSET58993.2023.10346675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346675","Cloud Computing;Smart Cities;Privacy;Ethical and Social Issues in IT;Internet of Things","Cloud computing;Ethics;Privacy;Data privacy;Technological innovation;Machine learning algorithms;Smart cities","","","","25","IEEE","19 Dec 2023","","","IEEE","IEEE Conferences"
"Toward Effective Retrieval Augmented Generative Services in 6G Networks","X. Huang; Y. Tang; J. Li; N. Zhang; X. Shen","Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, China; Department of Computer Science and Engineering, Washington University in St. Louis, St. Louis, MO, USA; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing, China; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Network,"20 Nov 2024","2024","38","6","459","467","Retrieval augmented generation (RAG) empowers generative language services by integrating extensive context from external data sources (a.k.a. knowledge bases). The current RAG-enhanced generative services are predominantly hosted in cloud environments, relying on static knowledge bases without real-time sensory information which may lead to constrained scalability, responsiveness, and overall service quality. One promising opportunity is to extend the deployment of such services to the network edge, leveraging the anticipated capabilities of 6G networks. In this article, we propose a deployment framework for RAG-enhanced generative services in 6G. We address the key challenges at the convergence of service deployment, 6G networks, and user interactions. Additionally, we explore potential techniques to enhance RAG-based services through data fusion, dynamic knowledge base deployment, service customization, and interactive user experiences. Lastly, we shed light on future paths toward the effective deployment and delivery of RAG-enhanced generative services.","1558-156X","","10.1109/MNET.2024.3436670","National Natural Science Foundation of China(grant numbers:62301151,62301336); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515110949); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620276","6G;retrieval augmented generation;knowledge base deployment;edge intelligence;service customization","6G mobile communication;Servers;Data integration;Knowledge based systems;Cloud computing;Streams;Real-time systems;Edge AI;Service-oriented systems engineering","","","","15","IEEE","1 Aug 2024","","","IEEE","IEEE Magazines"
"A Survey on Intelligent Network Operations and Performance Optimization Based on Large Language Models","S. Long; J. Tan; B. Mao; F. Tang; Y. Li; M. Zhao; N. Kato","Central South University, China; Central South University, China; Northwestern Polytechnical University, China; Central South University, China; Central South University, China; Central South University, China; Tohoku University, Japan",IEEE Communications Surveys & Tutorials,"","2025","PP","99","1","1","As Large Language Models (LLMs) have achieved significant success in handling multi-modal tasks such as text, images, videos, and sounds, particularly showcasing emergent capabilities in natural language tasks, they hold great potential for network operations that similarly involve vast amounts of text data, fault data, and log files. This paper focuses on the development of LLMs, detailing their fundamental principles and application scenarios across different domains. It highlights the remarkable capabilities of LLMs in tasks such as fault diagnosis, causal inference, and intelligent question answering, and applies these abilities to the field of network operations. Moreover, the paper reviews some of the key issues and technical barriers faced by intelligent networks, such as efficiently monitoring networks in real-time and providing timely alerts when necessary. In addition to examining the utilization of LLM in network operations, this paper introduces a framework for intelligent network operations and performance optimization, leveraging LLM. The objective of this framework is to bolster network robustness and furnish users with exceptional, personalized network services. Ultimately, we conclude by delineating the challenges encountered in LLM-based intelligent network operations and performance optimization, while presenting potential solutions to overcome these hurdles and propel the comprehensive deployment of LLM-driven network intelligence.","1553-877X","","10.1109/COMST.2025.3526606","the Postdoctoral Fellowship Program of CPSF(grant numbers:GZC20233160); Changsha Municipal Natural Science Foundation(grant numbers:kq2208284); Natural Science Foundation of Hunan Province(grant numbers:2023jj40774,2024JJ9173); National Natural Science Foundation of China(grant numbers:62302527); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829820","Large language model;Intelligent network;Network performance optimization;Network operation","Intelligent networks;Optimization;Costs;Monitoring;6G mobile communication;Surveys;Industries;Complexity theory;Automation;Tutorials","","","","","IEEE","7 Jan 2025","","","IEEE","IEEE Early Access Articles"
"Transforming Oilseed Production with the Power of IoT: Opportunities and Challenges","H. Jain; S. Gosai; N. Guruprasad","Department of Computer Science and Engineering, Global Academy of Technology, Bengaluru, Karnataka, India; Department of Computer Science and Engineering, Global Academy of Technology, Bengaluru, Karnataka, India; Department of Computer Science and Engineering, Global Academy of Technology, Bengaluru, Karnataka, India","2023 International Conference on IoT, Communication and Automation Technology (ICICAT)","2 Oct 2023","2023","","","1","6","This paper explores the application of the Internet of Things (IoT) technology in oilseed production. With the growing demand for vegetable oil and biodiesel, there is a need to improve the efficiency and productivity of oilseed crops. IoT provides a solution to this problem by allowing for real-time monitoring of various parameters such as soil moisture, temperature, and nutrient levels. This data can be used to optimize irrigation, fertilization, and other crop management practices. The paper also discusses the various IoT sensors available for implementing such systems, as well as the challenges that need to be addressed for successful adoption. The results of the study demonstrate the potential of IoT in revolutionizing oilseed production, paving the way for increased efficiency and environmental sustainability.","","979-8-3503-0282-0","10.1109/ICICAT57735.2023.10263750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10263750","IoT;Sensors;Optimized harvesting;Storage","Temperature sensors;Industries;Vegetable oils;Soil moisture;Production;Real-time systems;Sensors","","","","14","IEEE","2 Oct 2023","","","IEEE","IEEE Conferences"
"Automation of multi-layer multi-domain transport networks and the role of AI [Invited]","O. Gonzalez de Dios; P. Armingol Robles; L. Roelens; A. Muniz-Da-Costa; I. de Miguel; R. J. Duran Barroso; J. P. Fernandez-Palacios","Telefónica Innovación Digital, Madrid, Spain; Telefónica Innovación Digital, Madrid, Spain; Telefónica Innovación Digital, Madrid, Spain; Telefónica Innovación Digital, Madrid, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain; Telefónica Innovación Digital, Madrid, Spain",Journal of Optical Communications and Networking,"3 Jan 2025","2025","17","2","A124","A133","With increasing demand for customized connectivity, transport networks must evolve towards autonomous and customer-driven network management. This paper presents a comprehensive overview of network autonomy and the challenges associated with evolving toward higher levels of autonomy. Moreover, various use cases of artificial intelligence in network automation in IP-over-DWDM transport networks are also analyzed, in particular related to traffic prediction, quality of transmission, anomaly detection, network planning, and proactive failure management. Additionally, the role of generative AI in network operation is explored. Central to our discussion is a proposed control architecture based on open and standard SDN APIs, which incorporates network slicing for multi-layer transport networks and enables real-time access to normalized data, facilitating autonomous network operation.","1943-0639","","10.1364/JOCN.537463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823390","","Autonomous networks;Artificial intelligence;Real-time systems;Planning;Resource management;Network slicing;Data analysis;Computer architecture;Telemetry;Scalability","","","","","","3 Jan 2025","","","IEEE","IEEE Journals"
"Blockchain and Machine Learning Integration for Safe Data Sharing in Finance and HR","T. B. Sivakumar; E. Prathiba; S. Sharma; R. S. Prasad; M. S. Ramaratnam; V. Krishnamoorthy","Department of CSE, School of Computing, Vel Tech Rangarajan Dr.Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of Artificial Intelligence and Data Science, Mailam Engineering College, Mailam, India; Department of Business Administration, Shambhunath Institute of Engineering & Technology, Prayagraj, India; D Y Patil PGDM Institute, Pune, Akurdi, India; Department of Management Studies, Sri Chandrasekharendra Saraswathi Viswa Mahavidyalaya, Kanchipuram, India; Department of Management Studies, Kongu Engineering College, Erode, Perundurai, India",2024 International Conference on Intelligent Algorithms for Computational Intelligence Systems (IACIS),"24 Oct 2024","2024","","","1","6","Modern finance and HR businesses have challenges in exchanging data due to centralized systems that are subject to hacking and lack transparency. The study proposes employing blockchain technology and machine intelligence (ML) to address these issues holistically. The proposed system enhances integrity and resilience to assaults by utilizing a decentralized ledger for secure data exchange. ML algorithms enable predictive analytics, risk management, and personalized insights. The proposed system outperforms the existing system in terms of accuracy, security, and efficiency. The accuracy of fraud detection increases from 0.75 to 0.90, as does the estimate of staff turnover from 0.80 to 0.95. The proposed system achieves an overall accuracy of 95%, surpassing the existing system's 85%. Blockchain and ML integration can alter data management methods in finance and HR industries, with improved security measures resulting in a risk score of 2 compared to 7 in the existing system.","","979-8-3503-6066-0","10.1109/IACIS61494.2024.10721934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10721934","blockchain;finance;human resource;data sharing;security;predictive analytics;decentralized ledger","Industries;Training;Adaptation models;Accuracy;Heuristic algorithms;Data security;Computational modeling;Finance;Blockchains;Predictive analytics","","","","15","IEEE","24 Oct 2024","","","IEEE","IEEE Conferences"
"Dynamic Surveillance : Integration of VGG and ResNET","Y. Nashte; M. Chavan; R. Tamboli; T. Patil; U. Gurav","CSE (AIML), KIT's College of Engineering Kolhapur, Maharashtra, India; CSE (AIML), KIT's College of Engineering Kolhapur, Maharashtra, India; CSE (AIML), KIT's College of Engineering Kolhapur, Maharashtra, India; CSE (AIML), KIT's College of Engineering Kolhapur, Maharashtra, India; CSE (AIML), KIT's College of Engineering Kolhapur, Maharashtra, India","2024 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)","19 Nov 2024","2024","","","60","65","Within an environment where security and monitoring are of utmost significance, innovative research endeavors to reshape the field of surveillance technology. This study aims to solve the shortcomings of conventional surveillance systems, such as laborious manual data entry mistakes, imprecise human detection, and lengthy procedures for retrieving evidence film. This approach prioritized rapid picture collection, automated data logging, and accurate human identification in favor of human-centric alternatives. By means of thorough testing and execution, our study accomplished noteworthy outcomes in lowering mistakes and latency, therefore improving security responsiveness efficiently. To sum up, this method provides a viable response to the problems with surveillance technology, opening the door for more effective and dependable security systems.","","979-8-3503-5059-3","10.1109/DISCOVER62353.2024.10750569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10750569","Deep learning;machine learning;artificial intelligence;object detection;video surveillance;real-time;insight systems;SSD;VGG;ResNET","Deep learning;YOLO;Accuracy;Surveillance;Computational modeling;Real-time systems;Data models;Security;Integrated circuit modeling;Video recording","","","","20","IEEE","19 Nov 2024","","","IEEE","IEEE Conferences"
"Kubernetes Anti-Patterns: Overcome common pitfalls to achieve optimal deployments and a flawless Kubernetes ecosystem","G. M. Kannaiah",NA,Kubernetes Anti-Patterns: Overcome common pitfalls to achieve optimal deployments and a flawless Kubernetes ecosystem,"","2024","","","","","Discover practical insights for mastering Kubernetes problem-solving and efficient ecosystem management Key FeaturesLearn to recognize common Kubernetes anti-patterns with the guidance of a community expertDiscover actionable strategies and best practices to address anti-patternsExplore methods for fostering a culture of continuous improvement in KubernetesPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAs the popularity of Kubernetes continues to grow, it’s essential to understand and navigate the potential challenges of scalability, resource optimization, troubleshooting, and security. Kubernetes Anti-Patterns offers vital insights and strategies tailored to the current needs of practitioners and enthusiasts navigating the complexities of Kubernetes. Penned by an AWS-certified solutions architect with 16+ years of experience, this book will teach you the essential Kubernetes anti-patterns, their types, causes, and consequences. You’ll find practical solutions for each of the challenges and uncover real-world examples and case studies to enhance your Kubernetes expertise. Beyond technical details, you’ll delve into optimization, proactive assessment, and prevention strategies, ensuring your Kubernetes endeavors are marked by success and efficiency. Experienced or beginner, this book will equip you with the right knowledge to deploy and maintain a robust Kubernetes environment. By the end of this book, you’ll gain a holistic understanding of Kubernetes anti-patterns and develop the expertise to identify and address issues in various Kubernetes contexts. This knowledge will enable you to optimize your container orchestration environments and ensure the reliability, scalability, and security of your applications. What you will learnGet to grips with the nature and characteristics of Kubernetes anti-patternsFind out how to achieve stable Kubernetes deploymentsExtract insights from real-world use cases for informed decision-makingCultivate a proactive mindset for anticipating and preventing potential problemsOptimize Kubernetes deployments for improved efficiency and performanceDiscover actionable strategies for continuous improvement in your Kubernetes workflowWho this book is forKubernetes Anti-Patterns is for anyone who is actively working with or planning to work with Kubernetes in their professional roles. DevOps engineers, system administrators, software developers, IT managers, or any other professional responsible for container orchestration and deployment will find this book useful. A foundational understanding of Kubernetes concepts, terminology, and basic operations is assumed. Familiarity with key components like pods, services, deployments, and how Kubernetes manages containerized applications is required. ","","9781835463406","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10568914.pdf&bkn=10568913&pdfType=book","","","","","","","","24 Jun 2024","","","Packt Publishing","Packt Publishing eBooks"
"Enabling Dynamic Schema Modifications Through Codeless Data Management","P. Chavan Cholke; A. Patankar; A. Patil; S. Patwardhan; S. Phand","Vishwakarma Institute of Technology, Pune, Maharashtra, India; Vishwakarma Institute of Technology, Pune, Maharashtra, India; Vishwakarma Institute of Technology, Pune, Maharashtra, India; Vishwakarma Institute of Technology, Pune, Maharashtra, India; Vishwakarma Institute of Technology, Pune, Maharashtra, India",2024 IEEE Region 10 Symposium (TENSYMP),"19 Nov 2024","2024","","","1","9","In today's rapidly evolving digital landscape, effectively managing and adapting data structures in response to changing business needs is paramount. Traditional approaches to database management often require significant coding effort and manual intervention to modify schemas and handle corresponding objects, posing challenges in terms of agility and scalability. This research paper presents a novel framework for dynamic and codeless data management, aimed at addressing these challenges. The proposed system enables dynamic schema evolution, allowing users to modify and update data types hereby referred to as ‘templates’ in the paper, without writing code. Additionally, the system automates object handling, ensuring data consistency and reducing the risk of errors. By leveraging expression-based templates, users can create sophisticated data structures and implement complex business logic directly within the data model. The system's flexibility, ease of use, and automation capabilities empower organizations to adapt quickly to changing business requirements and scale their data management processes efficiently. Through a comprehensive examination of the system's architecture.features, and case studies, this paper explores the implications and advantages of codeless approaches to dynamic schema evolution and agile database development.","2642-6102","979-8-3503-6486-6","10.1109/TENSYMP61132.2024.10752325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752325","Object Factory;Design Patterns;Expression Evaluation;Data Access Objects;Expression generation;Templates","Technological innovation;Automation;Standards organizations;Organizations;Manuals;Aerodynamics;Data structures;Encoding;Data models;Logic","","","","31","IEEE","19 Nov 2024","","","IEEE","IEEE Conferences"
"Web-based Visualization and Analytics of Petascale data: Equity as a Tide that Lifts All Boats","A. Panta; X. Huang; N. McCurdy; D. Ellsworth; A. A. Gooch; G. Scorzelli; H. Torres; P. Klein; G. A. Ovando-Montejo; V. Pascucci","University of Utah; University of Utah; NASA Ames Research Center; NASA Ames Research Center; ViSOAR LLC; University of Utah; NASA Jet Propulsion Lab; Caltech; Utah State University, Blanding; University of Utah",2024 IEEE 14th Symposium on Large Data Analysis and Visualization (LDAV),"29 Nov 2024","2024","","","1","11","Scientists generate petabytes of data daily to help uncover environmental trends or behaviors that are hard to predict. For example, understanding climate simulations based on the long-term average of temperature, precipitation, and other environmental variables is essential to predicting and establishing root causes of future undesirable scenarios and assessing possible mitigation strategies. While supercomputer centers provide a powerful infrastructure for generating petabytes of simulation output, accessing and analyzing these datasets interactively remains challenging on multiple fronts. This paper presents an approach to managing, visualizing, and analyzing petabytes of data within a browser on equipment ranging from the top NASA supercomputer to commodity hardware like a laptop. Our novel data fabric abstraction layer allows user-friendly querying of scientific information while hiding the complexities of dealing with file systems or cloud services. We also optimize network utilization while streaming from petas-cale repositories through state-of-the-art progressive compression algorithms. Based on this abstraction, we provide customizable dashboards that can be accessed from any device with any internet connection, enabling interactive visual analysis of vast amounts of data to a wide range of users - from top scientists with access to leadership-class computing environments to undergraduate students of disadvantaged backgrounds from minority-serving institutions. We focus on NASA's use of petascale climate datasets as an example of particular societal impact and, therefore, a case where achieving equity in science participation is critical. We validate our approach by improving the ability of climate scientists to visually explore their data via two fully interactive dashboards. We further validate our approach by deploying the dashboards and simplified training materials in the classroom at a minority-serving institution. These dashboards, released in simplified form to the general public, contribute significantly to a broader push to democratize the access and use of climate data.","2832-6512","979-8-3315-1692-5","10.1109/LDAV64567.2024.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10767643","Data visualization;Petascale analytics;Data accessibility;Equity in science;Cloud computing;Petabytes","Training;Cloud computing;Visualization;Prevention and mitigation;NASA;Data visualization;Boats;Supercomputers;Fabrics;Tides","","","","77","IEEE","29 Nov 2024","","","IEEE","IEEE Conferences"
"PRISM: Predictive Resource Inference and Spot Instance Management","J. Oza; R. More; A. Maity; G. Kambli; C. Maniyath; A. Patil","Computer Engineering, K.J. Somaiya Institute of Technology; Computer Engineering, K.J. Somaiya Institute of Technology; Computer Engineering, K.J. Somaiya Institute of Technology; Computer Engineering, K.J. Somaiya Institute of Technology; Computer Engineering, K.J. Somaiya Institute of Technology; Computer Engineering, K.J. Somaiya Institute of Technology",2024 3rd International Conference for Advancement in Technology (ICONAT),"10 Dec 2024","2024","","","1","6","Resource-constrained engineering teams often face challenges in optimizing cloud infrastructure costs while maintaining the necessary compute resources for their workloads, especially for scalable projects. This paper proposes a novel neural network-driven framework for cost-effective hybrid cloud resource management, tailored specifically for small or resource-constrained engineering teams. The framework leverages a combination of spot instances in public clouds, containerization techniques, and neural networks to maximize resource utilization, handle scalable projects, and minimize costs.","","979-8-3503-5417-1","10.1109/ICONAT61936.2024.10774810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774810","Cost Optimization;Hybrid Cloud;Spot Instances;Neural Networks;Resource Allocation;Instance Management","Cloud computing;Costs;Scalability;Neural networks;Resource management;Optimization;Faces","","","","12","IEEE","10 Dec 2024","","","IEEE","IEEE Conferences"
"5G and IoT Cloud Integration for Enhancing Connectivity and Data Management","A. Manikanta Paladugu; R. V. Merugu; S. G. Krishna Gangavarapu; L. V. Krishna Meka; S. Kavitha; M. Kavitha","Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, Andhrapradesh, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, Andhrapradesh, India",2024 5th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV),"7 May 2024","2024","","","823","830","This research analyzed the result of super-fast 5G networks on the IoT and explores how the cloud can enhance the performance and execution of smart devices in conjunction with 5G. The arrival of 5G, akin to a next-level internet, enables rapid and low-latency communication between sensors and smart devices. Leveraging the cloud, which serves as a vast computing resource on the internet, can further optimize the capabilities of these smart devices in a 5G environment. The incorporation of 5th Generation and the cloud offers several significant outcomes. Firstly, it enhances connectivity by facilitating seamless and real-time data exchange among smart devices, enabling efficient interactions and improving overall system performance. Secondly, the cloud provides additional computing capacity and storage capacity, enabling smart devices to offload processing tasks and handle large volumes of generated data effectively. This capability enhances operational efficiency, particularly in domains such as self-driving cars and manufacturing, where real-time decision-making and advanced automation are critical. Moreover, the cloud's scalability and flexibility empower smart devices to adapt dynamically to changing demands. This capability allows businesses and individuals to scale their computing resources as needed, eliminating the need for substantial infrastructure investments. Additionally, the research addresses concerns regarding data management and security. By exploring cloud-based data handling techniques, it ensures efficient data processing while safeguarding privacy and implementing robust security measures for the interconnected ecosystem. In conclusion, this research aims to establish a symbiotic relationship between smart devices, 5G networks, and the cloud. Through this integration, it envisions a more connected and efficient IoT ecosystem, driving advancements in various industries, enhancing automation, and delivering an optimized user experience while upholding data privacy and security.","","979-8-3503-8564-9","10.1109/ICICV62344.2024.00136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10511245","Cloud Computing;IOT;5G;Data;Security","Industries;Cloud computing;Data privacy;Ethics;5G mobile communication;Decision making;Real-time systems","","","","16","IEEE","7 May 2024","","","IEEE","IEEE Conferences"
"The Definitive Guide to Data Integration: Unlock the power of data integration to efficiently manage, transform, and analyze data","P. -Y. BONNEFOY; E. CHAIZE; R. MANSUY; M. TAZI; S. Heckel",NA; NA; NA; NA; NA,"The Definitive Guide to Data Integration: Unlock the power of data integration to efficiently manage, transform, and analyze data","","2024","","","","","Learn the essentials of data integration with this comprehensive guide, covering everything from sources to solutions, and discover the key to making the most of your data stackKey FeaturesLearn how to leverage modern data stack tools and technologies for effective data integrationDesign and implement data integration solutions with practical advice and best practicesFocus on modern technologies such as cloud-based architectures, real-time data processing, and open-source tools and technologiesPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThe Definitive Guide to Data Integration is an indispensable resource for navigating the complexities of modern data integration. Focusing on the latest tools, techniques, and best practices, this guide helps you master data integration and unleash the full potential of your data. This comprehensive guide begins by examining the challenges and key concepts of data integration, such as managing huge volumes of data and dealing with the different data types. You’ll gain a deep understanding of the modern data stack and its architecture, as well as the pivotal role of open-source technologies in shaping the data landscape. Delving into the layers of the modern data stack, you’ll cover data sources, types, storage, integration techniques, transformation, and processing. The book also offers insights into data exposition and APIs, ingestion and storage strategies, data preparation and analysis, workflow management, monitoring, data quality, and governance. Packed with practical use cases, real-world examples, and a glimpse into the future of data integration, The Definitive Guide to Data Integration is an essential resource for data eclectics. By the end of this book, you’ll have the gained the knowledge and skills needed to optimize your data usage and excel in the ever-evolving world of data.What you will learnDiscover the evolving architecture and technologies shaping data integrationProcess large data volumes efficiently with data warehousingTackle the complexities of integrating large datasets from diverse sourcesHarness the power of data warehousing for efficient data storage and processingDesign and optimize effective data integration solutionsExplore data governance principles and compliance requirementsWho this book is forThis book is perfect for data engineers, data architects, data analysts, and IT professionals looking to gain a comprehensive understanding of data integration in the modern era. Whether you’re a beginner or an experienced professional enhancing your knowledge of the modern data stack, this definitive guide will help you navigate the data integration landscape.","","9781837634774","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10522545.pdf&bkn=10522544&pdfType=book","","","","","","","","8 May 2024","","","Packt Publishing","Packt Publishing eBooks"
"From Data to Insights: An In-Depth Analysis of Standard Data Warehousing and Data Mining Techniques in Various Industries","M. J. C. Samonte; R. J. L. Evangelista; J. A. T. Jonson; J. B. Tamargo","School of Information Technology, Mapúa University, Makati, Philippines; School of Information Technology, Mapúa University, Makati, Philippines; School of Information Technology, Mapúa University, Makati, Philippines; School of Information Technology, Mapúa University, Makati, Philippines",2024 14th International Conference on Software Technology and Engineering (ICSTE),"21 Jan 2025","2024","","","204","212","This paper comprehensively explores data warehousing and data mining techniques across diverse industries. The study investigates challenges, opportunities, and processes through a systematic methodology. Ethical considerations include copyright, privacy, and conflicts of interest, while technical hurdles involve managing data volume and ensuring integrity. Industries, including smart cities, healthcare, and education, offer avenues for optimized resource utilization and informed decision-making. The paper underscores the significance of responsible data management, technological advancements, and collaborative efforts in harnessing the transformative potential of large-scale data. The research employs this approach to provide insights into the evolving landscape of data-informed decision-making and its beneficial impact on industries and society. After a thorough literature review, this paper presents significant data warehousing and data mining opportunities across various sectors, such as optimizing innovative city processes and transforming healthcare and education decision-making. Embracing emerging technologies and adhering to ethical principles are crucial for harnessing the full potential of data for progress and innovation. It is concluded that collaboration between academia, industry, and regulatory bodies is essential in establishing standardized practices and responsible data usage.","","979-8-3503-7895-5","10.1109/ICSTE63875.2024.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10840394","Data Warehousing;Data Mining Techniques;Data Analysis;Big Data;Meta-analysis","Industries;Ethics;Technological innovation;Systematics;Warehousing;Decision making;Education;Collaboration;Medical services;Systematic literature review","","","","44","IEEE","21 Jan 2025","","","IEEE","IEEE Conferences"
"Data Valuation and Pricing in Internet of Things: Survey and Vision","X. Shi; H. Duan","Artificial Intelligence Research Institute, Shenzhen MSU-BIT University, Guangdong, China; Artificial Intelligence Research Institute, Shenzhen MSU-BIT University, Guangdong, China",2024 IEEE International Conference on Smart Internet of Things (SmartIoT),"17 Dec 2024","2024","","","547","554","In the digital age, data has become an invaluable asset for decision-making across various industries. Accurate data valuation is essential for businesses to effectively leverage their data assets, optimize strategies, and enhance operational efficiencies. This paper discusses the complex challenges inherent in data valuation methods, focusing on issues of data provenance and the lack of standardized valuation metrics. Moreover, the Internet of Things (IoT) further complicates this landscape by generating vast volumes of real-time data, which requires robust evaluation frameworks. Blockchain technology, with its decen-tralized and tamper-resistant characteristics, offers promising solutions by ensuring data integrity and traceability. Additionally, smart contracts enable automated and reliable execution of data transactions, reinforcing trust in the data exchange process. Tech-nically, the integration of wireless sensing technology and edge computing facilitates real-time data collection and processing, improving the accuracy and timeliness of data valuation, and machine learning (ML) techniques further enhance these efforts by uncovering patterns and relationships within large datasets. This study explores how these advanced technologies can address the limitations of existing data valuation methods, paving the way for a more transparent, secure, and efficient data marketplace.","2770-2677","979-8-3503-6644-0","10.1109/SmartIoT62235.2024.00090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788389","Data Valuation;Pricing;Internet of Things;Blockchain","Industries;Wireless communication;Wireless sensor networks;Accuracy;Decision making;Pricing;Real-time systems;Internet of Things;Cost accounting;Business","","","","48","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"Software Architecture for Agricultural Robots: Systems, Requirements, Challenges, Case Studies, and Future Perspectives","R. Raja","Donders Centre for Cognition, Department of Artificial Intelligence, Radboud University, Nijmegen, The Netherlands",IEEE Transactions on AgriFood Electronics,"10 Apr 2024","2024","2","1","125","137","Designing software architectures for autonomous robots for agricultural contexts is a demanding and difficult job due to the requirement to monitor numerous sensors and actuators, as well as autonomous decision-making in unpredictable, unexpected scenarios. Depending on the essential requirements of a robotic device for agricultural usage, robot software architecture is created differently. Since no single software architecture exists for all applications, extensive knowledge of the various software architectures for robots is needed when creating your own robotic architecture or selecting one from a number of existing architectures. As a result, this article provides a comprehensive history of software architecture and its application in the agricultural domain along with a chronology of how software design has evolved over time. We provide several case studies to understand the importance of application of software architecture in agriculture and food industry and how to choose the best architecture for agricultural tasks. Finally, this article discusses the open obstacles and difficulties that must be addressed in order to ensure more advancements in the development of robot architecture for agricultural applications.","2771-9529","","10.1109/TAFE.2024.3366335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459067","Agricultural robot;food processing;food packaging;harvesting robot;robot programming;software architecture","Robot sensing systems;Agricultural robots;Software architecture;Food packaging;Robot programming","","","","66","IEEE","5 Mar 2024","","","IEEE","IEEE Journals"
"Securing the Connected Future: A Comprehensive Analysis of Challenges, Threats, and Prospects in IoT Security","Suryakanta; H. Rao; J. Singh; G. Singh; S. Aggarwal","Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Amity University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Amity University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India",2023 3rd International Conference on Technological Advancements in Computational Sciences (ICTACS),"25 Jan 2024","2023","","","100","105","With new technology comes new challenges and opportunities. These opportunities try to leverage Internet of Things (I oT) and embark on creating a connected business. IoT promises technical advances, improved efficiencies, greater revenues and enhanced customer experiences. The rapid proliferation of IoT devices has revolutionized the way we interact with the world, offering unprecedented levels of connectivity and convenience. However, this proliferation has also exposed the IoT ecosystem to a myriad of security challenges and barriers. This research paper presents a comprehensive review of the current state of IoT security, focusing on the challenges and barriers, critical security issues that pose significant threats, and the potential future of IoT.","","979-8-3503-4233-8","10.1109/ICTACS59847.2023.10389948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389948","IoT Security;IoT Challenges and Barriers;IoT Future","Ecosystems;Focusing;Internet of Things;Security;Stakeholders;Business","","","","18","IEEE","25 Jan 2024","","","IEEE","IEEE Conferences"
"Integrated 3D Networking and Ambient IoT in 6G","M. Ghassemian; D. Vukobratovic; X. An; A. M. Valenzuela; L. Cordeiro; J. Fernandes; L. Rosa; S. Aguilar; S. Gupta","Huawei Technologies Duesseldorf GmbH, Germany; University of Novi Sad, Serbia; Huawei Technologies Duesseldorf GmbH, Germany; Instituto Tecnológico de Informática (ITI), Spain; OneSource, Portugal; OneSource, Portugal; OneSource, Portugal; SatelIoT, Spain; SatelIoT, Spain",2024 IEEE Conference on Standards for Communications and Networking (CSCN),"27 Jan 2025","2024","","","218","223","The paper provides an in-depth analysis of the integration of Integrated 3D Networking and Ambient IoT within the 6G standardization framework, as outlined by the IMT-2030 initiative. With the rapid evolution of telecommunications, advanced networking solutions are essential. Integrated 3D Networking combines terrestrial and non-terrestrial communication systems, enhancing connectivity and coverage, while Ambient IoT facilitates seamless, context-aware interactions between users and their environments. This study explores the core components and applications of Integrated 3D Networking, emphasizing its benefits in the 6G context, including improved service delivery, resilience and operational efficiency. Additionally, it examines the conceptual framework of Ambient IoT, addressing the challenges and opportunities of integration within a 6G environment. The synergistic relationship between these technologies is highlighted, focusing on enhanced sensing, connectivity, and positioning capabilities, supported by real-world use cases. Furthermore, the paper critically analyzes standardization efforts from organizations like ITU-R, IEEE, ETSI, and 3GPP, underscoring the necessity for harmonized standards to enable seamless integration. The findings reveal significant implications for advancing 6G standardization, identifying innovation opportunities and future research directions. By addressing these critical aspects, the paper aims to contribute to the discourse on the transformative potential of 6G technologies, paving the way for a ubiquitously connected and intelligent future.","2644-3252","979-8-3315-0742-8","10.1109/CSCN63874.2024.10849744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849744","6G standardization;3D Networking;Ambient IoT;Use case requirements;standardization landscape","6G mobile communication;Technological innovation;Three-dimensional displays;ETSI;Focusing;Organizations;Telecommunications;Sensors;3GPP;Resilience","","","","38","IEEE","27 Jan 2025","","","IEEE","IEEE Conferences"
"Artificial Intelligence–Blockchain‐Enabled–Internet of Things‐Based Cloud Applications for Next‐Generation Society","V. Hemamalini; A. K. Mishra; A. K. Tyagi; V. Kakulapati","Department of Networking and Communications, School of Computing, SRM Institute of Science and Technology, Chennai, India; Computer Science and Engineering, NIIT University, Neemrana, Rajasthan, India; Department of Fashion Technology, National Institute of Fashion Technology, New Delhi, Delhi, India; Sreenidhi Institute of Science and Technology, Hyderabad, Telangana, India",Automated Secure Computing for Next-Generation Systems,"","2024","","","65","82","Summary <p>Artificial intelligence (AI), blockchain technology, and Internet of Things (IoT) are three of the most rapidly evolving technologies in the current era. The integration of these technologies can provide significant benefits to cloud‐based environments by enhancing security, privacy, and data management. This paper proposes an architecture that combines AI, blockchain, and IoT in a cloud‐based environment. The proposed architecture provides a secure and reliable platform for data exchange and analysis, enabling the development of smart applications that can improve the efficiency, productivity, and quality of life. The architecture's core components are the IoT sensors, AI algorithms, and blockchain technology, which ensure data security and privacy, immutability, and transparency. The proposed architecture can be used in various applications, such as healthcare, logistics, and smart cities. In summary, this chapter provides an overview of the benefits and challenges associated with the integration of AI, blockchain, and IoT and proposes a novel architecture that can leverage these technologies to improve cloud‐based environments’ efficiency and security. This research work will discuss about futuristic technology and their role in respective fields in detail.</p>","","9781394213931","10.1002/9781394213948.ch4","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10554541.pdf&bkn=10554376&pdfType=chapter","","Internet of Things;Artificial intelligence;Blockchains;Cloud computing;Next generation networking;Medical services;Computer architecture","","","","","","11 Jun 2024","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Google Machine Learning and Generative AI for Solutions Architects: ​Build efficient and scalable AI/ML solutions on Google Cloud","K. Kavanagh; P. Vergadia",NA; NA,Google Machine Learning and Generative AI for Solutions Architects: ​Build efficient and scalable AI/ML solutions on Google Cloud,"","2024","","","","","Architect and run real-world AI/ML solutions at scale on Google Cloud, and discover best practices to address common industry challenges effectivelyKey FeaturesUnderstand key concepts, from fundamentals through to complex topics, via a methodical approachBuild real-world end-to-end MLOps solutions and generative AI applications on Google CloudGet your hands on a code repository with over 20 hands-on projects for all stages of the ML model development lifecyclePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionMost companies today are incorporating AI/ML into their businesses. Building and running apps utilizing AI/ML effectively is tough. This book, authored by a principal architect with about two decades of industry experience, who has led cross-functional teams to design, plan, implement, and govern enterprise cloud strategies, shows you exactly how to design and run AI/ML workloads successfully using years of experience from some of the world’s leading tech companies. You’ll get a clear understanding of essential fundamental AI/ML concepts, before moving on to complex topics with the help of examples and hands-on activities. This will help you explore advanced, cutting-edge AI/ML applications that address real-world use cases in today’s market. You’ll recognize the common challenges that companies face when implementing AI/ML workloads, and discover industry-proven best practices to overcome these. The chapters also teach you about the vast AI/ML landscape on Google Cloud and how to implement all the steps needed in a typical AI/ML project. You’ll use services such as BigQuery to prepare data; Vertex AI to train, deploy, monitor, and scale models in production; as well as MLOps to automate the entire process. By the end of this book, you will be able to unlock the full potential of Google Cloud's AI/ML offerings.What you will learnBuild solutions with open-source offerings on Google Cloud, such as TensorFlow, PyTorch, and SparkSource, understand, and prepare data for ML workloadsBuild, train, and deploy ML models on Google CloudCreate an effective MLOps strategy and implement MLOps workloads on Google CloudDiscover common challenges in typical AI/ML projects and get solutions from expertsExplore vector databases and their importance in Generative AI applicationsUncover new Gen AI patterns such as Retrieval Augmented Generation (RAG), agents, and agentic workflowsWho this book is forThis book is for aspiring solutions architects looking to design and implement AI/ML solutions on Google Cloud. Although this book is suitable for both beginners and experienced practitioners, basic knowledge of Python and ML concepts is required. The book focuses on how AI/ML is used in the real world on Google Cloud. It briefly covers the basics at the beginning to establish a baseline for you, but it does not go into depth on the underlying mathematical concepts that are readily available in academic material.","","9781803247021","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769249.pdf&bkn=10769248&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"Impact of IoT Integration on Enterprise Resource Planning (ERP) Systems: A Comprehensive Literature Analysis","S. Wijesinghe; I. Nanayakkara; R. Pathirana; R. Wickramarachchi; I. Fernando","Department of Industrial Management, University of Kelaniya, Dalugama, Sri Lanka; Department of Industrial Management, University of Kelaniya, Dalugama, Sri Lanka; Department of Industrial Management, University of Kelaniya, Dalugama, Sri Lanka; Department of Industrial Management, University of Kelaniya, Dalugama, Sri Lanka; Department of Industrial Management, University of Kelaniya, Dalugama, Sri Lanka",2024 International Research Conference on Smart Computing and Systems Engineering (SCSE),"11 Jun 2024","2024","7","","1","5","The integration of Internet of Things (IoT) technology with Enterprise Resource Planning (ERP) systems has gained significant attention in recent years. This research study aims to provide a comprehensive analysis of the impact of IoT integration on ERP systems. The study explores the benefits, challenges, and potential solutions associated with combining IoT and ERP. The findings highlight that IoT integration with ERP offers several advantages, such as real-time data collection, improved supply chain visibility, enhanced asset tracking, and predictive maintenance capabilities. These benefits lead to increased operational efficiency, reduced costs, and better decision-making. The integration of IoT with ERP also presents challenges that need to be addressed. These challenges include data security and privacy concerns, IoT traffic, and data management. The research identifies potential solutions and best practices to overcome these challenges. Furthermore, the study discusses the implications of IoT integration on various functional areas of ERP systems, such as healthcare, manufacturing, logistics, inventory management, and customer relationship management. The research methodology includes an extensive review of existing literature and case studies. This research provides valuable insights into the impact of IoT integration on ERP systems, offering guidance for organizations considering already implemented IoT-enabled ERP solutions or currently implementing ERP solutions.","2613-8662","979-8-3503-7568-8","10.1109/SCSE61872.2024.10550684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10550684","ERP system;IoT-enabled ERP;PRISMA","Technological innovation;Shape;Decision making;Supply chains;Organizations;Market research;Systems engineering and theory","","","","24","IEEE","11 Jun 2024","","","IEEE","IEEE Conferences"
"Application of Artificial Intelligence in Power Grid","L. Shi","Software engineering, School of Information Engineering, Shanghai Maritime University, Nantong, China","2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)","14 Jan 2025","2024","","","732","736","At present, artificial intelligence has been widely used in power system fault diagnosis, power grid operation and regulation, fault warning system, power grid equipment load prediction and other fields. Artificial intelligence can improve the efficiency and accuracy of fault diagnosis in power system. It can realize intelligent power grid management and optimal dispatching in power grid operation and regulation. In the fault warning system, the power grid faults can be predicted in advance and corresponding measures can be taken. In the load forecasting of power grid equipment, the load changes can be accurately predicted and reasonably adjusted. However, there are still some challenges in the application of AI in the power grid, such as data security and processing. This article provides a comprehensive overview and analysis of the application of artificial intelligence in the power grid.","","979-8-3315-0658-2","10.1109/CBASE64041.2024.10824290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824290","Artificial intelligence;Power grid;Power system fault diagnosis;Power grid operation and regulation;Fault warning system","Fault diagnosis;Power measurement;Accuracy;Alarm systems;Power grids;Regulation;Software measurement;Artificial intelligence;Power system faults;Software engineering","","","","13","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"Enabling Efficient NVM-Based Text Analytics without Decompression","X. Fang; F. Zhang; J. Nong; M. Zhang; P. Hu; Y. Chai; X. Du","Key Laboratory of Data Engineering and Knowledge Engineering (MOE), and School of Information, Renmin University of China; Key Laboratory of Data Engineering and Knowledge Engineering (MOE), and School of Information, Renmin University of China; Key Laboratory of Data Engineering and Knowledge Engineering (MOE), and School of Information, Renmin University of China; Department of Computer Science and Engineering, Tsinghua University; Key Laboratory of Data Engineering and Knowledge Engineering (MOE), and School of Information, Renmin University of China; Key Laboratory of Data Engineering and Knowledge Engineering (MOE), and School of Information, Renmin University of China; Key Laboratory of Data Engineering and Knowledge Engineering (MOE), and School of Information, Renmin University of China",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","3725","3738","Text analytics directly on compression (TADOC) is a promising technology designed for handling big data analytics. However, a substantial amount of DRAM is required for high performance, which limits its usage in many important scenarios where the capacity of DRAM is limited, such as memory-constrained systems. Non-volatile memory (NVM) is a novel storage technology that combines the advantage of reading per-formance and byte addressability of DRAM with the durability of traditional storage devices like SSD and HDD. Unfortunately, no research demonstrates how to use NVM to reduce DRAM utilization in compressed data analytics. In this paper, we propose N-TADOC, which substitutes DRAM with NVM while maintaining TADOC's analytics performance and space savings. Utilizing an NVM block device to reduce DRAM utilization presents two challenges, including poor data locality in traversing datasets and auxiliary data structure reconstruction on NVM. We develop novel designs to solve these challenges, including a pruning method with NVM pool management, bottom-up upper bound estimation, correspondent data structures, and persistence strategy at different levels of cost. Experimental results show that on four real-world datasets, N-TADOC achieves 2.04× performance speedup compared to the processing directly on the uncompressed data and 70.7% DRAM space saving compared to the original TADOC.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00286","National Natural Science Foundation of China(grant numbers:62172419,U1911203,62322213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597868","NVM;TADOC;text analytics directly on compressed data","Performance evaluation;Upper bound;Data analysis;Costs;Nonvolatile memory;Random access memory;Estimation","","","","65","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"Exploring different Actor Roles in Orchestrations of System of Systems","T. Nordstrom; L. R. Sutfeld; T. Besker","RISE Research Institutes of Sweden AB and Department of Applied Physics and Electronics, Umeå University, Sweden; Computer Science, RISE Research Institutes of Sweden AB, Gothenburg, Sweden; Systems Engineering, RISE Research Institutes of Sweden AB, Gothenburg, Sweden",2024 19th Annual System of Systems Engineering Conference (SoSE),"9 Aug 2024","2024","","","190","196","The rising complexity and interconnectedness of contemporary systems engineering solutions have spurred the development of Systems-of-Systems (SoS). Within a SoS, we find interconnected constituent systems (CSs), each possessing individual capabilities and managerial autonomy. For effective management of a SoS, a dedicated orchestration mechanism is crucial. However, currently, there is a lack of a well-defined internal structure or an understanding of roles and interactions between sub-parts of the Orchestrator. This paper proposes a framework for SoS orchestration, identifying distinct actors and their functional roles for an effective SoS operation. Our framework consists of two main groups: SoS Governors (handling legal and financial aspects) and the Orchestrator (responsible for the overall SoS operation). Key actors within the Orchestrator are identified and described, including the Goal Transformer, Registrar, Composer, Executor, Cartographer, Data Curator, and Translator. The paper concludes by discussing the dynamic collaboration between orchestration actors and the significance of clearly defining these roles for complex SoS management. This study offers a foundation for future research and practice in SoS orchestration, potentially enhancing these complex systems’ resilience, effectiveness, and overall management.","2835-3161","979-8-3503-6591-7","10.1109/SOSE62659.2024.10620949","Vinnova; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620949","System-of-Systems;Orchestration;Mediators","Law;Collaboration;Transformers;Complexity theory;System of systems;Resilience","","","","19","IEEE","9 Aug 2024","","","IEEE","IEEE Conferences"
"A Conceptual Framework for Predictive Maintenance of Underwater Sensors Using Named Data Networking and Machine Learning","A. Benarfa; S. Dahmane; B. Brik","Laboratoire d'Informatique et de Mathématiques, Université de Laghouat, Laghouat, Algeria; Computer Science Department, Ecole Normale Supérieure, Laghouat, Algeria; Computer Science Department, Sharjah University, Sharjah, UAE","2024 International Conference on Intelligent Computing, Communication, Networking and Services (ICCNS)","11 Dec 2024","2024","","","4","8","Underwater Wireless Sensor Networks (UWSNs) are essential for gathering data in diverse marine applications, including oceanographic research, environmental monitoring, and marine resource management. However, maintaining under-water sensors is challenging due to the harsh and inaccessible environment. This paper proposes a novel conceptual framework for predictive maintenance of UWSNs, leveraging the strengths of Named Data Networking (NDN) for data management and machine learning for sensor fault prediction. The framework integrates these technologies to enhance sensor network reliability and lifespan while minimizing maintenance costs. We discuss the design principles, key components, and potential benefits and challenges of this framework, along with a detailed analysis of its potential benefits and challenges. Additionally, we explore specific case studies to illustrate the applicability of the framework to real-world scenarios. This research highlights the potential of integrating NDN and AI for proactive maintenance in UWSNs, paving the way for future implementation and validation in real-world scenarios.","","979-8-3503-5469-0","10.1109/ICCNS62192.2024.10776363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10776363","Underwater Wireless Sensor Networks (UWSNs);Named Data Networking (NDN);Predictive Maintenance;Machine Learning;Sensor Fault Prediction","Wireless sensor networks;Costs;Accuracy;Machine learning;Sensors;Maintenance;Resource management;Environmental monitoring;Predictive maintenance","","","","22","IEEE","11 Dec 2024","","","IEEE","IEEE Conferences"
"Towards Proactive Maintenance : The Implementation of Digitized SCADA Systems for Predictive Maintenance Optimization in Production Environments","M. O. Seddini; L. Triqui-Sari","Department of Industrial Engineering Manufacturing Engineering Laboratory of Tlemcen (MELT), University of Tlemcen, Tlemcen, Algeria; Department of Industrial Engineering Manufacturing Engineering Laboratory of Tlemcen (MELT), University of Tlemcen, Tlemcen, Algeria",2024 IEEE 15th International Colloquium on Logistics and Supply Chain Management (LOGISTIQUA),"28 Jun 2024","2024","","","1","7","This paper advocates for the adoption of predictive maintenance strategies in production companies, highlighting the transition from traditional reactive and preventive maintenance approaches. It emphasizes the importance of data acquisition, management, and utilization in enabling predictive maintenance, proposing the development and implementation of a digitized Supervisory Control and Data Acquisition (SCADA) system. The proposed solution integrates advanced technologies such as sensors, Industrial Internet of Things (IIoT), and artificial intelligence (AI) to automate data acquisition, processing, and predictive analytics. Through systematic implementation, organizations can enhance operational efficiency, reduce downtime, and transition to proactive maintenance strategies. The paper presents the architecture, infrastructure setup, and testing methodology used to validate the effectiveness of the proposed system. Future research directions include continuous refinement of predictive models, scalability across industries, and understanding human factors for successful implementation.","2166-7373","979-8-3503-8391-1","10.1109/LOGISTIQUA61063.2024.10571506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10571506","Proactive maintenance;Supervisory Control and Data Acquisition (SCADA);Industrial Internet of Things (IIoT);Data acquisition;Data management;Industry 4.0","Scalability;Data acquisition;SCADA systems;Production;Predictive models;Maintenance;Artificial intelligence","","","","30","IEEE","28 Jun 2024","","","IEEE","IEEE Conferences"
"8 Overview of IoT Technologies and Applications","R. Jain",NA,Advancements in AI and IoT for Chip Manufacturing and Defect Prevention,"","2024","","","97","101","This is essential reading for semiconductor professionals seeking to expand their knowledge on silicon processes, understand the significance of defect prevention, and explore methods for optimizing processes by reducing defects using AI and IoT technologies. In the dynamic landscape of semiconductor manufacturing, the focus on processes and defect prevention stands paramount. Traditional approaches have yielded valuable insights, yet the emergence of artificial intelligence (AI) and Internet of Things (IoT) technologies heralds a new era in defect prevention strategies. Engineers specializing in AI and machine learning, interdisciplinary researchers, and early graduates aspiring to enter the semiconductor industry will also find this book invaluable. Meticulously crafted, this book provides concise, yet insightful content tailored to today's fast-paced readers. It emphasizes semiconductors, manufacturing processes, and defect prevention, offering a comprehensive understanding of these critical areas. The integration of AI and IoT in chip manufacturing defect prevention represents a groundbreaking advancement. Targeting semiconductor engineers, researchers, technology professionals, and students, this book serves as a valuable resource for understanding the interplay between semiconductors, manufacturing processes, defects, and the transformative potential of AI and IoT integration. Practical tools for failure analysis and parameter control are provided, along with hypothetical use cases and theoretical applications that inspire innovation. Through interdisciplinary insights, this book charts a course toward a future where semiconductor manufacturing defects are minimized, productivity is maximized, and innovation thrives at the intersection of technology and industry.","","9788770046800","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10643805.pdf&bkn=10643765&pdfType=chapter","","","","","","","","22 Aug 2024","","","River Publishers","River eBook Chapters"
"Unlocking the Potential of IoT Technologies in the Era of Industry 4.0 Digital Economy: An Exploration of the Transformative Impact","T. K. Vashishth; B. Kumar; K. K. Sharma; S. Chaudhary; R. Panwar; V. Sharma","School of Computer Science and Applications, IIMT University, Meerut, U.P, India; School of Computer Science and Applications, IIMT University, Meerut, U.P, India; School of Computer Science and Applications, IIMT University, Meerut, U.P, India; School of Computer Science and Applications, IIMT University, Meerut, U.P, India; School of Computer Science and Applications, IIMT University, Meerut, U.P, India; School of Computer Science and Applications, IIMT University, Meerut, U.P, India",2024 Sixth International Conference on Computational Intelligence and Communication Technologies (CCICT),"19 Jul 2024","2024","","","120","126","Business operations have undergone a considerable transition because of the Fourth Industrial Revolution or Industry 4.0. The Internet of Things (IoT) and the proliferation of connected gadgets have made the digital economy more dynamic and complicated. The introduction of the study provides an outline of Industry 4.0 and the salient features that characterise this period. The article then goes into detail on Industry 4.0’s use of IoT technologies and how such technologies are altering every aspect of business operations, from manufacturing to logistics and supply chain management. The report also looks at some of the issues with data security and privacy that enterprises have when deploying IoT technologies. The article provides case studies of companies that have effectively deployed IoT technology to help readers comprehend the transformative effects of these technologies. These case studies demonstrate how IoT technologies have helped businesses grow more productive, spend less money, and provide better customer service. In addition, the report looks at prospective IoT applications for Industry 4.0, like predictive maintenance and smart cities. Overall, this article offers a thorough review of the industry 4.0 digital economy’s transformational effects of IoT technology. It emphasises the potential advantages that companies can gain from these technologies as well as the difficulties they must overcome to reach their full potential.","","979-8-3503-7462-9","10.1109/CCICT62777.2024.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10596576","Internet of Things (IoT);smart manufacturing;preventive maintenance;supply chain management;workforce;job creation","Productivity;Supply chain management;Smart cities;Reviews;Companies;Fourth Industrial Revolution;Internet of Things","","","","10","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Digital Twin Models for Cybersecurity Use Cases in Water Utilities and SCADA Systems: A Review","J. R. Boogaard; S. P. Rao; S. R. A. Balaji; P. Ranganathan","Center for Cybersecurity Research (C2SR), University of North Dakota, Grand Forks, ND, USA; Center for Cybersecurity Research (C2SR), University of North Dakota, Grand Forks, ND, USA; Center for Cybersecurity Research (C2SR), University of North Dakota, Grand Forks, ND, USA; Center for Cybersecurity Research (C2SR), University of North Dakota, Grand Forks, ND, USA",2024 Cyber Awareness and Research Symposium (CARS),"13 Dec 2024","2024","","","1","11","This study seeks to investigate the recent trends in Digital Twin (DT) technology and how it can be utilized to improve the existing security of vulnerable public water treatment and wastewater treatment facilities. The scope of this study explores the integration of DT in water utilities to understand the technology’s potential in improving security and enhancing system efficiency. The paper also presents the Operational Technology (OT) issues and an overview of the capability in all manners with which Digital Twins use can transform water utility operations.","","979-8-3503-8641-7","10.1109/CARS61786.2024.10778873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778873","Cybersecurity;Digital Twin;SCADA;Water Utilities","Reviews;SCADA systems;Transforms;Digital twins;Safety;Wastewater;Wastewater treatment;Sustainable development;Cyberattack;Testing","","","","105","IEEE","13 Dec 2024","","","IEEE","IEEE Conferences"
"Enhancing Healthcare Services through User-Centered Data Collection and Analysis","O. Zungor; Y. Uludag; O. Celikel; O. Pinarer","Grad. School of Science and Engineering, Galatasaray University, Istanbul, Turkey; Dept. Computer Engineering, Galatasaray University, Istanbul, Turkey; Dept. Computer Engineering, Galatasaray University, Istanbul, Turkey; Dept. Computer Engineering, Galatasaray University, Istanbul, Turkey",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","6556","6563","The advent of real-time data processing applications has revolutionized monitoring and analysis capabilities across diverse operational domains, including big data and healthcare. This study focuses on the development and evaluation of a prototype application designed for real-time data processing in dynamic environments. The application parses configuration files, processes real-time sensor data and outputs calculated values at user-defined intervals, ensuring accuracy and timeliness in data analysis. Experimental evaluations under varied conditions validate the application’s robust performance in managing pipeline operations, computational efficiency, response times and data aggregation precision. Optimizations, including data type adjustments, significantly enhance network communication efficiency and reduce latency, critical for supporting real-time applications. The application’s flexibility in user-configured settings for data storage and aggregation proves essential for adapting to specific application requirements. This adaptability is particularly beneficial f or handling the complexities of big data and the sensitivity of healthcare data. Overall, this study contributes a robust solution for real-time data processing and continuous monitoring, demonstrating its feasibility and applicability across dynamic operational environments, including those requiring rigorous data handling and precise analytics.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825709","User-Centered Design;Internet of Medical Things (IoMT);Big Data Analytics in Healthcare;Predictive Health Analytics;Patient Engagement and Data Privacy","Data analysis;Sensitivity;Pipelines;Prototypes;Medical services;Big Data;Real-time systems;Time factors;Monitoring;Optimization","","","","26","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Nanoscale Computing at the Edge: AI Devices and Applications","S. Sivasubramani",Indian Institute of Technology Hyderabad,Nanoscale Computing: The Journey Beyond CMOS with Nanomagnetic Logic,"","2025","","","239","272","Summary <p>This chapter briefs the transformative impact of nanoscale computing on edge AI technologies. It discovers the interdisciplinary nature of nanoscale computing. It seamlessly merges physics, materials science, and computer science to redefine capabilities of AI devices at the edge. Real‐world implementations and success stories underscore the edge AI applications powered by nanomagnetic logic devices. The exploration spans Challenges and Future Developments. It showcase edge devices providing insightful case studies. The chapter gets into a comprehensive discussion on key concepts, emphasizing:‐ adaptability, collaboration, and continuous learning. Nanoscale computing emerges as a promise in edge AI. This chapter serves as a guide for professionals, researchers, and students. It offers an understanding of evolving landscape and pushing boundaries of possibilities in AI devices and applications at the edge.</p>","","9781394263578","10.1002/9781394263585.ch6","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10830658.pdf&bkn=10830553&pdfType=chapter","","Nanoscale devices;Cloud computing;Bandwidth;Real-time systems;Multi-access edge computing;Performance evaluation;Internet of Things;Decision making;Data handling;Computer architecture","","","","","","7 Jan 2025","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Data Management Strategy at Microsoft: Best practices from a tech giant's decade-long data transformation journey","A. Plotnikovs",NA,Data Management Strategy at Microsoft: Best practices from a tech giant's decade-long data transformation journey,"","2024","","","","","Leverage your data as a business asset, from readiness to actionable insights, and drive exceptional performanceKey FeaturesLearn strategies to create a data-driven culture and align data initiatives with business goalsNavigate the ever-evolving business landscape with a modern data platform and unique Data IPSurpass competitors by harnessing the true value of data and fostering data literacy in your organizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionMicrosoft pioneered data innovation and investment ahead of many in the industry, setting a remarkable standard for data maturity. Written by a data leader with over 15 years of experience following Microsoft’s data journey, this book delves into every crucial aspect of this journey, including change management, aligning with business needs, enhancing data value, and cultivating a data-driven culture. This book emphasizes that success in a data-driven enterprise goes beyond relying solely on modern technology and highlights the importance of prioritizing genuine business needs to propel necessary modernizations through change management practices. You’ll see how data-driven innovation does not solely reside within central IT engineering teams but also among the data's business owners who rely on data daily for their operational needs. This guide empower these professionals with clean, easily discoverable, and business-ready data, marking a significant breakthrough in how data is perceived and utilized throughout an enterprise. You’ll also discover advanced techniques to nurture the value of data as unique intellectual property, and differentiate your organization with the power of data. Its storytelling approach and summary of essential insights at the end of each chapter make this book invaluable for business and data leaders to advocate for crucial data investments.What you will learnDevelop a data-driven roadmap to achieve significant and quantifiable business goalsDiscover the ties between data management and change managementExplore the data maturity curve with essential technology investmentsBuild, safeguard, and amplify your organization's unique Data Intellectual PropertyEquip business leaders with trustworthy and high value data for informed decision-makingUnleash the value of data management and data governance to uplift your data investmentsWho this book is forThis book is for data leaders, CDOs, CDAOs, data practitioners, data stewards, and enthusiasts, as well as modern business leaders intrigued by the transformative potential of data. While a technical background isn't essential, a basic understanding of data management and quality concepts will be helpful. The book avoids twisted technical, engineering, or data science aspects, making it accessible and insightful for data engineers and data scientists to gain a wider understanding of enterprise data needs and challenges.","","9781835466933","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769273.pdf&bkn=10769272&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"Performance Analysis of Single Phase Induction Motor and Data Management Using IoT","A. Kadu; A. Patankar; A. Patil; S. Patwardhan; S. Phand","Department of Instrumentation Engineering, Vishwakarma Institute of Technology, Pune, Maharashtra, India; Department of Multidisciplinary Engineering, Vishwakarma Institute of Technology, Pune, Maharashtra, India; Department of Multidisciplinary Engineering, Vishwakarma Institute of Technology, Pune, Maharashtra, India; Department of Multidisciplinary Engineering, Vishwakarma Institute of Technology, Pune, Maharashtra, India; Department of Multidisciplinary Engineering, Vishwakarma Institute of Technology, Pune, Maharashtra, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","7","This research presents an innovative approach for real-time monitoring and analysis of induction motors by integrating NodeMCU and Arduino microcontrollers. The system employs a NodeMCU board for sensor data acquisition, while an Arduino board handles control and data processing tasks. Sensors attached to the induction motor collect crucial performance metrics, including temperature, vibration, and current consumption. The collected data is formatted into a Comma-Separated Values (CSV) file by the Arduino microcontroller. A Spring backend system parses the CSV data and stores it in a MongoDB database, enabling efficient management and storage of the acquired sensor data. The system incorporates an analytics service built on the Spring framework, enabling users to perform basic statistical methods and generate insightful visualizations. This functionality enhances the system’s capability to extract valuable insights from the collected data, aiding in predictive maintenance, fault detection, and performance optimization of induction motors. The proposed system offers a comprehensive solution for real-time monitoring, data management, and analysis of induction motors, utilizing the combined capabilities of NodeMCU, Arduino, Spring, and MongoDB.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10725656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725656","Induction Motors;Real-time Monitoring;NodeMCU;Arduino;Spring;MongoDB;Data Analysis;Predictive Maintenance;Fault Detection;Performance Optimization","Temperature sensors;Vibrations;Temperature measurement;Induction motors;Microcontrollers;Real-time systems;Springs;Monitoring;Optimization;Predictive maintenance","","","","12","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Data Engineering with Apache Spark, Delta Lake, and Lakehouse: Create scalable pipelines that ingest, curate, and aggregate complex data in a timely and secure way","M. Kukreja; D. Zburivsky",NA; NA,"Data Engineering with Apache Spark, Delta Lake, and Lakehouse: Create scalable pipelines that ingest, curate, and aggregate complex data in a timely and secure way","","2021","","","","","Understand the complexities of modern-day data engineering platforms and explore strategies to deal with them with the help of use case scenarios led by an industry expert in big dataKey FeaturesBecome well-versed with the core concepts of Apache Spark and Delta Lake for building data platformsLearn how to ingest, process, and analyze data that can be later used for training machine learning modelsUnderstand how to operationalize data models in production using curated dataBook DescriptionIn the world of ever-changing data and schemas, it is important to build data pipelines that can auto-adjust to changes. This book will help you build scalable data platforms that managers, data scientists, and data analysts can rely on. Starting with an introduction to data engineering, along with its key concepts and architectures, this book will show you how to use Microsoft Azure Cloud services effectively for data engineering. You'll cover data lake design patterns and the different stages through which the data needs to flow in a typical data lake. Once you've explored the main features of Delta Lake to build data lakes with fast performance and governance in mind, you'll advance to implementing the lambda architecture using Delta Lake. Packed with practical examples and code snippets, this book takes you through real-world examples based on production scenarios faced by the author in his 10 years of experience working with big data. Finally, you'll cover data lake deployment strategies that play an important role in provisioning the cloud resources and deploying the data pipelines in a repeatable and continuous way. By the end of this data engineering book, you'll know how to effectively deal with ever-changing data and create scalable data pipelines to streamline data science, ML, and artificial intelligence (AI) tasks.What you will learnDiscover the challenges you may face in the data engineering worldAdd ACID transactions to Apache Spark using Delta LakeUnderstand effective design strategies to build enterprise-grade data lakesExplore architectural and design patterns for building efficient data ingestion pipelinesOrchestrate a data pipeline for preprocessing data using Apache Spark and Delta Lake APIsAutomate deployment and monitoring of data pipelines in productionGet to grips with securing, monitoring, and managing data pipelines models efficientlyWho this book is forThis book is for aspiring data engineers and data analysts who are new to the world of data engineering and are looking for a practical guide to building scalable data platforms. If you already work with PySpark and want to use Delta Lake for data engineering, you'll find this book useful. Basic knowledge of Python, Spark, and SQL is expected.","","9781801074322","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163258.pdf&bkn=10163257&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Data Stewardship in Action: A roadmap to data value realization and measurable business outcomes","P. S. Lee; D. T. Charm",NA; NA,Data Stewardship in Action: A roadmap to data value realization and measurable business outcomes,"","2024","","","","","Take your organization's data maturity to the next level by operationalizing data governanceKey FeaturesDevelop the mindset and skills essential for successful data stewardshipApply practical advice and industry best practices, spanning data governance, quality management, and compliance, to enhance data stewardshipFollow a step-by-step program to develop a data operating model and implement data stewardship effectivelyPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the competitive data-centric world, mastering data stewardship is not just a requirement—it's the key to organizational success. Unlock strategic excellence with Data Stewardship in Action, your guide to exploring the intricacies of data stewardship and its implementation for maximum efficiency. From business strategy to data strategy, and then to data stewardship, this book shows you how to strategically deploy your workforce, processes, and technology for efficient data processing. You’ll gain mastery over the fundamentals of data stewardship, from understanding the different roles and responsibilities to implementing best practices for data governance. You’ll elevate your data management skills by exploring the technologies and tools for effective data handling. As you progress through the chapters, you’ll realize that this book not only helps you develop the foundational skills to become a successful data steward but also introduces innovative approaches, including leveraging AI and GPT, for enhanced data stewardship. By the end of this book, you’ll be able to build a robust data governance framework by developing policies and procedures, establishing a dedicated data governance team, and creating a data governance roadmap that ensures your organization thrives in the dynamic landscape of data management.What you will learnEnhance your job prospects by understanding the data stewardship field, roles, and responsibilitiesDiscover how to develop a data strategy and translate it into a functional data operating modelDevelop an effective and efficient data stewardship programGain practical experience of establishing a data stewardship initiativeImplement purposeful governance with measurable ROIPrioritize data use cases with the value and effort matrixWho this book is forThis book is for professionals working in the field of data management, including business analysts, data scientists, and data engineers looking to gain a deeper understanding of the data steward role. Senior executives who want to (re)establish the data governance body in their organizations will find this resource invaluable. While accessible to both beginners and professionals, basic knowledge of data management concepts, such as data modeling, data warehousing, and data quality, is a must to get started.","","9781837638123","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10460889.pdf&bkn=10460888&pdfType=book","","","","","","","","6 Mar 2024","","","Packt Publishing","Packt Publishing eBooks"
"The issues of big data network and AI initiatives [keynote 2]","Y. -i. Kwon",Hoseo University,2020 22nd International Conference on Advanced Communication Technology (ICACT),"9 Apr 2020","2020","","","1","52","This article consists only of a collection of slides from the author's conference presentation.","1738-9445","979-11-88428-04-5","10.23919/ICACT48636.2020.9061287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9061287","","Big Data;Artificial intelligence;Service robots;Three-dimensional printing","","","","","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Electric Power Data Asset Trading System Architecture Based on Double Chain Blockchain","X. Wang; B. Liu; W. Li; Z. Meng; Y. Zhu; R. Peng; L. Lu","State Grid Henan Information & Telecommunication Company (Data Center), Zhengzhou, Henan, China; State Grid Henan Information & Telecommunication Company (Data Center), Zhengzhou, Henan, China; State Grid Henan Information & Telecommunication Company (Data Center), Zhengzhou, Henan, China; State Grid Henan Information & Telecommunication Company (Data Center), Zhengzhou, Henan, China; State Grid Henan Information & Telecommunication Company (Data Center), Zhengzhou, Henan, China; Henan Jiuyu Tenglong Information & Engineering Co, Ltd., Zhengzhou, Henan, China; Beijing Remarkables United Technology Co., Ltd., Beijing, China",2024 4th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS),"13 Aug 2024","2024","","","75","79","This paper discusses the architecture of electric power data asset trading system based on dual blockchain. Firstly, the key technology of double chain blockchain is introduced, and its importance in the electric power data asset trading system is explained. Then, an architecture design of electric power data asset trading system based on double chain blockchain is proposed, and it is explained in detail. Then, the effectiveness of the dual-chain blockchain in implementing the electric power data asset trading system was verified through data analysis. Finally, the paper puts forward the problem of applying double chain blockchain to the architecture of electric power data asset trading system and the effective strategy of strengthening the application of double chain blockchain to the architecture of electric power data asset trading system. This research provides a feasible solution for the data asset trading system in the electric power industry, which helps to improve the transparency, security and efficiency of the transaction.","","979-8-3503-5998-5","10.1109/ACCTCS61748.2024.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612968","double chain blockchain;electric power data;asset transactions;system architecture","Computer science;Data analysis;Digital transformation;Systems architecture;Computer architecture;Power industry;Communications technology","","","","3","IEEE","13 Aug 2024","","","IEEE","IEEE Conferences"
"Implementation and Adoption of Digital Product Passports: A Systematic Literature Review","F. Abedi; U. A. Saari; L. Hakola","Industrial Engineering & Management, Faculty of Management & Business, Tampere University, Tampere, Finland; Industrial Engineering & Management, Faculty of Management & Business, Tampere University, Tampere, Finland; Technical Research Centre of Finland Ltd (VTT), Espoo, Finland","2024 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)","18 Dec 2024","2024","","","1","9","The transition towards sustainable and circular practices is crucial for optimizing resource use and reducing environmental impacts. Digital Product Passports (DPPs) as innovative tools play a key role in collecting and storing data throughout product lifecycles, enhancing sustainability and circularity in value chains. They improve transparency, enable data sharing among stakeholders, and encourage eco-friendly choices. Previous research has not focused on the factors impacting the implementation and adoption of DPPs. This systematic literature review of 53 articles analyzes the barriers and enablers in DPP adoption and implementation using the Technology-Organization-Environment (TOE) framework. The results show that digital technologies and legislative frameworks act as key enablers, while reluctance to share information among partners, complex data management and lack of standardization are major barriers. The paper also provides recommendations for companies and policymakers to promote the adoption of DPPs and facilitate the transition to the sustainable future.","2693-8855","979-8-3503-6243-5","10.1109/ICE/ITMC61926.2024.10794320","European Union(grant numbers:101112109); Business Finland(grant numbers:7926/31/2922,8306/31/2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794320","circular economy;digital product passport;sustainability;Technology-Organization-Environment (TOE) framework;traceability","Industries;Technological innovation;Databases;Collaboration;Production;Stakeholders;Reliability;Sustainable development;Fifth Industrial Revolution;Textiles","","","","54","IEEE","18 Dec 2024","","","IEEE","IEEE Conferences"
"Continuous Testing, Quality, Security, and Feedback: Essential strategies and secure practices for DevOps, DevSecOps, and SRE transformations","M. Hornbeek; D. Wakeman",NA; NA,"Continuous Testing, Quality, Security, and Feedback: Essential strategies and secure practices for DevOps, DevSecOps, and SRE transformations","","2024","","","","","A step-by-step guide to developing high-quality, secure, and agile software using continuous testing and feedback strategies and toolsKey FeaturesGain insights from real-world use cases and experiences of an IEEE Outstanding Engineer and DevOps consultantImplement best practices for continuous testing strategies and tools, test designs, environments, results, and metricsLeverage AI/ML, implementation patterns, and performance measurement during software developmentBook DescriptionOrganizations struggle to integrate and execute continuous testing, quality, security, and feedback practices into their DevOps, DevSecOps, and SRE approaches to achieve successful digital transformations. This book addresses these challenges by embedding these critical practices into your software development lifecycle. Beginning with the foundational concepts, the book progresses to practical applications, helping you understand why these practices are crucial in today’s fast-paced software development landscape. You’ll discover continuous strategies to avoid the common pitfalls and streamline the quality, security, and feedback mechanisms within software development processes. You’ll explore planning, discovery, and benchmarking through systematic engineering approaches, tailored to organizational needs. You’ll learn how to select toolchains, integrating AI/ML for resilience, and implement real-world case studies to achieve operational excellence. You’ll learn how to create strategic roadmaps, aligned with digital transformation goals, and measure outcomes recognized by DORA. You’ll explore emerging trends that are reshaping continuous practices in software development. By the end of this book, you’ll have the knowledge and skills to drive continuous improvement across the software development lifecycle.What you will learnEnsure continuous testing, quality, security, and feedback in DevOps, DevSecOps, and SRE practicesApply capability maturity models, set goals, conduct discoveries, and set benchmarks for digital transformationsImplement and assess continuous improvement strategies with various tools and frameworksAvoid pitfalls and enhance user experience with gap assessments, value stream management, and roadmapsAdhere to proven engineering practices for software delivery and operationsStay on top of emerging trends in AI/ML and continuous improvementWho this book is forThis book is for software engineers, DevOps engineers, DevSecOps engineers, site reliability engineers, testers, QA professionals, and enterprise leaders looking to implement continuous testing, quality, security, and feedback for achieving efficiency, reliability, and success in digital transformations. Basic knowledge and experience in software development, testing, system design and system operations is a must.","","9781835085219","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769387.pdf&bkn=10769386&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"Area-Efficient Pipeline Architecture for Serial Real-Valued Fast Fourier Transform","K. Li; H. Fang; Z. Ma; F. Yu; B. Zhang; Q. Xing","College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China; College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China; College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China; College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China; College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China; College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"","2024","PP","99","1","5","This brief presents a novel pipeline architecture designed to compute the fast Fourier transform (FFT) on real input signals in a serial format. This architecture significantly improves resource efficiency by sharing adders between butterfly and rotator structures. In addition, a novel data management approach for  $N$ -point radix-2 serial real-valued FFT (RFFT) has been proposed, which not only simplifies the data reordering circuit between processing elements (PEs) but also achieves natural order data output. The real-valued 1024-point FFT has been implemented on a field-programmable gate array (FPGA). Compared with typical real-valued serial commutator (RSC) FFT architecture, the proposed architecture achieves substantial improvement, including a reduction of 10.3% in the number of lookup tables (LUTs) and 12.5% in flip-flops (FFs).","1557-9999","","10.1109/TVLSI.2024.3496922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10767359","Fast Fourier transform (FFT);natural order output;pipelined architecture;real-valued;serial commutator","Computer architecture;Adders;Fast Fourier transforms;Hardware;Multiplexing;Timing;Very large scale integration;Throughput;Complexity theory;Resource management","","","","","IEEE","25 Nov 2024","","","IEEE","IEEE Early Access Articles"
"Building Modern SaaS Applications with C# and .NET: Build, deploy, and maintain professional SaaS applications","A. Watt",NA,"Building Modern SaaS Applications with C# and .NET: Build, deploy, and maintain professional SaaS applications","","2023","","","","","Embark on a tech-tastic adventure and build Software as a Service (SaaS) applications using the Microsoft tech stack Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesUnderstand the core concepts of Software as a Service and their importance in building modern applicationsBuild a wide array of key elements for SaaS applications using practical examplesLearn to test, deploy, upgrade, and maintain a SaaS applicationBook DescriptionThere are several concepts that must be mastered to deliver functional and efficient SaaS applications. This book is perfect for developers and teams with experience in traditional application development looking to switch to SaaS and deliver slick and modern applications. You‘ll start with a general overview of SaaS as a concept and learn with the help of an example throughout the book to bring life to the technical descriptions. You’ll use the Microsoft .NET tech stack for development and C# as the programming language to develop your desired SaaS application. Delivering SaaS requires a deep understanding of all layers in the application stack. As you progress, you’ll learn how to approach the database layer, the API, and the UI to confidently approach application development using the SaaS model. Additionally, you’ll explore how to test, deploy, maintain, and upgrade each component of the application. By the end of this book, you will be well equipped to approach all aspects of delivering software using the SaaS paradigm.What you will learnExplore SaaS and understand its importance in modern application developmentDiscover multi-tenancy and its impact on design decisions for SaaSBuild, test, and deploy a database, API, and UI for a SaaS applicationApproach authentication and authorization like a proScale a SaaS applicationEmploy C# and .NET to build SaaS applicationsWho this book is forIf you are a software developer with an interest in developing apps using the ‘SaaS’ paradigm, or a tech lead, scrum master, or a director and founder - this book will help you understand how to build a SaaS application. If you are a Java developer looking to start fresh with distributed systems, this book is for you. A basic understanding of Java, Spring/Spring Boot, and Web services will help you get the most out of this book.","","9781803240367","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251322.pdf&bkn=10251321&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"ChatGPT and AI for Accountants: A practitioner's guide to harnessing the power of GenAI to revolutionize your accounting practice","D. S. Dell; D. M. Akpan",NA; NA,ChatGPT and AI for Accountants: A practitioner's guide to harnessing the power of GenAI to revolutionize your accounting practice,"","2024","","","","","Elevate your accounting skills by applying ChatGPT across audit, tax, consulting, and beyondKey FeaturesLeverage the impact of AI on modern accounting, from audits to corporate governanceUse ChatGPT to streamline your accounting tasks with practical hands-on techniquesUnderstand the impact of AI in accounting through in-depth chapters covering various domains, including ethical considerations and data analyticsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced AI world, accounting professionals are increasingly challenged by the complexities of AI. Many struggle to integrate these advanced tools into their workflows, leading to a sense of overwhelm. ChatGPT for Accounting bridges this gap by not only simplifying AI concepts but also offering practical insights for its application in various accounting domains. This book takes you from the foundational principles of Generative Artificial Intelligence (GAI) to its practical applications in audits, tax planning, practice management, fraud examination, financial analysis, and beyond. Each chapter equips you with essential skills, showing you how AI can revolutionize internal control systems, enhance recruitment processes, streamline marketing plans, optimize tax strategies, and boost efficiency in audits. You’ll then advance to exploring the role of AI in forensic accounting, financial analysis, managerial accounting, and corporate governance, while also addressing ethical and security implications. Concluding with a reflective outlook on the promises and challenges of AI, you’ll gain a holistic view of the future of accounting. By the end of this book, you’ll be equipped with the knowledge to harness the power of AI effectively and ethically, transforming your accounting practice and staying ahead in the ever-evolving landscape.What you will learnUnderstand the fundamentals of AI and its impact on the accounting sectorGrasp how AI streamlines and enhances the auditing process for high accuracyUncover the potential of AI in simplifying tax processes and ensuring complianceGet to grips with using AI to identify discrepancies and prevent financial fraudMaster the art of AI-powered data analytics for informed decision-makingGain insights into seamlessly integrating AI tools within existing accounting systemsStay ahead in the evolving landscape of AI-led accounting tools and practicesWho this book is forWhether you're a seasoned accounting professional, a C-suite executive, a business owner, an accounting educator, a student of accounting, or a technology enthusiast, this book provides the knowledge and insights you need to navigate the changing landscape in applying GAI technology to make a difference in all you do. An appreciation and understanding of the accounting process and concepts will be beneficial.","","9781835462256","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769389.pdf&bkn=10769388&pdfType=book","","","","","","","","27 Nov 2024","","","Packt Publishing","Packt Publishing eBooks"
"A Study of Big Data and Classification of NoSQL Databases","J. Ahmed; M. Ahmed","Dept. of Computer Science and Information Technology, Maulana Azad National Urdu University, Hyderabad, India; Dept. of Computer Science and Information Technology, Maulana Azad National Urdu University, Hyderabad, India","2020 IEEE International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","6 Oct 2021","2020","","","1","8","Today, Big Data is the main topic of discussion everywhere due to its huge popularity as its getting generated in a huge volume in every second. It is getting huge consideration and gratitude because of its wide research area and application scenarios. Large scale, bulky, quick changes, huge growth in data is generally stated as Big Data. Data that is obtained from a wide variety of sources are usually in a format of structured, unstructured or semi-structured data. Many times big data is collected from multiple application sources, so there is a presence of structural heterogeneity. This problem of structural heterogeneity is one of the major challenges for researchers around the world and can be overcome using big data Integration. As big data refers to the data in large volumes, available in different formats and generated at extraordinary speed so to capture, process and analyze this kind of data becomes difficult using traditional data processing tools. These difficulties can be overcome using big data management tools and techniques. Big Data Integration and Management are very crucial, revolutionizing the industries and has many applications in all sectors of human life. This paper discusses brief information about big data, its history, integration issues, and available management methods and tools.","","978-1-6654-0482-2","10.1109/TEMSMET51618.2020.9557566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557566","Big Data;NoSQL Databases;Data Integration;Data Management;Big Data Analytics","Industries;NoSQL databases;Engineering management;Conferences;Entrepreneurship;Data integration;Big Data","","","","52","IEEE","6 Oct 2021","","","IEEE","IEEE Conferences"
"Towards the development of a network provisioning platform for data exchange in the health data space","N. Petroulakis; P. Zervoudakis; G. Nomikos; A. Kornilakis; P. Chatziadam; D. Laskaratos; V. M. . -. Eleftheria; Z. Eleni; V. Theodorou","Institute of Computer Science, Foundation for Research and Technology-Hellas (FORTH-ICS), Greece; Institute of Computer Science, Foundation for Research and Technology-Hellas (FORTH-ICS), Greece; Institute of Computer Science, Foundation for Research and Technology-Hellas (FORTH-ICS), Greece; Institute of Computer Science, Foundation for Research and Technology-Hellas (FORTH-ICS), Greece; Institute of Computer Science, Foundation for Research and Technology-Hellas (FORTH-ICS), Greece; Intracom SA Telecom Solutions, Greece; Intracom SA Telecom Solutions, Greece; Intracom SA Telecom Solutions, Greece; Intracom SA Telecom Solutions, Greece",2024 IEEE Conference on Standards for Communications and Networking (CSCN),"27 Jan 2025","2024","","","147","153","The deployment of network provisioning mechanisms across data locations in the health domain requires a secure environment to enable reliable, trustworthy, and sovereign data exchange, addressing all legal and regulatory considerations. A data space solution can facilitate secure, interoperable data exchange among diverse stakeholders, fostering collaboration while ensuring data privacy and compliance. This paper aims to tackle the challenge of data exchange in the health domain by outlining the requirements, intended uses, key functionalities, and proposed services for implementing secure network sharing mechanisms within the data space ecosystem. Additionally, it investigates and compares existing minimum viable data spaces to identify the most suitable mechanism for developing a data space platform. The paper presents the development of an architectural framework for a data space-enabled platform designed for network-provisioned data exchange within the health data space. Finally, to validate the proposed data space architecture and services, several realistic scenarios are presented.","2644-3252","979-8-3315-0742-8","10.1109/CSCN63874.2024.10849743","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849743","data space;network provisioning;data sharing;security and sovereignty;health domain;distributed data systems","Data privacy;Law;Refining;Ecosystems;Distributed databases;Collaboration;Data systems;Stakeholders;Reliability;Standards","","","","22","IEEE","27 Jan 2025","","","IEEE","IEEE Conferences"
"CMCache: An Adaptive Cross-Level Data Placement Method for Multi-Level Cache","Z. Zeng; Y. Tan; Z. Ma; J. Li; S. Zhao; D. Liu; X. Chen; A. Ren","College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Software Engineering, Chongqing Universityof Posts and Telecommunications, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Big Data and Software Engineering, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"","2025","PP","99","1","1","Multi-level cache systems enhance I/O performance by optimizing data placement across various cache levels from a global perspective. However, existing methods often struggle to place data at the optimal cache level promptly due to their reliance on historical access patterns and inflexible placement strategies. These methods face two main challenges: (1) For already cached data with sufficient access history, existing approaches only optimize movement between adjacent cache levels, potentially delaying data arrival at its globally optimal cache level and leading to unnecessary bandwidth consumption and increased latency. (2) For newly entered data without access history, current methods cannot accurately predict their future hotness and simply place them at a fixed cache level (i.e. first or last level), overlooking future accesses of new data and potentially resulting in high cache miss rates or cache pollution. To address these issues, we propose CMCache, an adaptive cross-level data placement method for multi-level cache. CMCache applies distinct placement strategies for cached and new data to reach the optimal level timely, considering their different characteristics. It also logically divides cache space into two sections to manage cached and new data separately, dynamically adjusting section sizes based on access patterns. This approach significantly improves data placement efficiency, achieving up to an 89% reduction in miss rates and a 79% decrease in average response times compared to existing methods.","1937-4151","","10.1109/TCAD.2025.3534116","National Natural Science Foundation of China(grant numbers:62072059,62472058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852153","Multi-level cache;data placement;cache management;storage system","Time factors;History;Prefetching;Delays;Performance evaluation;Bandwidth;System performance;Pollution;Optimization;Integrated circuits","","","","","IEEE","24 Jan 2025","","","IEEE","IEEE Early Access Articles"
"IEEE Access Special Section Editorial: Emerging Trends, Issues, and Challanges in Energy-Efficient Cloud Computing","G. Han; G. Jia; J. Lloret; Y. Bi","Department of Information and Communication System, Hohai University, Nanjing, China; Department of Computer Science, Hangzhou Dianzi University, Hangzhou, China; Department of Communications, Polytechnic University of Valencia, Valencia, Spain; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada",IEEE Access,"18 Jun 2020","2020","8","","108847","108856","Cloud computing is one of the most successful business models for providing a simple pay-as-you-go, and therefore is gaining much popularity in the industry. Customers and enterprises can maintain or scale-up a business easily while cutting down on their budget. However, energy consumption is one of the biggest problems in current cloud computing. It is both essential and urgent for governmental and industrial institutions to address this, to achieve rapid growth. The development of energy-efficient cloud computing has to be taken into consideration, which relies on the development of several key technologies: More energy-efficient mediums can be used in cloud computing at the platform level; energy-efficient scheduling algorithms, memory systems, storage systems, resource management policies, etc., can be adopted at the hypervisor level; energy-efficient scheduling, communications, and applications can be applied at the virtual machine level; and energy-efficient mobile cloud computing will be developed, involving green networking and wireless communications, cloud-based mobile applications, and limited resources management.","2169-3536","","10.1109/ACCESS.2020.3001770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120409","","","","1","","0","CCBY","18 Jun 2020","","","IEEE","IEEE Journals"
"Guest Editorial Special Issue on Trust-Oriented Designs of Internet of Things for Smart Cities","M. Shen; K. Xu; X. Du; M. J. Reed; M. Z. A. Bhuiyan; L. Zhang; R. Mijumbi","Department of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer and Information Sciences, Temple University, Philadelphia, USA; School of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Department of Computer and Information Sciences, Fordham University, Bronx, USA; Department of Computer Science and Technology, University of Science and Technology of China, Anhui, China; Software and Systems Reliability Engineering, Nokia Bell Labs, Blanchardstown, Ireland",IEEE Internet of Things Journal,"13 May 2020","2020","7","5","3897","3900","The Internet of Things (IoT) offers new opportunities for cities to make citizens live and work in more sustainable, healthy, and safe places. Since IoT applications in smart cities are characterized by different devices, networking standards, and data management strategies, trust becomes a fundamental issue in the IoT ecosystem. The explosion of IoT devices, along with their decentralized deployment, constraint resources, limited computational and cryptographic capabilities, brings challenges to trust management in IoT. The coexistence of multiple IoT domains also raises challenges, for example, how to evaluate and maintain trust across domain boundaries. This special issue aims at bringing the researchers from both academia and industry together to disseminate their recent advances related to the challenges and solutions in building trustful IoT for smart cities.","2327-4662","","10.1109/JIOT.2020.2982522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091961","","Special issues and sections;Smart cities;Internet of Things;Computational complexity;information management;Sustainable development","","","","0","IEEE","13 May 2020","","","IEEE","IEEE Journals"
"Message from the Program Chair: SCOUT 2021","S. Patnaik","SOA University, Bhubaneswar, India",2021 Smart City Challenges & Outcomes for Urban Transformation (SCOUT),"10 Nov 2022","2021","","","xiii","xiv","On the behalf of the organizing committee of the 1st International Conference on Smart City Challenges & Outcomes for Urban Transformation (SCOUT 2021), held during December 25-26th, 2021 in Bhubaneswar, Odisha, India, I would like to present this proceeding. The objective of this conference was to provide a strong platform for not only academicians and researchers but also policy makers to share their experiences of challenges faced and the alternative solutions they have come up with while bringing urban transformations to accomplish smart city projects through the adoption of disrupting technologies and state-of-the-art solutions.","","978-1-6654-0767-0","10.1109/SCOUT54618.2021.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9939235","","","","","","","IEEE","10 Nov 2022","","","IEEE","IEEE Conferences"
"Editorial: Third Quarter 2024 IEEE Communications Surveys and Tutorials","D. Niyato","College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore",IEEE Communications Surveys & Tutorials,"22 Aug 2024","2024","26","3","i","vii","I welcome you to the third issue of the IEEE Communications Surveys and Tutorials in 2024. This issue includes 19 papers covering different aspects of communication networks. In particular, these articles survey and tutor various issues in “Wireless Communications”, “Cyber Security”, “Network Virtualization”, “Vehicular and Sensor Communications”, “Multimedia Communications”, “Network and Service Management and Green Communications”, and “Internet Technologies”. A brief account of each of these papers is given below.","1553-877X","","10.1109/COMST.2024.3430588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10643728","","","","","","0","IEEE","22 Aug 2024","","","IEEE","IEEE Journals"
"Infusing Artificial Intelligence Into Software Engineering and the DevSecOps Continuum","T. (. Bannon","MITRE Corporation, Bedford, MA, USA",Computer,"2 Sep 2024","2024","57","9","140","148","The emergence of new artificial intelligence (AI) technologies, in particular, generative AI (GAI), shows groundbreaking potential, but there are challenges and limitations when evaluating GAI’s applicability for software engineering.","1558-0814","","10.1109/MC.2024.3423108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10663074","","","","","","16","IEEE","2 Sep 2024","","","IEEE","IEEE Magazines"
